{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T16:26:10.658889",
     "start_time": "2017-06-19T16:26:10.655004"
    }
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is split into stages that match those in the thesis document except for the pre-processing stage which is not included in the document and the CNN fine tuning stage which is separated out in the code. These stages are:\n",
    "\n",
    "-  Stage 0 -- Pre-process Image Files\n",
    "-  Stage 1 -- Image Preparation\n",
    "-  Stage 2 -- Feature Extraction using a Convolutional Neural Network\n",
    "-  Stage 3 -- Tile Clustering and Selection\n",
    "-  Stage 4 -- Machine Learning \n",
    "-  Stage 5 -- Inter-Imageset Test\n",
    "-  Stage 6 -- CNN Fine Tuning\n",
    "\n",
    "Each stage is split into two main sections:\n",
    "-  Functions\n",
    "-  Interactive steps\n",
    "\n",
    "Step through cells in order. Some interactive cells require settings to be specified (e.g. setting paths, image indexes, options selection). \n",
    "\n",
    "Many cells run into tens of minutes depending on number of images processed. Particularly long running cells (>2 hours) are noted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:23.617383",
     "start_time": "2017-06-06T13:14:23.578643"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "from time import strftime\n",
    "from timeit import timeit\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from subprocess import call\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plot\n",
    "from matplotlib import cm\n",
    "from matplotlib import pylab as pyl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn import svm\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import generic_utils\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:24.716608",
     "start_time": "2017-06-06T13:14:24.712195"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print all function for pd.DataFrames\n",
    "\n",
    "def print_all(df):\n",
    "    pd.set_option('display.max_rows', df.shape[0])\n",
    "    print(df)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0: Pre-process Image Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:32.746372",
     "start_time": "2017-06-06T13:14:27.138944"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating level: 1\n"
     ]
    }
   ],
   "source": [
    "#This step sets baselines globally\n",
    "\n",
    "levels = [1]\n",
    "l = 1\n",
    "\n",
    "global images_root_dir\n",
    "images_root_dir = '/Volumes/2T_HD/Masters_Project/images/'\n",
    "\n",
    "#Create directories if they don't already exist\n",
    "for l in levels:\n",
    "    print('Creating level:', l)\n",
    "    call(['mkdir', images_root_dir + 'level%s/' % (l, )])\n",
    "\n",
    "global results_dir\n",
    "results_dir = '/Volumes/2T_HD/Masters_Project/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T12:42:45.927844",
     "start_time": "2017-05-31T12:42:45.923611"
    }
   },
   "source": [
    "## Set Paths to SVS Files and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:26:11.741396",
     "start_time": "2017-06-05T14:26:11.737260"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell specifies source locations of files and directories\n",
    "# Source Astro SVS files\n",
    "CBTC_A = '/Volumes/2T_HD/Masters_Project/astrocytoma/*.svs'\n",
    "# Source Oligo SVS files (must be different to CBTC_A)\n",
    "CBTC_O = '/Volumes/2T_HD/Masters_Project/oligodendroglioma/*.svs'\n",
    "# Source TCGA raw images (flat directory)\n",
    "TCGA_raw_data_dir = '/Volumes/2T_HD/Data/'\n",
    "# Destination directory for creating patient directories including SVS images\n",
    "TCGA_dirs = '/Volumes/2T_HD/Masters_Project/data/'\n",
    "# Path to Patient_info.txt\n",
    "patient_info = \"/Volumes/2T_HD/Masters_Project/data/Patient_info.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View SVS File Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T07:40:06.246650",
     "start_time": "2017-06-05T07:39:56.002767"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_1.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_11.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_14.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_15.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_17.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_18.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_19.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_2.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_23.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_26.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_28.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_29.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_31.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_7.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_8.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/astrocytoma/cbtc_train_9.svs')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_10.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_12.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_13.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_16.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_20.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_21.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_22.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_24.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_25.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_27.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_3.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_30.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_32.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_4.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_5.svs'),\n",
       " OpenSlide('/Volumes/2T_HD/Masters_Project/oligodendroglioma/cbtc_train_6.svs')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell lists svs files\n",
    "astrocytomafiles = glob(CBTC_A)\n",
    "oligodendrogliomafiles = glob(CBTC_O)\n",
    "\n",
    "astrocytomaslides = [open_slide(astrocytomafiles[i]) for i, file in enumerate(astrocytomafiles)]\n",
    "oligodendrogliomaslides = [open_slide(oligodendrogliomafiles[i]) for i, file in enumerate(oligodendrogliomafiles)]\n",
    "\n",
    "display(astrocytomaslides)\n",
    "display(oligodendrogliomaslides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T07:38:33.250241",
     "start_time": "2017-06-05T07:38:33.236663"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 4.000028173775849, 16.002179314742996, 32.00435862948599),\n",
       " (1.0, 4.000069571000547, 16.00117485976003, 64.01211424822071),\n",
       " (1.0, 4.0, 16.002581909316767),\n",
       " (1.0, 4.000068941744226, 16.001186876215765, 64.02816296010536),\n",
       " (1.0, 4.00007743534149, 16.001882558059016, 32.0064345634358),\n",
       " (1.0, 4.00005319424818, 16.00148742924302, 32.006363656785176),\n",
       " (1.0, 4.000035595783126, 16.00109764613604, 64.01967956008633),\n",
       " (1.0, 4.000058374771664, 16.00079118051236, 64.02391912590514),\n",
       " (1.0, 4.0, 16.000333611342786, 32.003336670003335),\n",
       " (1.0, 4.0003734217030935, 16.007471288878207),\n",
       " (1.0, 4.000083402835696, 16.00444997616996),\n",
       " (1.0, 4.0000236933137465, 16.001232227488153, 32.00549867273416),\n",
       " (1.0, 4.000117992712584, 16.002019692623826, 32.006763427003975),\n",
       " (1.0, 4.000176366843034, 16.0016462841016, 32.006927279697976),\n",
       " (1.0, 4.0000260728998285, 16.000943782487116, 64.01713159319587),\n",
       " (1.0, 4.000202922077922, 16.003130528891397)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 4.00011320814337, 16.002067749092355, 32.01099055430055),\n",
       " (1.0, 4.000076769537847, 16.001535626535627, 32.003071253071255),\n",
       " (1.0, 4.000100408327198, 16.00200856989823, 32.00401713979646),\n",
       " (1.0, 4.000069319284625, 16.00138657792568, 32.00277315585136),\n",
       " (1.0, 4.000170419891039, 16.00205486798714, 32.007824348972534),\n",
       " (1.0, 4.000018601190476, 16.00077838223463, 32.00719106304494),\n",
       " (1.0, 4.00002707825616, 16.001682062045788, 32.006406382824494),\n",
       " (1.0, 4.000053009152914, 16.002745332219398, 32.005490664438796),\n",
       " (1.0, 4.000095008867494, 16.000380035469977, 32.004815002534215),\n",
       " (1.0, 4.000151255419986, 16.002942081502987),\n",
       " (1.0, 4.000122414004162, 16.00146914789422, 32.00548039937917),\n",
       " (1.0, 4.000271251705843, 8.000542503411687),\n",
       " (1.0, 4.000048631036327, 16.002016032553826, 64.0080641302153),\n",
       " (1.0, 4.000101927009087, 16.00323958015013, 32.00853276247733),\n",
       " (1.0, 4.000368007850835, 8.001554346307234),\n",
       " (1.0, 4.00007059155725, 16.00102956481193, 64.01301744798997)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell displays downsampling of slides at each level, starting wth level 0 as 1.0. \n",
    "astrocytomaslides_level_downsamples = [astrocytomaslides[i].level_downsamples for i, slide in \n",
    "                                      enumerate(astrocytomaslides)]\n",
    "oligodendrogliomaslides_level_downsamples = [oligodendrogliomaslides[i].level_downsamples for i, slide in \n",
    "                                      enumerate(oligodendrogliomaslides)]\n",
    "\n",
    "display(astrocytomaslides_level_downsamples)\n",
    "display(oligodendrogliomaslides_level_downsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T07:38:39.172530",
     "start_time": "2017-06-05T07:38:39.149511"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((89640, 70989), (22410, 17747), (5602, 4436), (2801, 2218)),\n",
       " ((147723, 69077), (36930, 17269), (9232, 4317), (2308, 1079)),\n",
       " ((65228, 28836), (16307, 7209), (4076, 1802)),\n",
       " ((178024, 58022), (44506, 14505), (11126, 3626), (2781, 906)),\n",
       " ((95924, 51658), (23981, 12914), (5995, 3228), (2997, 1614)),\n",
       " ((74821, 75577), (18705, 18894), (4676, 4723), (2338, 2361)),\n",
       " ((165949, 84949), (41487, 21237), (10371, 5309), (2592, 1327)),\n",
       " ((176501, 85030), (44125, 21257), (11031, 5314), (2757, 1328)),\n",
       " ((95924, 23008), (23981, 5752), (5995, 1438), (2997, 719)),\n",
       " ((27887, 37919), (6971, 9479), (1742, 2369)),\n",
       " ((47962, 34524), (11990, 8631), (2997, 2157)),\n",
       " ((84413, 83008), (21103, 20752), (5275, 5188), (2637, 2594)),\n",
       " ((94006, 79535), (23501, 19883), (5875, 4970), (2937, 2485)),\n",
       " ((70448, 34023), (17612, 8505), (4403, 2126), (2201, 1063)),\n",
       " ((151560, 76709), (37890, 19177), (9472, 4794), (2368, 1198)),\n",
       " ((27608, 29571), (6902, 7392), (1725, 1848))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[((84413, 67031), (21103, 16757), (5275, 4189), (2637, 2094)),\n",
       " ((80576, 78159), (20144, 19539), (5036, 4884), (2518, 2442)),\n",
       " ((59759, 51040), (14939, 12760), (3734, 3190), (1867, 1595)),\n",
       " ((119520, 57706), (29880, 14426), (7470, 3606), (3735, 1803)),\n",
       " ((71943, 68955), (17985, 17238), (4496, 4309), (2248, 2154)),\n",
       " ((107521, 45460), (26880, 11365), (6720, 2841), (3360, 1420)),\n",
       " ((73861, 84188), (18465, 21047), (4616, 5261), (2308, 2630)),\n",
       " ((113191, 42668), (28297, 10667), (7074, 2666), (3537, 1333)),\n",
       " ((111552, 63155), (27888, 15788), (6972, 3947), (3486, 1973)),\n",
       " ((41832, 39671), (10458, 9917), (2614, 2479)),\n",
       " ((100720, 32678), (25180, 8169), (6295, 2042), (3147, 1021)),\n",
       " ((26858, 16353), (6714, 4088), (3357, 2044)),\n",
       " ((146764, 82254), (36691, 20563), (9172, 5140), (2293, 1285)),\n",
       " ((124701, 46574), (31175, 11643), (7793, 2910), (3896, 1455)),\n",
       " ((16307, 19556), (4076, 4889), (2038, 2444)),\n",
       " ((172664, 84999), (43166, 21249), (10791, 5312), (2697, 1328))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell displays dimensions of slides on each level\n",
    "astrocytomaslides_level_dimensions = [astrocytomaslides[i].level_dimensions for i, slide in \n",
    "                                      enumerate(astrocytomaslides)]\n",
    "oligodendrogliomaslides_level_dimensions = [oligodendrogliomaslides[i].level_dimensions for i, slide in \n",
    "                                      enumerate(oligodendrogliomaslides)]\n",
    "\n",
    "\n",
    "display(astrocytomaslides_level_dimensions)\n",
    "display(oligodendrogliomaslides_level_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell displays SVS file properties Including original magnification\n",
    "astrocytomaslides_properties = [astrocytomaslides[i].properties for i, slide in \n",
    "                                      enumerate(astrocytomaslides)]\n",
    "\n",
    "oligodendrogliomaslides_properties = [oligodendrogliomaslides[i].properties for i, slide in \n",
    "                                      enumerate(oligodendrogliomaslides)]\n",
    "\n",
    "display(astrocytomaslides_properties)\n",
    "display(oligodendrogliomaslides_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T19:34:47.557718",
     "start_time": "2017-05-25T01:21:31.378Z"
    }
   },
   "source": [
    "### TCGA: Copy Raw images into patient directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T09:00:18.244804",
     "start_time": "2017-06-03T09:00:12.413047"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b5f4dafeb3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Copy TCGA images into directories for each patient. Skip this cell if this pre-processing has already been done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/*'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTCGA_raw_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/*'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/glob.py\u001b[0m in \u001b[0;36mglob1\u001b[0;34m(dirname, pattern)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Copy TCGA images into directories for each patient. Skip this cell if this pre-processing has already been done.\n",
    "\n",
    "dirs = glob('%s/*' % (TCGA_raw_data_dir,))\n",
    "for d in dirs:\n",
    "    file = glob('%s/*' % (d,))\n",
    "    file_name = file[0]\n",
    "    new_dir = file_name.split('/')[5][:12]\n",
    "    dir_name = TCGA_dirs + new_dir\n",
    "    \n",
    "    parms = 'cp %s %s' % (file_name, dir_name)\n",
    "    print('Creating directory', dir_name)\n",
    "    call(['mkdir', dir_name])\n",
    "    print('Copying svs file:', file_name, 'to:', dir_name)\n",
    "    call(parms, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-26T08:42:52.930267",
     "start_time": "2017-04-26T08:42:52.928144"
    }
   },
   "source": [
    "### Copy OpenSlide images to Tiff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T19:34:47.551489",
     "start_time": "2017-05-25T10:47:16.536578"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n",
      "Working on level: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-90437d6a9983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mparms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'time vips openslideload --level 0 %s %s%s.tiff[tile,compression=lzw]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#             print(parms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Copy all images to \"images\" directory as tiled tiff image. Use naming required for pre-processing.\n",
    "\n",
    "#CBTC images\n",
    "astro_files = glob(CBTC_A)\n",
    "oligo_files = glob(CBTC_O)\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    dest_dir = images_root_dir + 'level%s/' % (l, )\n",
    "\n",
    "    for a in astro_files:  \n",
    "        dest_file_name = 'img' + a.split('.')[0].split('/')[-1].split('_')[2]\n",
    "        print('Image being copied:', dest_file_name)\n",
    "        parms = 'time vips openslideload --level %s %s %s%s.tiff[tile,compression=lzw]' \\\n",
    "                % (l, a, dest_dir, dest_file_name)\n",
    "        print(parms)\n",
    "        call(parms, shell=True)\n",
    "            \n",
    "    for o in oligo_files:  \n",
    "        dest_file_name = 'img' + o.split('.')[0].split('/')[-1].split('_')[2]\n",
    "        print('Image being copied:', dest_file_name)\n",
    "        parms = 'time vips openslideload --level %s %s %s%s.tiff[tile,compression=lzw]' \\\n",
    "                % (l, a, dest_dir, dest_file_name)\n",
    "        print(parms)\n",
    "        call(parms, shell=True)\n",
    "    \n",
    "#TCGA images\n",
    "patient_dirs = glob('%s/TCGA*' % (TCGA_dirs,))\n",
    "\n",
    "for p in patient_dirs:\n",
    "    files = glob('%s/*.svs' % (p,))\n",
    "\n",
    "    for l in levels:\n",
    "        print('Working on level:', l)\n",
    "        \n",
    "        dest_dir = images_root_dir + 'level%s/' % (l, )\n",
    "        count = 0\n",
    "        for f in files:\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                dest_file_name = 'img' + f.split('.')[0].split('/')[-1].split('-')[2]\n",
    "                print('Image being copied:', dest_file_name)\n",
    "            else:\n",
    "                dest_file_name = 'img' + f.split('.')[0].split('/')[-1].split('-')[2] + 'b'\n",
    "                print('Image being copied:', dest_file_name)\n",
    "                \n",
    "            parms = 'time vips openslideload --level %s %s %s%s.tiff[tile,compression=lzw]' \\\n",
    "            % (l, f, dest_dir, dest_file_name)\n",
    "            \n",
    "            print(parms)\n",
    "            call(parms, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-25T19:34:47.557240",
     "start_time": "2017-05-25T01:16:58.737Z"
    }
   },
   "source": [
    "## Image Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBTC Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:21:44.232646",
     "start_time": "2017-06-06T13:21:44.223501"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CBTC Image indexes\n",
    "\n",
    "astro1 = [1,2,7,8,9,11,14,15,17,18,19,23,26,28,29,31]\n",
    "oligo1 = [3,4,5,6,10,12,13,16,20,21,22,24,25,27,30,32]\n",
    "images1 = [1,2,7,8,9,11,14,15,17,18,19,23,26,28,29,31,3,4,5,6,10,12,13,16,20,21,22,24,25,27,30,32]\n",
    "\n",
    "astro1 = [str(i) for i in astro1]\n",
    "oligo1 = [str(i) for i in oligo1]\n",
    "images1 = [str(i) for i in images1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:21:45.671547",
     "start_time": "2017-06-06T13:21:45.656391"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4938',\n",
      " '4938b',\n",
      " '4941',\n",
      " '4941b',\n",
      " '4942',\n",
      " '4942b',\n",
      " '4943',\n",
      " '4943b',\n",
      " '4944',\n",
      " '4944b',\n",
      " '5390',\n",
      " '5390b',\n",
      " '7902',\n",
      " '7902b',\n",
      " '7855',\n",
      " '7855b',\n",
      " '7299',\n",
      " '5963',\n",
      " '5963b',\n",
      " '5854',\n",
      " '5854b',\n",
      " '7694',\n",
      " '7694b',\n",
      " '7687',\n",
      " '6407',\n",
      " '6407b',\n",
      " '5964',\n",
      " '5964b',\n",
      " '7884',\n",
      " '7884b',\n",
      " '7301',\n",
      " '7301b',\n",
      " '5393',\n",
      " '5393b',\n",
      " '8164',\n",
      " '6666',\n",
      " '6666b',\n",
      " '8012',\n",
      " '8012b',\n",
      " '6692',\n",
      " '7693',\n",
      " '7693b',\n",
      " '7304',\n",
      " '7304b',\n",
      " '5849',\n",
      " '5849b',\n",
      " '7856',\n",
      " '7856b',\n",
      " '7879',\n",
      " '7879b',\n",
      " '7620',\n",
      " '7620b',\n",
      " '5395',\n",
      " '5395b',\n",
      " '7471',\n",
      " '7471b',\n",
      " '8165',\n",
      " '6410',\n",
      " '6410b',\n",
      " '8108',\n",
      " '7641',\n",
      " '7641b',\n",
      " '6669',\n",
      " '6669b',\n",
      " '7858',\n",
      " '7858b',\n",
      " '7302',\n",
      " '7302b',\n",
      " '7690',\n",
      " '7309',\n",
      " '7309b',\n",
      " '7875',\n",
      " '7875b',\n",
      " '6404',\n",
      " '6404b',\n",
      " '7467',\n",
      " '7467b',\n",
      " '8167',\n",
      " 'A6IZ',\n",
      " '7605',\n",
      " '7605b',\n",
      " '7470',\n",
      " '6408',\n",
      " '6408b',\n",
      " '7880',\n",
      " '7880b',\n",
      " '8019',\n",
      " '7860',\n",
      " '7860b',\n",
      " '8013',\n",
      " '8013b',\n",
      " '8168',\n",
      " 'A6J1',\n",
      " '7854',\n",
      " '7854b',\n",
      " '7611',\n",
      " '7611b',\n",
      " 'A6S2',\n",
      " '7477',\n",
      " 'A5TS',\n",
      " '7643',\n",
      " '7643b',\n",
      " '6690',\n",
      " '6690b',\n",
      " '7688',\n",
      " '7688b',\n",
      " '7298',\n",
      " '7298b',\n",
      " '6397',\n",
      " '6397b',\n",
      " '6691',\n",
      " '6691b',\n",
      " '7019',\n",
      " '7019b',\n",
      " '5396',\n",
      " '5396b',\n",
      " '8110',\n",
      " '8110b',\n",
      " 'A5TU',\n",
      " '7692',\n",
      " '7692b',\n",
      " '7677',\n",
      " '7677b',\n",
      " '6186',\n",
      " '6186b',\n",
      " '7480',\n",
      " '7480b',\n",
      " '7294',\n",
      " '7294b',\n",
      " '7608',\n",
      " '7608b',\n",
      " '7475',\n",
      " '7475b',\n",
      " '5397',\n",
      " '5397b',\n",
      " '5394',\n",
      " '5394b',\n",
      " '7479',\n",
      " '7479b',\n",
      " '6542',\n",
      " '6542b',\n",
      " '7609',\n",
      " '7609b',\n",
      " '6668',\n",
      " '6668b',\n",
      " '7481',\n",
      " '7481b',\n",
      " '8105',\n",
      " '8105b',\n",
      " '7877',\n",
      " '7877b',\n",
      " '7474',\n",
      " '7474b',\n",
      " '8109',\n",
      " '8109b',\n",
      " '7469',\n",
      " '7469b',\n",
      " '7476',\n",
      " '7476b',\n",
      " '5851',\n",
      " '8018',\n",
      " '8018b',\n",
      " '7882',\n",
      " '7882b',\n",
      " '6405',\n",
      " '6405b',\n",
      " '8163',\n",
      " '5855',\n",
      " '5855b',\n",
      " '7610',\n",
      " '7681',\n",
      " '7681b',\n",
      " '7008',\n",
      " '7008b',\n",
      " '8186',\n",
      " '8186b',\n",
      " '7616',\n",
      " '7616b',\n",
      " '8107',\n",
      " '8107b',\n",
      " 'A87N',\n",
      " 'A5TY',\n",
      " '6400',\n",
      " '6400b',\n",
      " '8010',\n",
      " '8010b',\n",
      " 'A5TR',\n",
      " '7014',\n",
      " '7014b',\n",
      " '6667',\n",
      " '7473',\n",
      " '7473b',\n",
      " '7634',\n",
      " '7634b',\n",
      " 'A4MT',\n",
      " 'A4MTb',\n",
      " '7606',\n",
      " '7606b',\n",
      " '7015',\n",
      " '7015b',\n",
      " '7637',\n",
      " '7637b',\n",
      " 'A713',\n",
      " '6401',\n",
      " '6401b',\n",
      " '8011',\n",
      " '8011b',\n",
      " '7684',\n",
      " '7684b',\n",
      " '7482',\n",
      " '7482b',\n",
      " '7874',\n",
      " '7874b',\n",
      " '7018',\n",
      " '7018b',\n",
      " '7680',\n",
      " '7680b',\n",
      " 'A60K',\n",
      " '7695',\n",
      " '7010',\n",
      " '7010b',\n",
      " '5965',\n",
      " '5965b',\n",
      " '7857',\n",
      " '7857b',\n",
      " 'A6S3',\n",
      " '7881',\n",
      " '7881b',\n",
      " 'A5TT',\n",
      " '5871',\n",
      " '5871b',\n",
      " '7689',\n",
      " '7689b',\n",
      " 'A5TP',\n",
      " '7602',\n",
      " '5874',\n",
      " '5874b',\n",
      " '7601',\n",
      " '7601b',\n",
      " '7686',\n",
      " '7686b',\n",
      " '8106',\n",
      " '8106b',\n",
      " '6290',\n",
      " '8166',\n",
      " '5853',\n",
      " '5853b',\n",
      " '5872',\n",
      " '5872b',\n",
      " '7472',\n",
      " '7472b',\n",
      " '7478',\n",
      " '7478b',\n",
      " '6402',\n",
      " '6402b',\n",
      " '7676',\n",
      " '7676b',\n",
      " '7873',\n",
      " '7873b',\n",
      " '6395',\n",
      " '6395b',\n",
      " '6399',\n",
      " '6399b',\n",
      " 'A4MU',\n",
      " '7603',\n",
      " '6689',\n",
      " '6689b',\n",
      " '8158',\n",
      " 'A6S6',\n",
      " 'A5TW',\n",
      " '5852',\n",
      " '5852b',\n",
      " 'A6S8',\n",
      " '7013',\n",
      " '7013b',\n",
      " '8104',\n",
      " '8104b',\n",
      " '7306',\n",
      " '7306b',\n",
      " '6688',\n",
      " '6688b',\n",
      " '7607',\n",
      " '6188',\n",
      " '6188b',\n",
      " '8189',\n",
      " '7691',\n",
      " '7691b',\n",
      " '8015',\n",
      " '8162',\n",
      " '7485',\n",
      " '7485b',\n",
      " 'A6S7']\n"
     ]
    }
   ],
   "source": [
    "#Build TCGA new_image list based on actual images in directory\n",
    "\n",
    "img_files = glob('%s/*.tiff' % (images_root_dir + 'level%s/' % (l, )))\n",
    "new_images = []\n",
    "for i in img_files:\n",
    "    img_ = i.split('.')[0].split('/')[-1].split('img')[1]\n",
    "    if \"_\" not in img_ and len(img_)>2:\n",
    "        new_image = img_\n",
    "        new_images.append(new_image)\n",
    "pprint(new_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:21:47.793111",
     "start_time": "2017-06-06T13:21:47.298519"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TCGA index of patients to cancer types based on Patient_info.txt (describing download from TCGA site)\n",
    "\n",
    "patients = open(patient_info, \"r\")\n",
    "lines = patients.read().split(' ')\n",
    "# pprint(lines)\n",
    "\n",
    "cancer_types = []\n",
    "cancer_grades = []\n",
    "patients = []\n",
    "for line in lines:\n",
    "    #Handle a couple of lines out of alignment\n",
    "    if \"TCGA-DU-6407\" in line:\n",
    "        phrases = line.split()\n",
    "        patient = phrases[-7].split('-')[2]\n",
    "        cancer_type = phrases[-5]\n",
    "        cancer_grade = phrases[-4]\n",
    "    elif \"TCGA-HT-7603\" in line:\n",
    "        phrases = line.split()\n",
    "        patient = phrases[-5].split('-')[2]\n",
    "        cancer_type = phrases[-3]\n",
    "        cancer_grade = phrases[-2]\n",
    "    #Remainder of dataset\n",
    "    elif \"TCGA\" in line:\n",
    "        phrases = line.split()\n",
    "        patient = phrases[-6].split('-')[2]\n",
    "        cancer_type = phrases[-4]\n",
    "        cancer_grade = phrases[-3]\n",
    "\n",
    "        patients.append(patient)\n",
    "        cancer_types.append(cancer_type)\n",
    "        cancer_grades.append(cancer_grade)\n",
    "\n",
    "#Convert to dataframe with all subtypes and grades included\n",
    "cancer = [('patient', patients), ('cancer subtype', cancer_types), ('cancer grade', cancer_grades)]\n",
    "cancer_df = pd.DataFrame.from_items(cancer)\n",
    "\n",
    "oligo2_df = cancer_df.loc[cancer_df['cancer subtype'] == 'Oligodendroglioma']\n",
    "astro2_df = cancer_df.loc[cancer_df['cancer subtype'] == 'Astrocytoma']\n",
    "mixed_df = cancer_df.loc[cancer_df['cancer subtype'] == 'Oligoastrocytoma']\n",
    "\n",
    "# Create index for subsets of images with G2 only\n",
    "astro2_g2_df = astro2_df.loc[astro2_df['cancer grade'] == 'G2']\n",
    "oligo2_g2_df = oligo2_df.loc[oligo2_df['cancer grade'] == 'G2']\n",
    "\n",
    "# Update index to remove images not actually available\n",
    "#Balance dataset between astro and oligo (52 images each)\n",
    "oligo2_test_df = oligo2_df[oligo2_df['patient'].isin(new_images)][52:]\n",
    "astro2_df = astro2_df[astro2_df['patient'].isin(new_images)]\n",
    "oligo2_df = oligo2_df[oligo2_df['patient'].isin(new_images)][:52]\n",
    "mixed_df = mixed_df[mixed_df['patient'].isin(new_images)]\n",
    "\n",
    "astro2_g2_df = astro2_g2_df.loc[astro2_g2_df['patient'].isin(new_images)]\n",
    "oligo2_g2_df = oligo2_g2_df.loc[oligo2_g2_df['patient'].isin(new_images)][:19]\n",
    "\n",
    "#Build astro2a, oligo2a, mixed2a lists\n",
    "astro2a = astro2_df['patient'].tolist()\n",
    "oligo2a = oligo2_df['patient'].tolist()\n",
    "oligo2a_test = oligo2_test_df['patient'].tolist()\n",
    "mixed2a = mixed_df['patient'].tolist()\n",
    "\n",
    "astro2a_g2 = astro2_g2_df['patient'].tolist()\n",
    "astro2a_test_g2 = astro2_g2_df['patient'].tolist()\n",
    "oligo2a_g2 = oligo2_g2_df['patient'].tolist()\n",
    "\n",
    "images2a = astro2a + oligo2a\n",
    "images2a_g2 = astro2a_g2 + oligo2a_g2\n",
    "\n",
    "images = images1 + images2a\n",
    "\n",
    "#Produce index for second image for each patient (note there is not always a second image)\n",
    "astro2b = []\n",
    "oligo2b = []\n",
    "#astro2a reflects patients - add 'b' to get second image for that patient\n",
    "for i,j in zip(astro2a,oligo2a):\n",
    "    ab = i + 'b'\n",
    "    ob = j + 'b'\n",
    "    astro2b.append(ab)\n",
    "    oligo2b.append(ob)\n",
    "\n",
    "#Select only files that exist on disk (some patients only have 1 file)\n",
    "astro2b_df = pd.DataFrame(astro2b)\n",
    "astro2b_df = astro2b_df[astro2b_df.isin(new_images)]\n",
    "#Balance dataset between astro and oligo (38 \"b\" images each)\n",
    "astro2b = astro2b_df.dropna()[0].tolist()[:38]\n",
    "\n",
    "oligo2b_df = pd.DataFrame(oligo2b)\n",
    "oligo2b_df = oligo2b_df[oligo2b_df.isin(new_images)]\n",
    "oligo2b = oligo2b_df.dropna()[0].tolist()\n",
    "\n",
    "images2b = astro2b + oligo2b\n",
    "\n",
    "#Display indices\n",
    "display(len(astro1))\n",
    "display(len(oligo1))\n",
    "display(len(images))\n",
    "\n",
    "display(len(astro2a))\n",
    "display(len(oligo2a))\n",
    "display(len(images2a))\n",
    "\n",
    "display(len(astro2b))\n",
    "display(len(oligo2b))\n",
    "display(len(images2b))\n",
    "\n",
    "display(len(mixed2a))\n",
    "\n",
    "# These indices may be varied for processing depending on need.\n",
    "# For example the following was used to omit images with too few tiles that would cause an error in clustering:\n",
    "# E.g. images2a = [i for i in images2a if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:41:42.965116",
     "start_time": "2017-06-05T14:41:42.935943"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(19, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(17, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(52, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(52, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Chack balance of TCGA dataset\n",
    "display(oligo2_df.loc[oligo2_df['cancer grade'] == 'G1'].shape)\n",
    "display(oligo2_df.loc[oligo2_df['cancer grade'] == 'G2'].shape)\n",
    "display(oligo2_df.loc[oligo2_df['cancer grade'] == 'G3'].shape)\n",
    "display(astro2_df.loc[astro2_df['cancer grade'] == 'G1'].shape)\n",
    "display(astro2_df.loc[astro2_df['cancer grade'] == 'G2'].shape)\n",
    "display(astro2_df.loc[astro2_df['cancer grade'] == 'G3'].shape)\n",
    "display(astro2_df.shape)\n",
    "display(oligo2_df.shape)\n",
    "display(astro2b_df.shape)\n",
    "display(oligo2b_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Image Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T07:31:50.350736",
     "start_time": "2017-06-02T07:31:50.247039"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function removes background from each image -- and does the writing to disk of \"img-fg\" \n",
    "#(original tiles unchanged)\n",
    "\n",
    "def remove_background(img, img_to_read, img_to_write, l):  \n",
    "\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    #Read\n",
    "    print('Reading image', img, 'level', l)\n",
    "    img_base = cv2.imread(img_to_read)\n",
    "    \n",
    "    print('Masking background..')\n",
    "    #Downsize to level3 to derive mask\n",
    "    scale = {1:8, 2:2, 3:1, 4:.5}\n",
    "    dim = (int(img_base.shape[1]/scale[l]), int(img_base.shape[0]/scale[l]))\n",
    "    img_l3 = cv2.resize(img_base, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_l3 = cv2.cvtColor(img_l3, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Remove background using Thresholding and Floodfill\n",
    "    _, img_l3_threshold = cv2.threshold(img_l3, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "    mask = np.zeros((img_l3_threshold.shape[0]+2, img_l3_threshold.shape[1]+2), np.uint8)\n",
    "    img_l3_floodfill = img_l3_threshold.copy()\n",
    "    cv2.floodFill(img_l3_floodfill, mask, (0,0), 255)\n",
    "    img_l3_floodfill_inverted = cv2.bitwise_not(img_l3_floodfill)\n",
    "    img_l3_fg = img_l3_threshold | img_l3_floodfill_inverted\n",
    "    \n",
    "    #Check Image sizes\n",
    "    d1 = img_base.shape[1] - int(img_l3_fg.shape[1]*scale[l]) \n",
    "    d0 = img_base.shape[0] - int(img_l3_fg.shape[0]*scale[l])\n",
    "    \n",
    "    #Upsize mask to fit base image\n",
    "    mask_dim = (int(img_l3_fg.shape[1]*scale[l])+d1, int(img_l3_fg.shape[0]*scale[l])+d0)\n",
    "    mask_fg = cv2.resize(img_l3_fg, mask_dim, interpolation = cv2.INTER_AREA)\n",
    "    mask_fg = np.repeat(mask_fg[:, :, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    #Apply foreground mask to base image\n",
    "    img_fg = cv2.bitwise_and(img_base, mask_fg)\n",
    "    \n",
    "    #Print Image sizes\n",
    "    display(mask_fg.shape)\n",
    "    display(img_fg.shape)\n",
    "    display(d1)\n",
    "    display(d0)\n",
    "    \n",
    "    #Write\n",
    "    print('Writing Foreground Image', img_to_write, 'for level:', l)\n",
    "    cv2.imwrite(img_to_write, img_fg)\n",
    "    \n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T07:31:51.448817",
     "start_time": "2017-06-02T07:31:51.433197"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function calculates the amount of tissue per tile\n",
    "\n",
    "def calculate_tissue_percentage(tile):\n",
    "    \n",
    "    #Sample background and iterate through image colours\n",
    "    img = Image.open(tile)\n",
    "    background = img.getpixel((0,0))\n",
    "    width, height = img.size\n",
    "    background_amount = next(count for count,colour in img.getcolors(width*height) if colour==background)\n",
    "    \n",
    "    #Calculations\n",
    "    tissue_amount = width*height - background_amount\n",
    "    tissue_percent = tissue_amount*100.0/width/height\n",
    "    \n",
    "    return(tissue_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T07:31:52.624306",
     "start_time": "2017-06-02T07:31:52.588876"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function determines the tile numbers to use -- and does the wrting to disk of \"tile_array\"\n",
    "\n",
    "def prepare_tiles(img, files, files_fg, tile_array_to_write):\n",
    "\n",
    "    print('Selecting tiles with large tissue proportion for Image:', img)\n",
    "    print(len(files), 'tiles being processed for image', img, 'on level', l)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    tile_list = []\n",
    "    for file, file_fg in zip(files, files_fg):\n",
    "        #Use tile only if it contains at least 80% tissue\n",
    "        tissue_percent = calculate_tissue_percentage(file_fg)\n",
    "        if l == 1:\n",
    "            if tissue_percent >= 80:\n",
    "                #Load tiles, preprocess and stack into an array\n",
    "                tile = load_img(file, target_size=(224, 224))\n",
    "                tile = img_to_array(tile)\n",
    "                tile = preprocess_input(tile)\n",
    "                tile_list.append(tile) \n",
    "        elif l == 2:\n",
    "            if tissue_percent >= 60:\n",
    "                #Load tiles, preprocess and stack into an array\n",
    "                tile = load_img(file, target_size=(224, 224))\n",
    "                tile = img_to_array(tile)\n",
    "                tile = preprocess_input(tile)\n",
    "                tile_list.append(tile)\n",
    "        elif l == 3:\n",
    "                #Load tiles, preprocess and stack into an array\n",
    "                tile = load_img(file, target_size=(224, 224))\n",
    "                tile = img_to_array(tile)\n",
    "                tile = preprocess_input(tile)\n",
    "                tile_list.append(tile)\n",
    "    tile_array = np.stack(tile_list, axis=0)\n",
    "    print(tile_array.shape[0], 'tiles selected from image', img, 'on level', l)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    #Save tile array for this image to disk\n",
    "    print('Saving selected tiles for Image:', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    np.save(tile_array_to_write, tile_array)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Image Preparation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-25T13:52:18.037761",
     "start_time": "2017-04-25T13:52:18.033293"
    }
   },
   "source": [
    "### Remove Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T08:14:06.580283",
     "start_time": "2017-06-03T08:13:55.964908"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Start time:  2017-06-03 08:13:55\n",
      "Reading image img5396b level 1\n",
      "Masking background..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4399, 7378, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4399, 7378, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Foreground Image /Volumes/2T_HD/Masters_Project/images/level1/img_fg5396b.tiff for level: 1\n",
      "End time:  2017-06-03 08:14:06\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This cell saves to disk background-removed tiles \"img-fg\" -- used to select tiles for processing\n",
    "\n",
    "#Select desired index (currently set to original CBTC images)\n",
    "for i in images:\n",
    "    print('Working on level:', l)\n",
    "\n",
    "    for l in levels:\n",
    "        img = 'img%s' % (i,)\n",
    "        img_to_read = images_root_dir + 'level%s/img%s.tiff' % (l, i)\n",
    "        img_to_write = images_root_dir + 'level%s/img_fg%s.tiff' % (l, i)\n",
    "        remove_background(img, img_to_read, img_to_write, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-25T18:50:20.430116",
     "start_time": "2017-04-25T08:31:57.578Z"
    }
   },
   "source": [
    "### Perform interactive tiling of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T08:15:18.243718",
     "start_time": "2017-06-03T08:15:18.225162"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Start time:  2017-06-03 08:15:18\n",
      "time vips dzsave /Volumes/2T_HD/Masters_Project/images/level1/img5396b.tiff img5396b --depth one --tile-size 224 --overlap 0 --suffix .jpg\n",
      "End time:  2017-06-03 08:15:18\n",
      "Start time:  2017-06-03 08:15:18\n",
      "time vips dzsave /Volumes/2T_HD/Masters_Project/images/level1/img_fg5396b.tiff /Volumes/2T_HD/Masters_Project/images/level1/img_fg5396b --depth one --tile-size 224 --overlap 0 --suffix .jpg\n",
      "End time:  2017-06-03 08:15:18\n"
     ]
    }
   ],
   "source": [
    "#This cell uses vips dzsave to tile images and copy them into a subdirectory: images_root_dir/level/0/imagename_files\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    dir = images_root_dir + 'level%s/' % (l, )\n",
    "    \n",
    "    for i in images:\n",
    "        \n",
    "        parms1 = 'time vips dzsave %simg%s.tiff %simg%s --depth one --tile-size 224 --overlap 0 --suffix .jpg' % (dir, i, dir, i)\n",
    "        parms2 = 'time vips dzsave %simg_fg%s.tiff %simg_fg%s --depth one --tile-size 224 --overlap 0 --suffix .jpg' % (dir, i, dir, i)\n",
    "        \n",
    "        print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print(parms1)\n",
    "        call(parms1, shell=True)\n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print(parms2)\n",
    "        call(parms2, shell=True)\n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T08:16:25.782856",
     "start_time": "2017-06-03T08:16:07.803497"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Selecting tiles with large tissue proportion for Image: img5396b\n",
      "660 tiles being processed for image img5396b on level 1\n",
      "Start time:  2017-06-03 08:16:07\n",
      "427 tiles selected from image img5396b on level 1\n",
      "End time:  2017-06-03 08:16:21\n",
      "Saving selected tiles for Image: img5396b\n",
      "Start time:  2017-06-03 08:16:21\n",
      "End time:  2017-06-03 08:16:25\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This cell lists tile jpegs for images, and calls functions that check tissue percentage, loads tile if greater \n",
    "# than 80% tissue, preprocesses the tile, and saves all tiles for image to disk in a numpy array \"tile_array\". \n",
    "# It also prints out the number of tiles in the image which is important if the number is smaller than number \n",
    "# to be selected in later stages (e.g. clustering) for further procesing\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    for i in images:\n",
    "        #Set names\n",
    "        img = 'img%s' % (i,)\n",
    "        dir = images_root_dir + 'level%s/img%s_files' % (l, i)\n",
    "        files = glob('%s/0/*.jpg' % (dir,))\n",
    "        dir_fg = images_root_dir + 'level%s/img_fg%s_files' % (l, i)\n",
    "        files_fg = glob('%s/0/*.jpg' % (dir_fg,))\n",
    "        tile_array_to_write = images_root_dir + 'level%s/img%s_files/tile_array' % (l, i)\n",
    "        prepare_tiles(img, files, files_fg, tile_array_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Feature Extraction using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T09:48:45.884528",
     "start_time": "2017-06-03T09:48:45.872428"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function writes to disk the \"tile_features\" array -- including features extracted from ResNet50 for each tile.\n",
    "\n",
    "def extract_features(img, tile_array_to_read, features_to_write):\n",
    "    \n",
    "    #Extract features for this image from top layer of Resnet50 model\n",
    "    print('Extracting features for Image:', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    tile_array = np.load(tile_array_to_read)\n",
    "    tile_features = ResNet50_model.predict(tile_array)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    #Save features to disk\n",
    "    print('Saving features for Image:', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    np.save(features_to_write, tile_features)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')bl\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gather tuned features\n",
    "# cnn_model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "# tuned_features = cnn_model.predict(X_astro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive CNN Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:28:10.272202",
     "start_time": "2017-06-06T13:27:53.445879"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download Resnet50\n",
    "ResNet50_model = ResNet50(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-04T20:14:27.501779",
     "start_time": "2017-06-04T20:14:27.495772"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 zero_padding2d_1\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 max_pooling2d_1\n",
      "6 res2a_branch2a\n",
      "7 bn2a_branch2a\n",
      "8 activation_2\n",
      "9 res2a_branch2b\n",
      "10 bn2a_branch2b\n",
      "11 activation_3\n",
      "12 res2a_branch2c\n",
      "13 res2a_branch1\n",
      "14 bn2a_branch2c\n",
      "15 bn2a_branch1\n",
      "16 add_1\n",
      "17 activation_4\n",
      "18 res2b_branch2a\n",
      "19 bn2b_branch2a\n",
      "20 activation_5\n",
      "21 res2b_branch2b\n",
      "22 bn2b_branch2b\n",
      "23 activation_6\n",
      "24 res2b_branch2c\n",
      "25 bn2b_branch2c\n",
      "26 add_2\n",
      "27 activation_7\n",
      "28 res2c_branch2a\n",
      "29 bn2c_branch2a\n",
      "30 activation_8\n",
      "31 res2c_branch2b\n",
      "32 bn2c_branch2b\n",
      "33 activation_9\n",
      "34 res2c_branch2c\n",
      "35 bn2c_branch2c\n",
      "36 add_3\n",
      "37 activation_10\n",
      "38 res3a_branch2a\n",
      "39 bn3a_branch2a\n",
      "40 activation_11\n",
      "41 res3a_branch2b\n",
      "42 bn3a_branch2b\n",
      "43 activation_12\n",
      "44 res3a_branch2c\n",
      "45 res3a_branch1\n",
      "46 bn3a_branch2c\n",
      "47 bn3a_branch1\n",
      "48 add_4\n",
      "49 activation_13\n",
      "50 res3b_branch2a\n",
      "51 bn3b_branch2a\n",
      "52 activation_14\n",
      "53 res3b_branch2b\n",
      "54 bn3b_branch2b\n",
      "55 activation_15\n",
      "56 res3b_branch2c\n",
      "57 bn3b_branch2c\n",
      "58 add_5\n",
      "59 activation_16\n",
      "60 res3c_branch2a\n",
      "61 bn3c_branch2a\n",
      "62 activation_17\n",
      "63 res3c_branch2b\n",
      "64 bn3c_branch2b\n",
      "65 activation_18\n",
      "66 res3c_branch2c\n",
      "67 bn3c_branch2c\n",
      "68 add_6\n",
      "69 activation_19\n",
      "70 res3d_branch2a\n",
      "71 bn3d_branch2a\n",
      "72 activation_20\n",
      "73 res3d_branch2b\n",
      "74 bn3d_branch2b\n",
      "75 activation_21\n",
      "76 res3d_branch2c\n",
      "77 bn3d_branch2c\n",
      "78 add_7\n",
      "79 activation_22\n",
      "80 res4a_branch2a\n",
      "81 bn4a_branch2a\n",
      "82 activation_23\n",
      "83 res4a_branch2b\n",
      "84 bn4a_branch2b\n",
      "85 activation_24\n",
      "86 res4a_branch2c\n",
      "87 res4a_branch1\n",
      "88 bn4a_branch2c\n",
      "89 bn4a_branch1\n",
      "90 add_8\n",
      "91 activation_25\n",
      "92 res4b_branch2a\n",
      "93 bn4b_branch2a\n",
      "94 activation_26\n",
      "95 res4b_branch2b\n",
      "96 bn4b_branch2b\n",
      "97 activation_27\n",
      "98 res4b_branch2c\n",
      "99 bn4b_branch2c\n",
      "100 add_9\n",
      "101 activation_28\n",
      "102 res4c_branch2a\n",
      "103 bn4c_branch2a\n",
      "104 activation_29\n",
      "105 res4c_branch2b\n",
      "106 bn4c_branch2b\n",
      "107 activation_30\n",
      "108 res4c_branch2c\n",
      "109 bn4c_branch2c\n",
      "110 add_10\n",
      "111 activation_31\n",
      "112 res4d_branch2a\n",
      "113 bn4d_branch2a\n",
      "114 activation_32\n",
      "115 res4d_branch2b\n",
      "116 bn4d_branch2b\n",
      "117 activation_33\n",
      "118 res4d_branch2c\n",
      "119 bn4d_branch2c\n",
      "120 add_11\n",
      "121 activation_34\n",
      "122 res4e_branch2a\n",
      "123 bn4e_branch2a\n",
      "124 activation_35\n",
      "125 res4e_branch2b\n",
      "126 bn4e_branch2b\n",
      "127 activation_36\n",
      "128 res4e_branch2c\n",
      "129 bn4e_branch2c\n",
      "130 add_12\n",
      "131 activation_37\n",
      "132 res4f_branch2a\n",
      "133 bn4f_branch2a\n",
      "134 activation_38\n",
      "135 res4f_branch2b\n",
      "136 bn4f_branch2b\n",
      "137 activation_39\n",
      "138 res4f_branch2c\n",
      "139 bn4f_branch2c\n",
      "140 add_13\n",
      "141 activation_40\n",
      "142 res5a_branch2a\n",
      "143 bn5a_branch2a\n",
      "144 activation_41\n",
      "145 res5a_branch2b\n",
      "146 bn5a_branch2b\n",
      "147 activation_42\n",
      "148 res5a_branch2c\n",
      "149 res5a_branch1\n",
      "150 bn5a_branch2c\n",
      "151 bn5a_branch1\n",
      "152 add_14\n",
      "153 activation_43\n",
      "154 res5b_branch2a\n",
      "155 bn5b_branch2a\n",
      "156 activation_44\n",
      "157 res5b_branch2b\n",
      "158 bn5b_branch2b\n",
      "159 activation_45\n",
      "160 res5b_branch2c\n",
      "161 bn5b_branch2c\n",
      "162 add_15\n",
      "163 activation_46\n",
      "164 res5c_branch2a\n",
      "165 bn5c_branch2a\n",
      "166 activation_47\n",
      "167 res5c_branch2b\n",
      "168 bn5c_branch2b\n",
      "169 activation_48\n",
      "170 res5c_branch2c\n",
      "171 bn5c_branch2c\n",
      "172 add_16\n",
      "173 activation_49\n",
      "174 avg_pool\n"
     ]
    }
   ],
   "source": [
    "# View ReNet50 layers\n",
    "for i, layer in enumerate(ResNet50_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-25T15:30:13.342778",
     "start_time": "2017-04-25T15:30:13.340599"
    }
   },
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T22:34:57.576123",
     "start_time": "2017-06-02T22:34:38.381324"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "img4938b already processed\n",
      "img4941b already processed\n",
      "img4942b already processed\n",
      "img4943b already processed\n",
      "img4944b already processed\n",
      "img5393b already processed\n",
      "img5394b already processed\n",
      "img5397b already processed\n",
      "img6188b already processed\n",
      "img6666b already processed\n",
      "img5854b already processed\n",
      "img6402b already processed\n",
      "img6405b already processed\n",
      "img7010b already processed\n",
      "img7013b already processed\n",
      "img7298b already processed\n",
      "img5963b already processed\n",
      "img6688b already processed\n",
      "img6689b already processed\n",
      "img6691b already processed\n",
      "img7476b already processed\n",
      "img7478b already processed\n",
      "img7479b already processed\n",
      "img7485b already processed\n",
      "img7601b already processed\n",
      "img7606b already processed\n",
      "img7680b already processed\n",
      "img7686b already processed\n",
      "img7691b already processed\n",
      "img7854b already processed\n",
      "img7855b already processed\n",
      "img7857b already processed\n",
      "img7858b already processed\n",
      "img7860b already processed\n",
      "img7884b already processed\n",
      "img8011b already processed\n",
      "img8104b already processed\n",
      "img8106b already processed\n",
      "Image features extracted from ResNet50 will be written to: /Volumes/2T_HD/Masters_Project/images/level1/img5390b_files/tile_features.npy\n",
      "Extracting features for Image: img5390b\n",
      "Start time:  2017-06-02 22:34:39\n",
      "End time:  2017-06-02 22:34:50\n",
      "Saving features for Image: img5390b\n",
      "Start time:  2017-06-02 22:34:50\n",
      "End time:  2017-06-02 22:34:51\n",
      "_________________________________________\n",
      "Image features extracted from ResNet50 will be written to: /Volumes/2T_HD/Masters_Project/images/level1/img5395b_files/tile_features.npy\n",
      "Extracting features for Image: img5395b\n",
      "Start time:  2017-06-02 22:34:52\n",
      "End time:  2017-06-02 22:34:57\n",
      "Saving features for Image: img5395b\n",
      "Start time:  2017-06-02 22:34:57\n",
      "End time:  2017-06-02 22:34:57\n",
      "_________________________________________\n",
      "Image features extracted from ResNet50 will be written to: /Volumes/2T_HD/Masters_Project/images/level1/img5396b_files/tile_features.npy\n",
      "Extracting features for Image: img5396b\n",
      "Start time:  2017-06-02 22:34:57\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/2T_HD/Masters_Project/images/level1/img5396b_files/tile_array.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-393e2755c64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_to_write\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image features extracted from ResNet50 will be written to:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_to_write\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_array_to_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_to_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'already processed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-07c50d117c8b>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(img, tile_array_to_read, features_to_write)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting features for Image:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start time: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtile_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_array_to_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtile_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End time: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/2T_HD/Masters_Project/images/level1/img5396b_files/tile_array.npy'"
     ]
    }
   ],
   "source": [
    "# This step is very long running (8+ hours).\n",
    "\n",
    "# This step calls a function that extracts features from ResNet50 for each tile -- and writes 4D feature tensor \n",
    "# to disk in the \"tile_features\" numpy array. \n",
    "# Since no training is involved, all features can be extracted and saved ahead of time to allow for \n",
    "# quicker machine learning runs. \n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    for i in images:\n",
    "        \n",
    "        img = 'img%s' % (i,)\n",
    "        tile_array_to_read = images_root_dir + 'level%s/img%s_files/tile_array.npy' % (l, i)\n",
    "        features_to_write = images_root_dir + 'level%s/img%s_files/tile_features' % (l, i)\n",
    "        \n",
    "        if not path.exists(features_to_write + '.npy'):\n",
    "            print('Image features extracted from ResNet50 will be written to:', features_to_write + '.npy')\n",
    "            extract_features(img, tile_array_to_read, features_to_write)\n",
    "        else:\n",
    "            print(img, 'already processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Tile Clustering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-26T07:27:55.143069",
     "start_time": "2017-05-26T07:27:55.090259"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function performs SVD and calculates retained variance -- and writes to disk of \"U\", \"s\", \"V\", \"V_k\"\n",
    "\n",
    "def perform_SVD(img, features_to_read, K, U_to_write, s_to_write, V_to_write, V_k_to_write):\n",
    "    \n",
    "    #Load saved Features\n",
    "    print('Loading Saved Features for Image', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    tile_features = np.load(features_to_read)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "    #PCA\n",
    "    print('Starting PCA for Features of Image', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    U, s, V  = np.linalg.svd(tile_features[:,0,0,:])\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    #Retained Variance\n",
    "    sum_evals = sum(s)\n",
    "    print(sum_evals)\n",
    "    retained_variance = [(i / sum_evals)*100 for i in s]\n",
    "    cum_rv = np.cumsum(retained_variance)\n",
    "    k_values = [1, 2, 5, 10, 20, 100]\n",
    "    \n",
    "    [print('For', k, 'features, SVD retained variance is:', str(int(cum_rv[k])) + '%') for k in k_values]\n",
    "    \n",
    "    #Create reduced matrix V_k\n",
    "    V_k = V[:,:K]\n",
    "    \n",
    "#     print('Features shape',tile_features.shape)\n",
    "#     print('tile features V_k',tile_features.dot(V_k).shape)\n",
    "#     print('V shape',V.shape)\n",
    "#     print('U shape',U.shape)\n",
    "#     print('s shape',s.shape)\n",
    "#     print('V_k shape',V_k.shape)\n",
    "    \n",
    "    #Save matrices to disk\n",
    "    print('Saving Decomposed Matrices for Features of Image', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    np.save(U_to_write, U)\n",
    "    np.save(s_to_write, s)\n",
    "    np.save(V_to_write, V)\n",
    "    np.save(V_k_to_write, V_k)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-27T22:10:10.420602",
     "start_time": "2017-05-27T22:10:10.325018"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function saves to disk the \"closest_tiles\" array per image serving as an index of closest tiles to be used. \n",
    "\n",
    "def perform_feature_clustering(img, n_clusters, n_closest_tiles, X, closest_tiles_to_write, \\\n",
    "    remove_top_cluster, keep_only_top_cluster, remove_largest_clusters, new_tile_features_to_write):\n",
    "    \n",
    "    #Clustering\n",
    "    print('Starting cluster analysis for features of image', img)\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    labels = kmeans.predict(X)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    \n",
    "    print(\"For number of clusters =\", n_clusters,\n",
    "          \"The silhouette score is :\", silhouette_avg)\n",
    "    \n",
    "    cluster_silhouettes_averages = []\n",
    "    closest_tiles_list = []\n",
    "    cluster_sizes = []\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        closest, _ = pairwise_distances_argmin_min(centers[[i]], X)\n",
    "        #Tile index that would sort in ascending order of distances (minimum first)\n",
    "        closest_tiles_array = np.argsort(pairwise_distances(centers, X))[i, :n_closest_tiles]\n",
    "        #Silhouette average of all sihouettes within cluster\n",
    "        cluster_silhouette_avg = np.mean(silhouette_samples(X, labels)[labels == i])\n",
    "        \n",
    "        closest_tiles_list.append(closest_tiles_array)\n",
    "        cluster_silhouettes_averages.append(cluster_silhouette_avg)\n",
    "        \n",
    "        cluster_sizes.append(X[labels == i].shape[0])\n",
    "    \n",
    "    closest_tiles = np.stack(closest_tiles_list, axis=0)\n",
    "    \n",
    "    top_cluster_index = np.argmax(cluster_silhouettes_averages)\n",
    "    worst_cluster_index = np.argmin(cluster_silhouettes_averages)\n",
    "    largest_cluster_index = np.argmax(cluster_sizes)\n",
    "    second_largest_cluster_index = np.argsort(cluster_sizes)[-2]\n",
    "\n",
    "    print('The', n_clusters, 'ave cluster silhouettes are:', cluster_silhouettes_averages)\n",
    "    print('')\n",
    "    print('The best cluster is:', top_cluster_index)\n",
    "    print('The worst cluster is:', worst_cluster_index)\n",
    "    print('The largest cluster is:', np.argmax(cluster_sizes))\n",
    "    print('')\n",
    "    print('Closest tiles for best cluster', top_cluster_index, ':', closest_tiles[top_cluster_index])\n",
    "    print('Closest tiles for worst cluster', worst_cluster_index, ':', closest_tiles[worst_cluster_index])\n",
    "    print('Closest tiles for largest cluster', np.argmax(cluster_sizes), ':', closest_tiles[largest_cluster_index])\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "            print('Number of tiles in cluster', i, 'is:', X[labels == i].shape[0]) #<-- size of cluster\n",
    "    \n",
    "    if remove_top_cluster == 'yes':\n",
    "#         closest_tiles = np.delete(closest_tiles, top_cluster_index, 0)\n",
    "#         print('Closest tiles new shape:', closest_tiles.shape)\n",
    "        new_tiles_features = X[labels != top_cluster_index]\n",
    "        np.save(new_tile_features_to_write, new_tile_features)\n",
    "        print('Removing tiles from the top cluster...')\n",
    "        \n",
    "    elif keep_only_top_cluster == 'yes':\n",
    "#         closest_tiles = closest_tiles[top_cluster_index]\n",
    "#         print('Closest tiles new shape:', closest_tiles.shape)\n",
    "        new_tiles_features = X[labels == top_cluster_index]\n",
    "        np.save(new_tile_features_to_write, new_tile_features)\n",
    "        print('Removing tiles from all but the top cluster...')\n",
    "        \n",
    "    elif remove_largest_clusters == 'yes':\n",
    "        new_tile_features = X[labels != largest_cluster_index]\n",
    "#         new_tile_features = new_tile_features[labels != second_largest_cluster_index]\n",
    "        print(X.shape)\n",
    "        print(new_tile_features.shape)\n",
    "        np.save(new_tile_features_to_write, new_tile_features)\n",
    "        print('Removing tiles from largest cluster...')\n",
    "        \n",
    "    print('Closest tiles new shape:', closest_tiles.shape)\n",
    "    \n",
    "    #Save closest tiles per cluster to disk\n",
    "    print('Saving closest tiles per cluster for Features of Image', img)\n",
    "    np.save(closest_tiles_to_write, closest_tiles)\n",
    "    \n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "      \n",
    "    return(kmeans, labels, centers, silhouette_avg, cluster_silhouettes_averages, closest_tiles, \\\n",
    "           top_cluster_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Clustering Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-25T15:43:04.514014",
     "start_time": "2017-04-25T15:43:04.511249"
    }
   },
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-24T11:28:12.808887",
     "start_time": "2017-05-24T11:26:35.533163"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Loading Saved Features for Image img6186\n",
      "Start time:  2017-05-24 11:26:35\n",
      "End time:  2017-05-24 11:26:35\n",
      "Starting PCA for Features of Image img6186\n",
      "Start time:  2017-05-24 11:26:35\n",
      "End time:  2017-05-24 11:26:37\n",
      "1297.00545118\n",
      "For 1 features, SVD retained variance is: 64%\n",
      "For 2 features, SVD retained variance is: 67%\n",
      "For 5 features, SVD retained variance is: 70%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img6186\n",
      "Start time:  2017-05-24 11:26:37\n",
      "End time:  2017-05-24 11:26:38\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5851\n",
      "Start time:  2017-05-24 11:26:38\n",
      "End time:  2017-05-24 11:26:39\n",
      "Starting PCA for Features of Image img5851\n",
      "Start time:  2017-05-24 11:26:39\n",
      "End time:  2017-05-24 11:26:40\n",
      "685.852786474\n",
      "For 1 features, SVD retained variance is: 68%\n",
      "For 2 features, SVD retained variance is: 70%\n",
      "For 5 features, SVD retained variance is: 75%\n",
      "For 10 features, SVD retained variance is: 78%\n",
      "For 20 features, SVD retained variance is: 83%\n",
      "For 100 features, SVD retained variance is: 96%\n",
      "Saving Decomposed Matrices for Features of Image img5851\n",
      "Start time:  2017-05-24 11:26:40\n",
      "End time:  2017-05-24 11:26:40\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5852\n",
      "Start time:  2017-05-24 11:26:40\n",
      "End time:  2017-05-24 11:26:40\n",
      "Starting PCA for Features of Image img5852\n",
      "Start time:  2017-05-24 11:26:40\n",
      "End time:  2017-05-24 11:26:42\n",
      "1404.12404635\n",
      "For 1 features, SVD retained variance is: 63%\n",
      "For 2 features, SVD retained variance is: 65%\n",
      "For 5 features, SVD retained variance is: 69%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 88%\n",
      "Saving Decomposed Matrices for Features of Image img5852\n",
      "Start time:  2017-05-24 11:26:42\n",
      "End time:  2017-05-24 11:26:42\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5853\n",
      "Start time:  2017-05-24 11:26:42\n",
      "End time:  2017-05-24 11:26:42\n",
      "Starting PCA for Features of Image img5853\n",
      "Start time:  2017-05-24 11:26:42\n",
      "End time:  2017-05-24 11:26:43\n",
      "454.81824546\n",
      "For 1 features, SVD retained variance is: 73%\n",
      "For 2 features, SVD retained variance is: 76%\n",
      "For 5 features, SVD retained variance is: 79%\n",
      "For 10 features, SVD retained variance is: 82%\n",
      "For 20 features, SVD retained variance is: 87%\n",
      "For 100 features, SVD retained variance is: 99%\n",
      "Saving Decomposed Matrices for Features of Image img5853\n",
      "Start time:  2017-05-24 11:26:43\n",
      "End time:  2017-05-24 11:26:44\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5855\n",
      "Start time:  2017-05-24 11:26:44\n",
      "End time:  2017-05-24 11:26:44\n",
      "Starting PCA for Features of Image img5855\n",
      "Start time:  2017-05-24 11:26:44\n",
      "End time:  2017-05-24 11:26:45\n",
      "1813.27442863\n",
      "For 1 features, SVD retained variance is: 47%\n",
      "For 2 features, SVD retained variance is: 50%\n",
      "For 5 features, SVD retained variance is: 55%\n",
      "For 10 features, SVD retained variance is: 60%\n",
      "For 20 features, SVD retained variance is: 66%\n",
      "For 100 features, SVD retained variance is: 82%\n",
      "Saving Decomposed Matrices for Features of Image img5855\n",
      "Start time:  2017-05-24 11:26:45\n",
      "End time:  2017-05-24 11:26:45\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5871\n",
      "Start time:  2017-05-24 11:26:45\n",
      "End time:  2017-05-24 11:26:46\n",
      "Starting PCA for Features of Image img5871\n",
      "Start time:  2017-05-24 11:26:46\n",
      "End time:  2017-05-24 11:26:48\n",
      "1977.73475003\n",
      "For 1 features, SVD retained variance is: 55%\n",
      "For 2 features, SVD retained variance is: 57%\n",
      "For 5 features, SVD retained variance is: 61%\n",
      "For 10 features, SVD retained variance is: 65%\n",
      "For 20 features, SVD retained variance is: 70%\n",
      "For 100 features, SVD retained variance is: 83%\n",
      "Saving Decomposed Matrices for Features of Image img5871\n",
      "Start time:  2017-05-24 11:26:48\n",
      "End time:  2017-05-24 11:26:48\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5872\n",
      "Start time:  2017-05-24 11:26:48\n",
      "End time:  2017-05-24 11:26:49\n",
      "Starting PCA for Features of Image img5872\n",
      "Start time:  2017-05-24 11:26:49\n",
      "End time:  2017-05-24 11:26:49\n",
      "1121.7280215\n",
      "For 1 features, SVD retained variance is: 58%\n",
      "For 2 features, SVD retained variance is: 61%\n",
      "For 5 features, SVD retained variance is: 65%\n",
      "For 10 features, SVD retained variance is: 69%\n",
      "For 20 features, SVD retained variance is: 74%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img5872\n",
      "Start time:  2017-05-24 11:26:49\n",
      "End time:  2017-05-24 11:26:50\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img6395\n",
      "Start time:  2017-05-24 11:26:50\n",
      "End time:  2017-05-24 11:26:50\n",
      "Starting PCA for Features of Image img6395\n",
      "Start time:  2017-05-24 11:26:50\n",
      "End time:  2017-05-24 11:26:51\n",
      "888.28640306\n",
      "For 1 features, SVD retained variance is: 61%\n",
      "For 2 features, SVD retained variance is: 63%\n",
      "For 5 features, SVD retained variance is: 67%\n",
      "For 10 features, SVD retained variance is: 72%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 91%\n",
      "Saving Decomposed Matrices for Features of Image img6395\n",
      "Start time:  2017-05-24 11:26:51\n",
      "End time:  2017-05-24 11:26:51\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img6542\n",
      "Start time:  2017-05-24 11:26:51\n",
      "End time:  2017-05-24 11:26:51\n",
      "Starting PCA for Features of Image img6542\n",
      "Start time:  2017-05-24 11:26:51\n",
      "End time:  2017-05-24 11:26:52\n",
      "1546.70851086\n",
      "For 1 features, SVD retained variance is: 55%\n",
      "For 2 features, SVD retained variance is: 58%\n",
      "For 5 features, SVD retained variance is: 62%\n",
      "For 10 features, SVD retained variance is: 66%\n",
      "For 20 features, SVD retained variance is: 71%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img6542\n",
      "Start time:  2017-05-24 11:26:52\n",
      "End time:  2017-05-24 11:26:53\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7019\n",
      "Start time:  2017-05-24 11:26:53\n",
      "End time:  2017-05-24 11:26:53\n",
      "Starting PCA for Features of Image img7019\n",
      "Start time:  2017-05-24 11:26:53\n",
      "End time:  2017-05-24 11:26:55\n",
      "1722.45951021\n",
      "For 1 features, SVD retained variance is: 60%\n",
      "For 2 features, SVD retained variance is: 62%\n",
      "For 5 features, SVD retained variance is: 66%\n",
      "For 10 features, SVD retained variance is: 70%\n",
      "For 20 features, SVD retained variance is: 74%\n",
      "For 100 features, SVD retained variance is: 86%\n",
      "Saving Decomposed Matrices for Features of Image img7019\n",
      "Start time:  2017-05-24 11:26:55\n",
      "End time:  2017-05-24 11:26:55\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7304\n",
      "Start time:  2017-05-24 11:26:55\n",
      "End time:  2017-05-24 11:26:56\n",
      "Starting PCA for Features of Image img7304\n",
      "Start time:  2017-05-24 11:26:56\n",
      "End time:  2017-05-24 11:26:58\n",
      "1418.96459522\n",
      "For 1 features, SVD retained variance is: 66%\n",
      "For 2 features, SVD retained variance is: 68%\n",
      "For 5 features, SVD retained variance is: 72%\n",
      "For 10 features, SVD retained variance is: 75%\n",
      "For 20 features, SVD retained variance is: 78%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img7304\n",
      "Start time:  2017-05-24 11:26:58\n",
      "End time:  2017-05-24 11:26:58\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7306\n",
      "Start time:  2017-05-24 11:26:58\n",
      "End time:  2017-05-24 11:26:58\n",
      "Starting PCA for Features of Image img7306\n",
      "Start time:  2017-05-24 11:26:58\n",
      "End time:  2017-05-24 11:27:00\n",
      "1553.90211164\n",
      "For 1 features, SVD retained variance is: 62%\n",
      "For 2 features, SVD retained variance is: 64%\n",
      "For 5 features, SVD retained variance is: 67%\n",
      "For 10 features, SVD retained variance is: 71%\n",
      "For 20 features, SVD retained variance is: 75%\n",
      "For 100 features, SVD retained variance is: 87%\n",
      "Saving Decomposed Matrices for Features of Image img7306\n",
      "Start time:  2017-05-24 11:27:00\n",
      "End time:  2017-05-24 11:27:01\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8162\n",
      "Start time:  2017-05-24 11:27:01\n",
      "End time:  2017-05-24 11:27:01\n",
      "Starting PCA for Features of Image img8162\n",
      "Start time:  2017-05-24 11:27:01\n",
      "End time:  2017-05-24 11:27:03\n",
      "1672.99799526\n",
      "For 1 features, SVD retained variance is: 64%\n",
      "For 2 features, SVD retained variance is: 66%\n",
      "For 5 features, SVD retained variance is: 69%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 88%\n",
      "Saving Decomposed Matrices for Features of Image img8162\n",
      "Start time:  2017-05-24 11:27:03\n",
      "End time:  2017-05-24 11:27:04\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8163\n",
      "Start time:  2017-05-24 11:27:04\n",
      "End time:  2017-05-24 11:27:04\n",
      "Starting PCA for Features of Image img8163\n",
      "Start time:  2017-05-24 11:27:04\n",
      "End time:  2017-05-24 11:27:06\n",
      "1558.91105866\n",
      "For 1 features, SVD retained variance is: 64%\n",
      "For 2 features, SVD retained variance is: 66%\n",
      "For 5 features, SVD retained variance is: 70%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 88%\n",
      "Saving Decomposed Matrices for Features of Image img8163\n",
      "Start time:  2017-05-24 11:27:06\n",
      "End time:  2017-05-24 11:27:06\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8166\n",
      "Start time:  2017-05-24 11:27:06\n",
      "End time:  2017-05-24 11:27:07\n",
      "Starting PCA for Features of Image img8166\n",
      "Start time:  2017-05-24 11:27:07\n",
      "End time:  2017-05-24 11:27:08\n",
      "1787.6871845\n",
      "For 1 features, SVD retained variance is: 55%\n",
      "For 2 features, SVD retained variance is: 57%\n",
      "For 5 features, SVD retained variance is: 62%\n",
      "For 10 features, SVD retained variance is: 66%\n",
      "For 20 features, SVD retained variance is: 71%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img8166\n",
      "Start time:  2017-05-24 11:27:08\n",
      "End time:  2017-05-24 11:27:09\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8167\n",
      "Start time:  2017-05-24 11:27:09\n",
      "End time:  2017-05-24 11:27:09\n",
      "Starting PCA for Features of Image img8167\n",
      "Start time:  2017-05-24 11:27:09\n",
      "End time:  2017-05-24 11:27:11\n",
      "1564.58986915\n",
      "For 1 features, SVD retained variance is: 57%\n",
      "For 2 features, SVD retained variance is: 60%\n",
      "For 5 features, SVD retained variance is: 64%\n",
      "For 10 features, SVD retained variance is: 68%\n",
      "For 20 features, SVD retained variance is: 73%\n",
      "For 100 features, SVD retained variance is: 86%\n",
      "Saving Decomposed Matrices for Features of Image img8167\n",
      "Start time:  2017-05-24 11:27:11\n",
      "End time:  2017-05-24 11:27:11\n",
      "_________________________________________\n",
      "Loading Saved Features for Image imgA5TR\n",
      "Start time:  2017-05-24 11:27:11\n",
      "End time:  2017-05-24 11:27:11\n",
      "Starting PCA for Features of Image imgA5TR\n",
      "Start time:  2017-05-24 11:27:11\n",
      "End time:  2017-05-24 11:27:16\n",
      "2884.08997114\n",
      "For 1 features, SVD retained variance is: 47%\n",
      "For 2 features, SVD retained variance is: 50%\n",
      "For 5 features, SVD retained variance is: 55%\n",
      "For 10 features, SVD retained variance is: 60%\n",
      "For 20 features, SVD retained variance is: 65%\n",
      "For 100 features, SVD retained variance is: 79%\n",
      "Saving Decomposed Matrices for Features of Image imgA5TR\n",
      "Start time:  2017-05-24 11:27:16\n",
      "End time:  2017-05-24 11:27:17\n",
      "_________________________________________\n",
      "Loading Saved Features for Image imgA6S6\n",
      "Start time:  2017-05-24 11:27:17\n",
      "End time:  2017-05-24 11:27:17\n",
      "Starting PCA for Features of Image imgA6S6\n",
      "Start time:  2017-05-24 11:27:17\n",
      "End time:  2017-05-24 11:27:18\n",
      "1620.37311265\n",
      "For 1 features, SVD retained variance is: 53%\n",
      "For 2 features, SVD retained variance is: 56%\n",
      "For 5 features, SVD retained variance is: 62%\n",
      "For 10 features, SVD retained variance is: 66%\n",
      "For 20 features, SVD retained variance is: 71%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image imgA6S6\n",
      "Start time:  2017-05-24 11:27:18\n",
      "End time:  2017-05-24 11:27:18\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img5965\n",
      "Start time:  2017-05-24 11:27:18\n",
      "End time:  2017-05-24 11:27:18\n",
      "Starting PCA for Features of Image img5965\n",
      "Start time:  2017-05-24 11:27:18\n",
      "End time:  2017-05-24 11:27:20\n",
      "1501.04728564\n",
      "For 1 features, SVD retained variance is: 58%\n",
      "For 2 features, SVD retained variance is: 60%\n",
      "For 5 features, SVD retained variance is: 65%\n",
      "For 10 features, SVD retained variance is: 69%\n",
      "For 20 features, SVD retained variance is: 73%\n",
      "For 100 features, SVD retained variance is: 86%\n",
      "Saving Decomposed Matrices for Features of Image img5965\n",
      "Start time:  2017-05-24 11:27:20\n",
      "End time:  2017-05-24 11:27:20\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7637\n",
      "Start time:  2017-05-24 11:27:20\n",
      "End time:  2017-05-24 11:27:20\n",
      "Starting PCA for Features of Image img7637\n",
      "Start time:  2017-05-24 11:27:20\n",
      "End time:  2017-05-24 11:27:22\n",
      "1841.44769039\n",
      "For 1 features, SVD retained variance is: 46%\n",
      "For 2 features, SVD retained variance is: 48%\n",
      "For 5 features, SVD retained variance is: 54%\n",
      "For 10 features, SVD retained variance is: 59%\n",
      "For 20 features, SVD retained variance is: 65%\n",
      "For 100 features, SVD retained variance is: 81%\n",
      "Saving Decomposed Matrices for Features of Image img7637\n",
      "Start time:  2017-05-24 11:27:22\n",
      "End time:  2017-05-24 11:27:22\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7643\n",
      "Start time:  2017-05-24 11:27:22\n",
      "End time:  2017-05-24 11:27:22\n",
      "Starting PCA for Features of Image img7643\n",
      "Start time:  2017-05-24 11:27:22\n",
      "End time:  2017-05-24 11:27:23\n",
      "551.343836665\n",
      "For 1 features, SVD retained variance is: 63%\n",
      "For 2 features, SVD retained variance is: 66%\n",
      "For 5 features, SVD retained variance is: 72%\n",
      "For 10 features, SVD retained variance is: 78%\n",
      "For 20 features, SVD retained variance is: 84%\n",
      "For 100 features, SVD retained variance is: 99%\n",
      "Saving Decomposed Matrices for Features of Image img7643\n",
      "Start time:  2017-05-24 11:27:23\n",
      "End time:  2017-05-24 11:27:23\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8186\n",
      "Start time:  2017-05-24 11:27:23\n",
      "End time:  2017-05-24 11:27:23\n",
      "Starting PCA for Features of Image img8186\n",
      "Start time:  2017-05-24 11:27:23\n",
      "End time:  2017-05-24 11:27:24\n",
      "701.326242324\n",
      "For 1 features, SVD retained variance is: 84%\n",
      "For 2 features, SVD retained variance is: 85%\n",
      "For 5 features, SVD retained variance is: 87%\n",
      "For 10 features, SVD retained variance is: 88%\n",
      "For 20 features, SVD retained variance is: 90%\n",
      "For 100 features, SVD retained variance is: 96%\n",
      "Saving Decomposed Matrices for Features of Image img8186\n",
      "Start time:  2017-05-24 11:27:24\n",
      "End time:  2017-05-24 11:27:25\n",
      "_________________________________________\n",
      "Loading Saved Features for Image imgA4MU\n",
      "Start time:  2017-05-24 11:27:25\n",
      "End time:  2017-05-24 11:27:25\n",
      "Starting PCA for Features of Image imgA4MU\n",
      "Start time:  2017-05-24 11:27:25\n",
      "End time:  2017-05-24 11:27:26\n",
      "1359.35623413\n",
      "For 1 features, SVD retained variance is: 58%\n",
      "For 2 features, SVD retained variance is: 60%\n",
      "For 5 features, SVD retained variance is: 65%\n",
      "For 10 features, SVD retained variance is: 69%\n",
      "For 20 features, SVD retained variance is: 74%\n",
      "For 100 features, SVD retained variance is: 87%\n",
      "Saving Decomposed Matrices for Features of Image imgA4MU\n",
      "Start time:  2017-05-24 11:27:26\n",
      "End time:  2017-05-24 11:27:27\n",
      "_________________________________________\n",
      "Loading Saved Features for Image imgA60K\n",
      "Start time:  2017-05-24 11:27:27\n",
      "End time:  2017-05-24 11:27:27\n",
      "Starting PCA for Features of Image imgA60K\n",
      "Start time:  2017-05-24 11:27:27\n",
      "End time:  2017-05-24 11:27:28\n",
      "1224.0137815\n",
      "For 1 features, SVD retained variance is: 55%\n",
      "For 2 features, SVD retained variance is: 59%\n",
      "For 5 features, SVD retained variance is: 63%\n",
      "For 10 features, SVD retained variance is: 68%\n",
      "For 20 features, SVD retained variance is: 73%\n",
      "For 100 features, SVD retained variance is: 88%\n",
      "Saving Decomposed Matrices for Features of Image imgA60K\n",
      "Start time:  2017-05-24 11:27:28\n",
      "End time:  2017-05-24 11:27:28\n",
      "_________________________________________\n",
      "Loading Saved Features for Image imgA713\n",
      "Start time:  2017-05-24 11:27:28\n",
      "End time:  2017-05-24 11:27:28\n",
      "Starting PCA for Features of Image imgA713\n",
      "Start time:  2017-05-24 11:27:28\n",
      "End time:  2017-05-24 11:27:29\n",
      "1584.85844395\n",
      "For 1 features, SVD retained variance is: 49%\n",
      "For 2 features, SVD retained variance is: 52%\n",
      "For 5 features, SVD retained variance is: 58%\n",
      "For 10 features, SVD retained variance is: 63%\n",
      "For 20 features, SVD retained variance is: 68%\n",
      "For 100 features, SVD retained variance is: 84%\n",
      "Saving Decomposed Matrices for Features of Image imgA713\n",
      "Start time:  2017-05-24 11:27:29\n",
      "End time:  2017-05-24 11:27:29\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7473\n",
      "Start time:  2017-05-24 11:27:29\n",
      "End time:  2017-05-24 11:27:30\n",
      "Starting PCA for Features of Image img7473\n",
      "Start time:  2017-05-24 11:27:30\n",
      "End time:  2017-05-24 11:27:31\n",
      "1365.07916613\n",
      "For 1 features, SVD retained variance is: 63%\n",
      "For 2 features, SVD retained variance is: 66%\n",
      "For 5 features, SVD retained variance is: 70%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 77%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img7473\n",
      "Start time:  2017-05-24 11:27:31\n",
      "End time:  2017-05-24 11:27:31\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7474\n",
      "Start time:  2017-05-24 11:27:31\n",
      "End time:  2017-05-24 11:27:31\n",
      "Starting PCA for Features of Image img7474\n",
      "Start time:  2017-05-24 11:27:31\n",
      "End time:  2017-05-24 11:27:32\n",
      "1301.06052349\n",
      "For 1 features, SVD retained variance is: 59%\n",
      "For 2 features, SVD retained variance is: 61%\n",
      "For 5 features, SVD retained variance is: 66%\n",
      "For 10 features, SVD retained variance is: 70%\n",
      "For 20 features, SVD retained variance is: 75%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img7474\n",
      "Start time:  2017-05-24 11:27:32\n",
      "End time:  2017-05-24 11:27:33\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7475\n",
      "Start time:  2017-05-24 11:27:33\n",
      "End time:  2017-05-24 11:27:33\n",
      "Starting PCA for Features of Image img7475\n",
      "Start time:  2017-05-24 11:27:33\n",
      "End time:  2017-05-24 11:27:34\n",
      "2100.48875626\n",
      "For 1 features, SVD retained variance is: 47%\n",
      "For 2 features, SVD retained variance is: 50%\n",
      "For 5 features, SVD retained variance is: 55%\n",
      "For 10 features, SVD retained variance is: 60%\n",
      "For 20 features, SVD retained variance is: 66%\n",
      "For 100 features, SVD retained variance is: 81%\n",
      "Saving Decomposed Matrices for Features of Image img7475\n",
      "Start time:  2017-05-24 11:27:34\n",
      "End time:  2017-05-24 11:27:35\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7482\n",
      "Start time:  2017-05-24 11:27:35\n",
      "End time:  2017-05-24 11:27:35\n",
      "Starting PCA for Features of Image img7482\n",
      "Start time:  2017-05-24 11:27:35\n",
      "End time:  2017-05-24 11:27:36\n",
      "1177.56425396\n",
      "For 1 features, SVD retained variance is: 68%\n",
      "For 2 features, SVD retained variance is: 70%\n",
      "For 5 features, SVD retained variance is: 73%\n",
      "For 10 features, SVD retained variance is: 76%\n",
      "For 20 features, SVD retained variance is: 80%\n",
      "For 100 features, SVD retained variance is: 91%\n",
      "Saving Decomposed Matrices for Features of Image img7482\n",
      "Start time:  2017-05-24 11:27:36\n",
      "End time:  2017-05-24 11:27:36\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7608\n",
      "Start time:  2017-05-24 11:27:36\n",
      "End time:  2017-05-24 11:27:37\n",
      "Starting PCA for Features of Image img7608\n",
      "Start time:  2017-05-24 11:27:37\n",
      "End time:  2017-05-24 11:27:40\n",
      "2145.5574015\n",
      "For 1 features, SVD retained variance is: 57%\n",
      "For 2 features, SVD retained variance is: 60%\n",
      "For 5 features, SVD retained variance is: 65%\n",
      "For 10 features, SVD retained variance is: 68%\n",
      "For 20 features, SVD retained variance is: 73%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img7608\n",
      "Start time:  2017-05-24 11:27:40\n",
      "End time:  2017-05-24 11:27:41\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7609\n",
      "Start time:  2017-05-24 11:27:41\n",
      "End time:  2017-05-24 11:27:41\n",
      "Starting PCA for Features of Image img7609\n",
      "Start time:  2017-05-24 11:27:41\n",
      "End time:  2017-05-24 11:27:42\n",
      "807.491066348\n",
      "For 1 features, SVD retained variance is: 65%\n",
      "For 2 features, SVD retained variance is: 68%\n",
      "For 5 features, SVD retained variance is: 72%\n",
      "For 10 features, SVD retained variance is: 76%\n",
      "For 20 features, SVD retained variance is: 80%\n",
      "For 100 features, SVD retained variance is: 93%\n",
      "Saving Decomposed Matrices for Features of Image img7609\n",
      "Start time:  2017-05-24 11:27:42\n",
      "End time:  2017-05-24 11:27:42\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7610\n",
      "Start time:  2017-05-24 11:27:42\n",
      "End time:  2017-05-24 11:27:42\n",
      "Starting PCA for Features of Image img7610\n",
      "Start time:  2017-05-24 11:27:42\n",
      "End time:  2017-05-24 11:27:46\n",
      "2238.79100816\n",
      "For 1 features, SVD retained variance is: 56%\n",
      "For 2 features, SVD retained variance is: 59%\n",
      "For 5 features, SVD retained variance is: 63%\n",
      "For 10 features, SVD retained variance is: 67%\n",
      "For 20 features, SVD retained variance is: 72%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img7610\n",
      "Start time:  2017-05-24 11:27:46\n",
      "End time:  2017-05-24 11:27:46\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7611\n",
      "Start time:  2017-05-24 11:27:46\n",
      "End time:  2017-05-24 11:27:47\n",
      "Starting PCA for Features of Image img7611\n",
      "Start time:  2017-05-24 11:27:47\n",
      "End time:  2017-05-24 11:27:48\n",
      "1178.27770945\n",
      "For 1 features, SVD retained variance is: 67%\n",
      "For 2 features, SVD retained variance is: 70%\n",
      "For 5 features, SVD retained variance is: 73%\n",
      "For 10 features, SVD retained variance is: 76%\n",
      "For 20 features, SVD retained variance is: 80%\n",
      "For 100 features, SVD retained variance is: 90%\n",
      "Saving Decomposed Matrices for Features of Image img7611\n",
      "Start time:  2017-05-24 11:27:48\n",
      "End time:  2017-05-24 11:27:48\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7681\n",
      "Start time:  2017-05-24 11:27:48\n",
      "End time:  2017-05-24 11:27:48\n",
      "Starting PCA for Features of Image img7681\n",
      "Start time:  2017-05-24 11:27:48\n",
      "End time:  2017-05-24 11:27:49\n",
      "1252.49735296\n",
      "For 1 features, SVD retained variance is: 59%\n",
      "For 2 features, SVD retained variance is: 62%\n",
      "For 5 features, SVD retained variance is: 67%\n",
      "For 10 features, SVD retained variance is: 71%\n",
      "For 20 features, SVD retained variance is: 76%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img7681\n",
      "Start time:  2017-05-24 11:27:49\n",
      "End time:  2017-05-24 11:27:49\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7684\n",
      "Start time:  2017-05-24 11:27:49\n",
      "End time:  2017-05-24 11:27:50\n",
      "Starting PCA for Features of Image img7684\n",
      "Start time:  2017-05-24 11:27:50\n",
      "End time:  2017-05-24 11:27:55\n",
      "2808.3240863\n",
      "For 1 features, SVD retained variance is: 53%\n",
      "For 2 features, SVD retained variance is: 56%\n",
      "For 5 features, SVD retained variance is: 60%\n",
      "For 10 features, SVD retained variance is: 64%\n",
      "For 20 features, SVD retained variance is: 69%\n",
      "For 100 features, SVD retained variance is: 82%\n",
      "Saving Decomposed Matrices for Features of Image img7684\n",
      "Start time:  2017-05-24 11:27:55\n",
      "End time:  2017-05-24 11:27:56\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7690\n",
      "Start time:  2017-05-24 11:27:56\n",
      "End time:  2017-05-24 11:27:56\n",
      "Starting PCA for Features of Image img7690\n",
      "Start time:  2017-05-24 11:27:56\n",
      "End time:  2017-05-24 11:27:58\n",
      "1816.59467012\n",
      "For 1 features, SVD retained variance is: 56%\n",
      "For 2 features, SVD retained variance is: 58%\n",
      "For 5 features, SVD retained variance is: 63%\n",
      "For 10 features, SVD retained variance is: 67%\n",
      "For 20 features, SVD retained variance is: 72%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img7690\n",
      "Start time:  2017-05-24 11:27:58\n",
      "End time:  2017-05-24 11:27:58\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7692\n",
      "Start time:  2017-05-24 11:27:58\n",
      "End time:  2017-05-24 11:27:58\n",
      "Starting PCA for Features of Image img7692\n",
      "Start time:  2017-05-24 11:27:58\n",
      "End time:  2017-05-24 11:28:01\n",
      "1852.51277615\n",
      "For 1 features, SVD retained variance is: 58%\n",
      "For 2 features, SVD retained variance is: 60%\n",
      "For 5 features, SVD retained variance is: 64%\n",
      "For 10 features, SVD retained variance is: 67%\n",
      "For 20 features, SVD retained variance is: 72%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img7692\n",
      "Start time:  2017-05-24 11:28:01\n",
      "End time:  2017-05-24 11:28:01\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7873\n",
      "Start time:  2017-05-24 11:28:01\n",
      "End time:  2017-05-24 11:28:01\n",
      "Starting PCA for Features of Image img7873\n",
      "Start time:  2017-05-24 11:28:01\n",
      "End time:  2017-05-24 11:28:03\n",
      "1374.75042664\n",
      "For 1 features, SVD retained variance is: 66%\n",
      "For 2 features, SVD retained variance is: 69%\n",
      "For 5 features, SVD retained variance is: 72%\n",
      "For 10 features, SVD retained variance is: 75%\n",
      "For 20 features, SVD retained variance is: 79%\n",
      "For 100 features, SVD retained variance is: 89%\n",
      "Saving Decomposed Matrices for Features of Image img7873\n",
      "Start time:  2017-05-24 11:28:03\n",
      "End time:  2017-05-24 11:28:03\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7879\n",
      "Start time:  2017-05-24 11:28:03\n",
      "End time:  2017-05-24 11:28:03\n",
      "Starting PCA for Features of Image img7879\n",
      "Start time:  2017-05-24 11:28:03\n",
      "End time:  2017-05-24 11:28:04\n",
      "1263.68622302\n",
      "For 1 features, SVD retained variance is: 60%\n",
      "For 2 features, SVD retained variance is: 64%\n",
      "For 5 features, SVD retained variance is: 67%\n",
      "For 10 features, SVD retained variance is: 71%\n",
      "For 20 features, SVD retained variance is: 76%\n",
      "For 100 features, SVD retained variance is: 88%\n",
      "Saving Decomposed Matrices for Features of Image img7879\n",
      "Start time:  2017-05-24 11:28:04\n",
      "End time:  2017-05-24 11:28:05\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7880\n",
      "Start time:  2017-05-24 11:28:05\n",
      "End time:  2017-05-24 11:28:05\n",
      "Starting PCA for Features of Image img7880\n",
      "Start time:  2017-05-24 11:28:05\n",
      "End time:  2017-05-24 11:28:07\n",
      "1936.01958986\n",
      "For 1 features, SVD retained variance is: 55%\n",
      "For 2 features, SVD retained variance is: 59%\n",
      "For 5 features, SVD retained variance is: 63%\n",
      "For 10 features, SVD retained variance is: 67%\n",
      "For 20 features, SVD retained variance is: 72%\n",
      "For 100 features, SVD retained variance is: 85%\n",
      "Saving Decomposed Matrices for Features of Image img7880\n",
      "Start time:  2017-05-24 11:28:07\n",
      "End time:  2017-05-24 11:28:08\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img7902\n",
      "Start time:  2017-05-24 11:28:08\n",
      "End time:  2017-05-24 11:28:08\n",
      "Starting PCA for Features of Image img7902\n",
      "Start time:  2017-05-24 11:28:08\n",
      "End time:  2017-05-24 11:28:09\n",
      "590.434859952\n",
      "For 1 features, SVD retained variance is: 78%\n",
      "For 2 features, SVD retained variance is: 80%\n",
      "For 5 features, SVD retained variance is: 82%\n",
      "For 10 features, SVD retained variance is: 84%\n",
      "For 20 features, SVD retained variance is: 87%\n",
      "For 100 features, SVD retained variance is: 96%\n",
      "Saving Decomposed Matrices for Features of Image img7902\n",
      "Start time:  2017-05-24 11:28:09\n",
      "End time:  2017-05-24 11:28:09\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8013\n",
      "Start time:  2017-05-24 11:28:09\n",
      "End time:  2017-05-24 11:28:09\n",
      "Starting PCA for Features of Image img8013\n",
      "Start time:  2017-05-24 11:28:09\n",
      "End time:  2017-05-24 11:28:10\n",
      "914.121633145\n",
      "For 1 features, SVD retained variance is: 63%\n",
      "For 2 features, SVD retained variance is: 66%\n",
      "For 5 features, SVD retained variance is: 70%\n",
      "For 10 features, SVD retained variance is: 73%\n",
      "For 20 features, SVD retained variance is: 78%\n",
      "For 100 features, SVD retained variance is: 91%\n",
      "Saving Decomposed Matrices for Features of Image img8013\n",
      "Start time:  2017-05-24 11:28:10\n",
      "End time:  2017-05-24 11:28:11\n",
      "_________________________________________\n",
      "Loading Saved Features for Image img8018\n",
      "Start time:  2017-05-24 11:28:11\n",
      "End time:  2017-05-24 11:28:11\n",
      "Starting PCA for Features of Image img8018\n",
      "Start time:  2017-05-24 11:28:11\n",
      "End time:  2017-05-24 11:28:12\n",
      "1919.3355353\n",
      "For 1 features, SVD retained variance is: 46%\n",
      "For 2 features, SVD retained variance is: 49%\n",
      "For 5 features, SVD retained variance is: 55%\n",
      "For 10 features, SVD retained variance is: 60%\n",
      "For 20 features, SVD retained variance is: 65%\n",
      "For 100 features, SVD retained variance is: 82%\n",
      "Saving Decomposed Matrices for Features of Image img8018\n",
      "Start time:  2017-05-24 11:28:12\n",
      "End time:  2017-05-24 11:28:12\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This cell calls a function that derives and writes to disk \"V_k\" (and U, s, V) array including (K) features \n",
    "# for clustering\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    #Set n_features\n",
    "    K = 100\n",
    "    \n",
    "    for i in images:\n",
    "        #Set names\n",
    "        img = 'img%s' % (i,)\n",
    "        features_to_read = images_root_dir + 'level%s/img%s_files/tile_features.npy' % (l, i)\n",
    "        U_to_write = images_root_dir + 'level%s/img%s_files/U' % (l, i)\n",
    "        s_to_write = images_root_dir + 'level%s/img%s_files/s' % (l, i)\n",
    "        V_to_write = images_root_dir + 'level%s/img%s_files/V' % (l, i)\n",
    "        V_k_to_write = images_root_dir + 'level%s/img%s_files/V_k' % (l, i)\n",
    "        perform_SVD(img, features_to_read, K, U_to_write, s_to_write, V_to_write, V_k_to_write)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:41:42.746773",
     "start_time": "2017-05-30T15:41:34.331864"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: img4\n",
      "For n_clusters = 10 The average silhouette_score is : 0.208102\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You passed in an invalid linestyle, `__`.  See docs of Line2D.set_linestyle for valid values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mset_linestyle\u001b[0;34m(self, ls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls_mapper_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-09aff63027b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mgraph1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mgraph1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilhouette_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mgraph1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36maxvline\u001b[0;34m(self, x, ymin, ymax, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drawstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_linestyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_drawstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrawstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_linewidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tijohnso/anaconda/lib/python3.5/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mset_linestyle\u001b[0;34m(self, ls)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                   \u001b[0;34m\"`{}`.  See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                   \u001b[0;34m\"docs of Line2D.set_linestyle for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                   \"valid values.\").format(ls))\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linestyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You passed in an invalid linestyle, `__`.  See docs of Line2D.set_linestyle for valid values."
     ]
    }
   ],
   "source": [
    "# This cell builds silhouette diagrams of clusters for images, for different values of n_clusters.\n",
    "# It also creates scatter plots over the feature space of the first two principal components\n",
    "\n",
    "imlist = [4]\n",
    "for i in imlist:\n",
    "    img = 'img%s' % (i,)\n",
    "    print('Image:', img)\n",
    "    features_to_read = images_root_dir + 'level%s/img%s_files/tile_features.npy' % (l, i)\n",
    "    tile_features = np.load(features_to_read)\n",
    "    X = tile_features[:,0,0,:]\n",
    "#     X = tile_features\n",
    "\n",
    "\n",
    "    for n_clusters in range(10, 11):\n",
    "        f, (graph1, graph2) = plot.subplots(1, 2)\n",
    "        f.set_size_inches(30, 15)\n",
    "\n",
    "        graph1.set_xlim([-0.1, 1])\n",
    "        graph1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "        labels = kmeans.predict(X)\n",
    "        V_to_read = images_root_dir + 'level%s/img%s_files/V.npy' % (l, i)\n",
    "        V = np.load(V_to_read)\n",
    "        V = V[:,:2]\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, labels)\n",
    "        \n",
    "        print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        # Silhouette scores\n",
    "        sample_silhouette_values = silhouette_samples(X, labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
    "            cluster_silhouette_values.sort()\n",
    "            cluster_size = cluster_silhouette_values.shape[0]\n",
    "            \n",
    "            y_upper = y_lower + cluster_size\n",
    "\n",
    "            color = cm.spectral(float(i) / n_clusters)\n",
    "            graph1.fill_betweenx(np.arange(y_lower, y_upper),0, cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            graph1.text(-0.05, y_lower + 0.5 * cluster_size, str(i))\n",
    "\n",
    "            y_lower = y_upper + 10\n",
    "\n",
    "        graph1.set_title('Silhouette plot for %s clusters' % (n_clusters, ))\n",
    "        graph1.set_xlabel('Silhouette scores')\n",
    "        graph1.set_ylabel('Cluster')\n",
    "\n",
    "        graph1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        graph1.set_yticks([])\n",
    "        graph1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # Plot of clusters against features\n",
    "        graph2.set_xlim([-0.01, .01])\n",
    "#         graph2.set_ylim([-0.01, .01])\n",
    "        graph2.set_xticks([-0.009, -0.006, -0.003, 0, 0.003, 0.006, 0.009])\n",
    "#         graph2.set_yticks([-0.09, -0.06, -0.03, 0, 0.03, 0.06, 0.09])\n",
    "        colors = cm.spectral(labels.astype(float) / n_clusters)\n",
    "        graph2.scatter(V[:, 0], V[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors)\n",
    "\n",
    "        # Label the clusters\n",
    "        centers = kmeans.cluster_centers_\n",
    "        graph2.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200)\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            graph2.scatter(c[0], c[1], marker='$%d$' % (i, ), alpha=1, s=50)\n",
    "\n",
    "        graph2.set_title('Clustered data visualisation')\n",
    "        graph2.set_xlabel('Feature space for the 1st component')\n",
    "        graph2.set_ylabel('Feature space for the 2nd component')\n",
    "\n",
    "        plot.suptitle(('Silhouette analysis for KMeans clustering on sample data with %s clusters' % n_clusters), fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plot.show()\n",
    "#         pyl.savefig(img + str(n_clusters) + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster tiles and Calculate closest tiles to cluster centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-27T22:12:19.187167",
     "start_time": "2017-05-27T22:10:10.422626"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7687\n",
      "Start time:  2017-05-27 22:10:10\n",
      "For number of clusters = 10 The silhouette score is : 0.146571\n",
      "The 10 ave cluster silhouettes are: [0.075919986, 0.014638377, 0.074325629, 0.20982367, 0.15851234, 0.18298297, -0.010670979, 0.10727489, 0.181798, 0.64596206]\n",
      "\n",
      "The best cluster is: 9\n",
      "The worst cluster is: 6\n",
      "The largest cluster is: 7\n",
      "\n",
      "Closest tiles for best cluster 9 : [1518 1368 1281  971 1371 1517 1433 1072  441  972]\n",
      "Closest tiles for worst cluster 6 : [411 414 194 771 228 831  98  43 192 137]\n",
      "Closest tiles for largest cluster 7 : [887 119 120 524 167 701 742 932 944 674]\n",
      "Number of tiles in cluster 0 is: 45\n",
      "Number of tiles in cluster 1 is: 31\n",
      "Number of tiles in cluster 2 is: 239\n",
      "Number of tiles in cluster 3 is: 132\n",
      "Number of tiles in cluster 4 is: 175\n",
      "Number of tiles in cluster 5 is: 239\n",
      "Number of tiles in cluster 6 is: 110\n",
      "Number of tiles in cluster 7 is: 254\n",
      "Number of tiles in cluster 8 is: 247\n",
      "Number of tiles in cluster 9 is: 48\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7687\n",
      "End time:  2017-05-27 22:10:24\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7688\n",
      "Start time:  2017-05-27 22:10:24\n",
      "For number of clusters = 10 The silhouette score is : 0.220275\n",
      "The 10 ave cluster silhouettes are: [0.21731824, 0.2113564, 0.7356658, 0.1772397, 0.24687596, 0.058136869, 0.1330203, 0.10256714, 0.035517909, 0.24994637]\n",
      "\n",
      "The best cluster is: 2\n",
      "The worst cluster is: 8\n",
      "The largest cluster is: 9\n",
      "\n",
      "Closest tiles for best cluster 2 : [895 877   0   1 907 874 699  71 878 139]\n",
      "Closest tiles for worst cluster 8 : [852   4  28 134   3 911 825 903 265 905]\n",
      "Closest tiles for largest cluster 9 : [274 636 387 595 210 246 346 224 426 256]\n",
      "Number of tiles in cluster 0 is: 149\n",
      "Number of tiles in cluster 1 is: 148\n",
      "Number of tiles in cluster 2 is: 32\n",
      "Number of tiles in cluster 3 is: 178\n",
      "Number of tiles in cluster 4 is: 90\n",
      "Number of tiles in cluster 5 is: 24\n",
      "Number of tiles in cluster 6 is: 22\n",
      "Number of tiles in cluster 7 is: 45\n",
      "Number of tiles in cluster 8 is: 25\n",
      "Number of tiles in cluster 9 is: 211\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7688\n",
      "End time:  2017-05-27 22:10:30\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7689\n",
      "Start time:  2017-05-27 22:10:30\n",
      "For number of clusters = 10 The silhouette score is : 0.161563\n",
      "The 10 ave cluster silhouettes are: [0.10981652, 0.15608306, 0.62580842, 0.033814829, 0.011049327, 0.15172403, 0.14592092, 0.19087771, 0.068303309, 0.21791993]\n",
      "\n",
      "The best cluster is: 2\n",
      "The worst cluster is: 4\n",
      "The largest cluster is: 7\n",
      "\n",
      "Closest tiles for best cluster 2 : [258 821 377 998 855 973 734 988 664 915]\n",
      "Closest tiles for worst cluster 4 : [706 937 566 445 823 529 530 691 719 513]\n",
      "Closest tiles for largest cluster 7 : [295 303 396 486 383 465 209 394 274 365]\n",
      "Number of tiles in cluster 0 is: 107\n",
      "Number of tiles in cluster 1 is: 134\n",
      "Number of tiles in cluster 2 is: 67\n",
      "Number of tiles in cluster 3 is: 87\n",
      "Number of tiles in cluster 4 is: 69\n",
      "Number of tiles in cluster 5 is: 104\n",
      "Number of tiles in cluster 6 is: 118\n",
      "Number of tiles in cluster 7 is: 166\n",
      "Number of tiles in cluster 8 is: 91\n",
      "Number of tiles in cluster 9 is: 56\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7689\n",
      "End time:  2017-05-27 22:10:38\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7693\n",
      "Start time:  2017-05-27 22:10:38\n",
      "For number of clusters = 10 The silhouette score is : 0.135958\n",
      "The 10 ave cluster silhouettes are: [0.070748106, 0.12501585, 0.10587532, 0.080301896, 0.014967678, 0.11815024, 0.11331507, 0.13048899, 0.62820643, 0.063083611]\n",
      "\n",
      "The best cluster is: 8\n",
      "The worst cluster is: 4\n",
      "The largest cluster is: 2\n",
      "\n",
      "Closest tiles for best cluster 8 : [552 276 442 340 547 464 506 508 208 535]\n",
      "Closest tiles for worst cluster 4 : [289 184 296 150 434 493 432 139 517 407]\n",
      "Closest tiles for largest cluster 2 : [ 59 424 392  58  24  17 198 125 194  19]\n",
      "Number of tiles in cluster 0 is: 69\n",
      "Number of tiles in cluster 1 is: 32\n",
      "Number of tiles in cluster 2 is: 78\n",
      "Number of tiles in cluster 3 is: 57\n",
      "Number of tiles in cluster 4 is: 13\n",
      "Number of tiles in cluster 5 is: 73\n",
      "Number of tiles in cluster 6 is: 71\n",
      "Number of tiles in cluster 7 is: 59\n",
      "Number of tiles in cluster 8 is: 40\n",
      "Number of tiles in cluster 9 is: 62\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7693\n",
      "End time:  2017-05-27 22:10:42\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7694\n",
      "Start time:  2017-05-27 22:10:42\n",
      "For number of clusters = 10 The silhouette score is : 0.176837\n",
      "The 10 ave cluster silhouettes are: [0.19887307, 0.069926105, 0.19465609, 0.11318815, 0.10792046, 0.66091371, 0.14185877, 0.18056843, 0.16708325, 0.099609487]\n",
      "\n",
      "The best cluster is: 5\n",
      "The worst cluster is: 1\n",
      "The largest cluster is: 7\n",
      "\n",
      "Closest tiles for best cluster 5 : [ 184  741 1166  942 1167  879  759  919 1164  807]\n",
      "Closest tiles for worst cluster 1 : [250 757  91 365 226  16 139 584 513 259]\n",
      "Closest tiles for largest cluster 7 : [ 524  871  449  340  343 1004  842  558  927  383]\n",
      "Number of tiles in cluster 0 is: 57\n",
      "Number of tiles in cluster 1 is: 104\n",
      "Number of tiles in cluster 2 is: 88\n",
      "Number of tiles in cluster 3 is: 114\n",
      "Number of tiles in cluster 4 is: 112\n",
      "Number of tiles in cluster 5 is: 72\n",
      "Number of tiles in cluster 6 is: 119\n",
      "Number of tiles in cluster 7 is: 243\n",
      "Number of tiles in cluster 8 is: 173\n",
      "Number of tiles in cluster 9 is: 86\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7694\n",
      "End time:  2017-05-27 22:10:52\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7695\n",
      "Start time:  2017-05-27 22:10:52\n",
      "For number of clusters = 10 The silhouette score is : 0.229405\n",
      "The 10 ave cluster silhouettes are: [0.23198721, 0.031107752, -0.01999883, 0.11489691, 0.7163322, 0.2289612, -0.040528048, 0.25729376, 0.3437143, 0.20705348]\n",
      "\n",
      "The best cluster is: 4\n",
      "The worst cluster is: 6\n",
      "The largest cluster is: 5\n",
      "\n",
      "Closest tiles for best cluster 4 : [ 607  550  308  665 1416  523  438   16   48 1382]\n",
      "Closest tiles for worst cluster 6 : [ 217  473  471 1289  584 1463  417 1245  474  639]\n",
      "Closest tiles for largest cluster 5 : [ 871 1492 1202  975 1264  430 1420  816  370 1534]\n",
      "Number of tiles in cluster 0 is: 219\n",
      "Number of tiles in cluster 1 is: 61\n",
      "Number of tiles in cluster 2 is: 52\n",
      "Number of tiles in cluster 3 is: 132\n",
      "Number of tiles in cluster 4 is: 74\n",
      "Number of tiles in cluster 5 is: 276\n",
      "Number of tiles in cluster 6 is: 87\n",
      "Number of tiles in cluster 7 is: 188\n",
      "Number of tiles in cluster 8 is: 244\n",
      "Number of tiles in cluster 9 is: 266\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7695\n",
      "End time:  2017-05-27 22:11:06\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7856\n",
      "Start time:  2017-05-27 22:11:06\n",
      "For number of clusters = 10 The silhouette score is : 0.188008\n",
      "The 10 ave cluster silhouettes are: [0.31645113, 0.13691358, 0.10735546, 0.13722354, 0.084805883, 0.23581414, 0.18441391, 0.67949444, 0.012273712, 0.082356758]\n",
      "\n",
      "The best cluster is: 7\n",
      "The worst cluster is: 8\n",
      "The largest cluster is: 5\n",
      "\n",
      "Closest tiles for best cluster 7 : [ 406 1037 1103  708    0  768 1032 1015 1097  158]\n",
      "Closest tiles for worst cluster 8 : [935 471  28   3  26 502 345 318 153 538]\n",
      "Closest tiles for largest cluster 5 : [ 53  15  14 160 110  13 166  73  16  22]\n",
      "Number of tiles in cluster 0 is: 172\n",
      "Number of tiles in cluster 1 is: 45\n",
      "Number of tiles in cluster 2 is: 108\n",
      "Number of tiles in cluster 3 is: 73\n",
      "Number of tiles in cluster 4 is: 53\n",
      "Number of tiles in cluster 5 is: 177\n",
      "Number of tiles in cluster 6 is: 169\n",
      "Number of tiles in cluster 7 is: 51\n",
      "Number of tiles in cluster 8 is: 111\n",
      "Number of tiles in cluster 9 is: 145\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7856\n",
      "End time:  2017-05-27 22:11:16\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7874\n",
      "Start time:  2017-05-27 22:11:16\n",
      "For number of clusters = 10 The silhouette score is : 0.336164\n",
      "The 10 ave cluster silhouettes are: [0.097321302, 0.87872702, 0.16906327, 0.01770127, 0.19538708, 0.16453889, 0.23525038, 0.078868866, 0.19869585, 0.068640806]\n",
      "\n",
      "The best cluster is: 1\n",
      "The worst cluster is: 3\n",
      "The largest cluster is: 1\n",
      "\n",
      "Closest tiles for best cluster 1 : [170  77 150   7  78 117 102  25 134  35]\n",
      "Closest tiles for worst cluster 3 : [361  99 331 336 334 310 157 165 161 224]\n",
      "Closest tiles for largest cluster 1 : [170  77 150   7  78 117 102  25 134  35]\n",
      "Number of tiles in cluster 0 is: 48\n",
      "Number of tiles in cluster 1 is: 149\n",
      "Number of tiles in cluster 2 is: 89\n",
      "Number of tiles in cluster 3 is: 31\n",
      "Number of tiles in cluster 4 is: 25\n",
      "Number of tiles in cluster 5 is: 24\n",
      "Number of tiles in cluster 6 is: 92\n",
      "Number of tiles in cluster 7 is: 53\n",
      "Number of tiles in cluster 8 is: 44\n",
      "Number of tiles in cluster 9 is: 30\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7874\n",
      "End time:  2017-05-27 22:11:20\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7875\n",
      "Start time:  2017-05-27 22:11:20\n",
      "For number of clusters = 10 The silhouette score is : 0.199316\n",
      "The 10 ave cluster silhouettes are: [0.70048684, 0.25509313, 0.27883154, 0.11990716, 0.052798335, 0.10703227, 0.15771356, 0.13550514, 0.14581373, 0.12208188]\n",
      "\n",
      "The best cluster is: 0\n",
      "The worst cluster is: 4\n",
      "The largest cluster is: 5\n",
      "\n",
      "Closest tiles for best cluster 0 : [198 220 221  61 195 206 169 144 102 219]\n",
      "Closest tiles for worst cluster 4 : [  4 145 216   2 158 184   1   7   0 213]\n",
      "Closest tiles for largest cluster 5 : [ 53  91  84 119 185 112  52  51  76 132]\n",
      "Number of tiles in cluster 0 is: 16\n",
      "Number of tiles in cluster 1 is: 32\n",
      "Number of tiles in cluster 2 is: 27\n",
      "Number of tiles in cluster 3 is: 20\n",
      "Number of tiles in cluster 4 is: 7\n",
      "Number of tiles in cluster 5 is: 45\n",
      "Number of tiles in cluster 6 is: 3\n",
      "Number of tiles in cluster 7 is: 25\n",
      "Number of tiles in cluster 8 is: 7\n",
      "Number of tiles in cluster 9 is: 40\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7875\n",
      "End time:  2017-05-27 22:11:21\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7877\n",
      "Start time:  2017-05-27 22:11:21\n",
      "For number of clusters = 10 The silhouette score is : 0.18851\n",
      "The 10 ave cluster silhouettes are: [0.12545788, 0.091351457, 0.071645454, 0.1981837, 0.35640621, 0.74252796, 0.11241565, 0.11879601, 0.27081484, 0.1833273]\n",
      "\n",
      "The best cluster is: 5\n",
      "The worst cluster is: 2\n",
      "The largest cluster is: 0\n",
      "\n",
      "Closest tiles for best cluster 5 : [451 586 655 329 560 637 612 337 392 307]\n",
      "Closest tiles for worst cluster 2 : [175 230 106 321 198  78 419 289 257 229]\n",
      "Closest tiles for largest cluster 0 : [ 13 293 401 356 262 325 193 168 224 409]\n",
      "Number of tiles in cluster 0 is: 130\n",
      "Number of tiles in cluster 1 is: 26\n",
      "Number of tiles in cluster 2 is: 117\n",
      "Number of tiles in cluster 3 is: 101\n",
      "Number of tiles in cluster 4 is: 67\n",
      "Number of tiles in cluster 5 is: 32\n",
      "Number of tiles in cluster 6 is: 24\n",
      "Number of tiles in cluster 7 is: 50\n",
      "Number of tiles in cluster 8 is: 5\n",
      "Number of tiles in cluster 9 is: 127\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7877\n",
      "End time:  2017-05-27 22:11:26\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7881\n",
      "Start time:  2017-05-27 22:11:26\n",
      "For number of clusters = 10 The silhouette score is : 0.206454\n",
      "The 10 ave cluster silhouettes are: [0.12819166, 0.41004306, 0.13223815, 0.46322861, 0.13267276, 0.12406471, 0.17712788, 0.29016179, 0.14794607, 0.089185402]\n",
      "\n",
      "The best cluster is: 3\n",
      "The worst cluster is: 9\n",
      "The largest cluster is: 2\n",
      "\n",
      "Closest tiles for best cluster 3 : [ 858  233 1014  395  859  996  671 1006 1010  998]\n",
      "Closest tiles for worst cluster 9 : [317 927 409 642 713 716 566 922 681 837]\n",
      "Closest tiles for largest cluster 2 : [807 503 469 754 641 757 679 784 755 781]\n",
      "Number of tiles in cluster 0 is: 79\n",
      "Number of tiles in cluster 1 is: 137\n",
      "Number of tiles in cluster 2 is: 140\n",
      "Number of tiles in cluster 3 is: 81\n",
      "Number of tiles in cluster 4 is: 97\n",
      "Number of tiles in cluster 5 is: 137\n",
      "Number of tiles in cluster 6 is: 102\n",
      "Number of tiles in cluster 7 is: 74\n",
      "Number of tiles in cluster 8 is: 80\n",
      "Number of tiles in cluster 9 is: 104\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7881\n",
      "End time:  2017-05-27 22:11:35\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img7882\n",
      "Start time:  2017-05-27 22:11:35\n",
      "For number of clusters = 10 The silhouette score is : 0.145039\n",
      "The 10 ave cluster silhouettes are: [0.23170854, 0.013099506, 0.70234483, 0.050641209, -0.0047597424, 0.16622823, 0.05923355, 0.16121717, 0.037267711, 0.060579132]\n",
      "\n",
      "The best cluster is: 2\n",
      "The worst cluster is: 4\n",
      "The largest cluster is: 5\n",
      "\n",
      "Closest tiles for best cluster 2 : [207 296  82 719 118 390 149 676 705  18]\n",
      "Closest tiles for worst cluster 4 : [150 297 417 204 504 342 515 222 374 613]\n",
      "Closest tiles for largest cluster 5 : [227 359 465 409 522 499 558 584 338 475]\n",
      "Number of tiles in cluster 0 is: 91\n",
      "Number of tiles in cluster 1 is: 64\n",
      "Number of tiles in cluster 2 is: 36\n",
      "Number of tiles in cluster 3 is: 96\n",
      "Number of tiles in cluster 4 is: 55\n",
      "Number of tiles in cluster 5 is: 155\n",
      "Number of tiles in cluster 6 is: 22\n",
      "Number of tiles in cluster 7 is: 138\n",
      "Number of tiles in cluster 8 is: 22\n",
      "Number of tiles in cluster 9 is: 41\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img7882\n",
      "End time:  2017-05-27 22:11:41\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8010\n",
      "Start time:  2017-05-27 22:11:41\n",
      "For number of clusters = 10 The silhouette score is : 0.191012\n",
      "The 10 ave cluster silhouettes are: [0.2067038, 0.46723458, 0.097061396, 0.2044162, 0.27225277, -0.073870599, 0.2109708, 0.11165918, 0.037651803, 0.29640037]\n",
      "\n",
      "The best cluster is: 1\n",
      "The worst cluster is: 5\n",
      "The largest cluster is: 7\n",
      "\n",
      "Closest tiles for best cluster 1 : [456 519 525 786 685 746 734 226 671 795]\n",
      "Closest tiles for worst cluster 5 : [327 198 388 440 125 186 389 564 138 286]\n",
      "Closest tiles for largest cluster 7 : [178 741 526 652 702 162 607 616 675 577]\n",
      "Number of tiles in cluster 0 is: 137\n",
      "Number of tiles in cluster 1 is: 52\n",
      "Number of tiles in cluster 2 is: 101\n",
      "Number of tiles in cluster 3 is: 31\n",
      "Number of tiles in cluster 4 is: 117\n",
      "Number of tiles in cluster 5 is: 34\n",
      "Number of tiles in cluster 6 is: 115\n",
      "Number of tiles in cluster 7 is: 138\n",
      "Number of tiles in cluster 8 is: 29\n",
      "Number of tiles in cluster 9 is: 49\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8010\n",
      "End time:  2017-05-27 22:11:48\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8012\n",
      "Start time:  2017-05-27 22:11:48\n",
      "For number of clusters = 10 The silhouette score is : 0.145213\n",
      "The 10 ave cluster silhouettes are: [0.17140989, 0.058875278, 0.70310766, 0.11708489, 0.20248, 0.056588385, 0.072499886, 0.069193088, 0.07042066, 0.14408919]\n",
      "\n",
      "The best cluster is: 2\n",
      "The worst cluster is: 5\n",
      "The largest cluster is: 3\n",
      "\n",
      "Closest tiles for best cluster 2 : [308   0 336 108 277 247 215 278 216 364]\n",
      "Closest tiles for worst cluster 5 : [580 415 440 530 468 670 416 669 671 536]\n",
      "Closest tiles for largest cluster 3 : [263 261 119 410 225 255 581 127 313 314]\n",
      "Number of tiles in cluster 0 is: 99\n",
      "Number of tiles in cluster 1 is: 74\n",
      "Number of tiles in cluster 2 is: 45\n",
      "Number of tiles in cluster 3 is: 137\n",
      "Number of tiles in cluster 4 is: 24\n",
      "Number of tiles in cluster 5 is: 67\n",
      "Number of tiles in cluster 6 is: 78\n",
      "Number of tiles in cluster 7 is: 25\n",
      "Number of tiles in cluster 8 is: 70\n",
      "Number of tiles in cluster 9 is: 76\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8012\n",
      "End time:  2017-05-27 22:11:53\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8019\n",
      "Start time:  2017-05-27 22:11:53\n",
      "For number of clusters = 10 The silhouette score is : 0.131805\n",
      "The 10 ave cluster silhouettes are: [0.58727968, 0.16692632, 0.15298222, 0.13310182, 0.11536709, 0.15026747, -0.020145355, 0.17160802, 0.077271909, 0.010839824]\n",
      "\n",
      "The best cluster is: 0\n",
      "The worst cluster is: 6\n",
      "The largest cluster is: 8\n",
      "\n",
      "Closest tiles for best cluster 0 : [707 722 135 136 736 684 567 137  31 629]\n",
      "Closest tiles for worst cluster 6 : [ 60 375 168 496 138  27 424 355  61  62]\n",
      "Closest tiles for largest cluster 8 : [280 392 430 332 536 440 291 275 237 377]\n",
      "Number of tiles in cluster 0 is: 37\n",
      "Number of tiles in cluster 1 is: 132\n",
      "Number of tiles in cluster 2 is: 28\n",
      "Number of tiles in cluster 3 is: 46\n",
      "Number of tiles in cluster 4 is: 90\n",
      "Number of tiles in cluster 5 is: 29\n",
      "Number of tiles in cluster 6 is: 29\n",
      "Number of tiles in cluster 7 is: 76\n",
      "Number of tiles in cluster 8 is: 197\n",
      "Number of tiles in cluster 9 is: 75\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8019\n",
      "End time:  2017-05-27 22:11:59\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8105\n",
      "Start time:  2017-05-27 22:11:59\n",
      "For number of clusters = 10 The silhouette score is : 0.137468\n",
      "The 10 ave cluster silhouettes are: [0.16714504, 0.41003653, 0.14785804, 0.046891123, 0.12576154, 0.046746388, 0.12917012, 0.087494031, 0.18525869, -0.014989357]\n",
      "\n",
      "The best cluster is: 1\n",
      "The worst cluster is: 9\n",
      "The largest cluster is: 3\n",
      "\n",
      "Closest tiles for best cluster 1 : [ 10 604 495 189 266   1 346 671 869  86]\n",
      "Closest tiles for worst cluster 9 : [340 545 128 492  88 493 109 162 520 752]\n",
      "Closest tiles for largest cluster 3 : [153 620 480 619 914  73 942 853 812 873]\n",
      "Number of tiles in cluster 0 is: 160\n",
      "Number of tiles in cluster 1 is: 89\n",
      "Number of tiles in cluster 2 is: 108\n",
      "Number of tiles in cluster 3 is: 174\n",
      "Number of tiles in cluster 4 is: 71\n",
      "Number of tiles in cluster 5 is: 75\n",
      "Number of tiles in cluster 6 is: 91\n",
      "Number of tiles in cluster 7 is: 67\n",
      "Number of tiles in cluster 8 is: 130\n",
      "Number of tiles in cluster 9 is: 58\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8105\n",
      "End time:  2017-05-27 22:12:07\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8107\n",
      "Start time:  2017-05-27 22:12:07\n",
      "For number of clusters = 10 The silhouette score is : 0.198591\n",
      "The 10 ave cluster silhouettes are: [0.19571234, 0.19046718, 0.1982742, 0.22692972, 0.28011194, 0.064138427, 0.063917056, 0.47833529, 0.016532052, 0.21552053]\n",
      "\n",
      "The best cluster is: 7\n",
      "The worst cluster is: 8\n",
      "The largest cluster is: 0\n",
      "\n",
      "Closest tiles for best cluster 7 : [351 352 264 129 350 306 284 337 353  83]\n",
      "Closest tiles for worst cluster 8 : [127  40  84 196  25  22 151 219  70 197]\n",
      "Closest tiles for largest cluster 0 : [111 136 260 134 137  90 238 119 144 246]\n",
      "Number of tiles in cluster 0 is: 68\n",
      "Number of tiles in cluster 1 is: 35\n",
      "Number of tiles in cluster 2 is: 40\n",
      "Number of tiles in cluster 3 is: 34\n",
      "Number of tiles in cluster 4 is: 46\n",
      "Number of tiles in cluster 5 is: 21\n",
      "Number of tiles in cluster 6 is: 40\n",
      "Number of tiles in cluster 7 is: 19\n",
      "Number of tiles in cluster 8 is: 11\n",
      "Number of tiles in cluster 9 is: 40\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8107\n",
      "End time:  2017-05-27 22:12:10\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8108\n",
      "Start time:  2017-05-27 22:12:10\n",
      "For number of clusters = 10 The silhouette score is : 0.176497\n",
      "The 10 ave cluster silhouettes are: [0.6846267, 0.04756457, 0.2920517, 0.15789436, 0.07257022, 0.17405607, 0.075725891, 0.21580167, 0.1247165, 0.092465833]\n",
      "\n",
      "The best cluster is: 0\n",
      "The worst cluster is: 1\n",
      "The largest cluster is: 4\n",
      "\n",
      "Closest tiles for best cluster 0 : [297 296 240 299 108 264 305 306 239  19]\n",
      "Closest tiles for worst cluster 1 : [252 272 270 271 141 167 266 243  89 276]\n",
      "Closest tiles for largest cluster 4 : [201 173 130  95 188 225  71 175 227 122]\n",
      "Number of tiles in cluster 0 is: 25\n",
      "Number of tiles in cluster 1 is: 26\n",
      "Number of tiles in cluster 2 is: 31\n",
      "Number of tiles in cluster 3 is: 44\n",
      "Number of tiles in cluster 4 is: 68\n",
      "Number of tiles in cluster 5 is: 27\n",
      "Number of tiles in cluster 6 is: 22\n",
      "Number of tiles in cluster 7 is: 10\n",
      "Number of tiles in cluster 8 is: 48\n",
      "Number of tiles in cluster 9 is: 8\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8108\n",
      "End time:  2017-05-27 22:12:12\n",
      "_________________________________________\n",
      "Using full feature set\n",
      "Starting cluster analysis for features of image img8109\n",
      "Start time:  2017-05-27 22:12:12\n",
      "For number of clusters = 10 The silhouette score is : 0.277526\n",
      "The 10 ave cluster silhouettes are: [0.81361967, 0.16795617, 0.13663425, 0.27591252, 0.11509255, 0.15789804, 0.079755172, 0.022969594, 0.17224541, 0.21175626]\n",
      "\n",
      "The best cluster is: 0\n",
      "The worst cluster is: 7\n",
      "The largest cluster is: 0\n",
      "\n",
      "Closest tiles for best cluster 0 : [854 899 918 808 811 904 903 857 891 866]\n",
      "Closest tiles for worst cluster 7 : [548 573 655 814 373 480 755 455 453 689]\n",
      "Closest tiles for largest cluster 0 : [854 899 918 808 811 904 903 857 891 866]\n",
      "Number of tiles in cluster 0 is: 156\n",
      "Number of tiles in cluster 1 is: 155\n",
      "Number of tiles in cluster 2 is: 93\n",
      "Number of tiles in cluster 3 is: 86\n",
      "Number of tiles in cluster 4 is: 68\n",
      "Number of tiles in cluster 5 is: 106\n",
      "Number of tiles in cluster 6 is: 17\n",
      "Number of tiles in cluster 7 is: 41\n",
      "Number of tiles in cluster 8 is: 74\n",
      "Number of tiles in cluster 9 is: 123\n",
      "Closest tiles new shape: (10, 10)\n",
      "Saving closest tiles per cluster for Features of Image img8109\n",
      "End time:  2017-05-27 22:12:19\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This cell calls a function  to perform kmeans clustering and distance to centroid calculations\n",
    "# It writes the \"closest_tiles\" numpy array to disk which is an of n_clusters * n_closest_tiles index\n",
    "# Options may be passed in to specify different clustering behaviour such as: remove top or largest cluster or\n",
    "# recluster based removing a cluster on a previous clustering run.\n",
    "# It also prints out information for further exploration of clustering\n",
    "\n",
    "pca = 'no'\n",
    "remove_top_cluster = 'no'\n",
    "keep_only_top_cluster = 'no'\n",
    "remove_largest_clusters = 'no'\n",
    "subsequent_pass = 'no'\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    #Set clustering values\n",
    "    n_closest_tiles = 10\n",
    "    n_clusters = 10\n",
    "    \n",
    "    closest_tiles_list = []\n",
    "    top_cluster_tiles_index_list = []\n",
    "    for i in images:\n",
    "        #Set names\n",
    "        img = 'img%s' % (i,)\n",
    "        closest_tiles_to_write = images_root_dir + 'level%s/img%s_files/closest_tiles' % (l, i)\n",
    "        features_to_read = images_root_dir + 'level%s/img%s_files/tile_features.npy' % (l, i)\n",
    "        new_tile_features_to_write = images_root_dir + 'level%s/img%s_files/new_tile_features' % (l, i)\n",
    "        new_tile_features_to_read = images_root_dir + 'level%s/img%s_files/new_tile_features.npy' % (l, i)\n",
    "        \n",
    "        if pca == 'yes':\n",
    "            V_k_to_read = images_root_dir + 'level%s/img%s_files/V_k.npy' % (l, i)\n",
    "            V_k = np.load(V_k_to_read)\n",
    "            tile_features_k = tile_features[:,0,0,:].dot(V_k)\n",
    "            print(tile_features_k.shape)\n",
    "            print(V_k.shape)\n",
    "            X = tile_features_k\n",
    "        else:\n",
    "            print('Using full feature set')\n",
    "            if subsequent_pass == 'yes':\n",
    "                print('second clustering pass..')\n",
    "                X = np.load(new_tile_features_to_read)\n",
    "            else:\n",
    "                tile_features = np.load(features_to_read)\n",
    "                X = tile_features[:,0,0,:]\n",
    "        \n",
    "        kmeans, labels, centers, silhouette_avg, cluster_silhouettes_averages, closest_tiles, \\\n",
    "            top_cluster_tiles_index = perform_feature_clustering(img, n_clusters, \\\n",
    "            n_closest_tiles, X, closest_tiles_to_write, remove_top_cluster, keep_only_top_cluster, \\\n",
    "            remove_largest_clusters, new_tile_features_to_write)\n",
    "        closest_tiles_list.append(closest_tiles)\n",
    "        top_cluster_tiles_index_list.append(top_cluster_tiles_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T22:13:35.588756",
     "start_time": "2017-05-13T22:13:34.938031"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img2268\n",
      "img2330\n",
      "img818\n",
      "img1474\n",
      "img2415\n",
      "img2117\n",
      "img1143\n",
      "img1198\n",
      "img617\n",
      "img569\n"
     ]
    }
   ],
   "source": [
    "# Interactive cell for viewing tiles of certain clusters\n",
    "top_tiles = np.argsort(pairwise_distances(centers, X))[np.argmax(cluster_silhouettes_averages), :n_closest_tiles]\n",
    "for t in top_tiles:\n",
    "    winname = 'img%d' % (t,)\n",
    "    print(winname)\n",
    "    cv2.imshow(winname, tile_img2[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T22:14:28.230526",
     "start_time": "2017-05-13T22:14:28.128514"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Random Tiles from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T22:03:05.565868",
     "start_time": "2017-05-23T22:03:00.672697"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Saving random tiles for Features of Image img1\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img2\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img9\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img11\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img14\n",
      "Start time:  2017-05-23 22:03:00\n",
      "End time:  2017-05-23 22:03:00\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img15\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img17\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img18\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img19\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img23\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img26\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img28\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img29\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img31\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img3\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5\n",
      "Start time:  2017-05-23 22:03:01\n",
      "End time:  2017-05-23 22:03:01\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img10\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img12\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img13\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img16\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img20\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img21\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img22\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img24\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img25\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img27\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img30\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img32\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4938\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4941\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4942\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4943\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img4944\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6188\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6290\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6666\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6667\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5854\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6402\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6405\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7010\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7013\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7298\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:02\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7299\n",
      "Start time:  2017-05-23 22:03:02\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8158\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TP\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TU\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TW\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TY\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6S7\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5963\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6688\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6689\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6691\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA87N\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7476\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7477\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7478\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7479\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7485\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7601\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7606\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7607\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7680\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7686\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7691\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7854\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7855\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7857\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7858\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7860\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7884\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8011\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8015\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8104\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8106\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8110\n",
      "Start time:  2017-05-23 22:03:03\n",
      "End time:  2017-05-23 22:03:03\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5396\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6668\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6669\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5849\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5874\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6397\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6399\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6400\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6401\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6404\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6408\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6410\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7008\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7014\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7015\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7018\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7294\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7301\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7302\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7309\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8164\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8165\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8168\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TS\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA5TT\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6S2\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6S3\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6S8\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img5964\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6690\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img6692\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7634\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7641\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img8189\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:04\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA4MT\n",
      "Start time:  2017-05-23 22:03:04\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6IZ\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image imgA6J1\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7467\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7469\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7470\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7471\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7472\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7480\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7481\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7602\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7605\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7616\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7620\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n",
      "Saving random tiles for Features of Image img7677\n",
      "Start time:  2017-05-23 22:03:05\n",
      "End time:  2017-05-23 22:03:05\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This cell saves to disk the \"random_tiles\" array per image -- which is the equivalent to \"closest_tiles\" with \n",
    "# the index of tiles derived randomly rather than by clustering of feature vectors\n",
    "# Later steps use either the \"random_tiles\" array or the \"closest_tiles\" array for testing\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    #Set clustering values\n",
    "    n_random_tiles = 100\n",
    "    \n",
    "    for i in images:\n",
    "        #Set names\n",
    "        img = 'img%s' % (i,)\n",
    "        random_tiles_to_write = images_root_dir + 'level%s/img%s_files/random_tiles' % (l, i)\n",
    "        features_to_read = images_root_dir + 'level%s/img%s_files/tile_features.npy' % (l, i)\n",
    "        tile_features = np.load(features_to_read)\n",
    "        features_random_tiles = np.random.choice(tile_features.shape[0], n_random_tiles, replace=False)\n",
    "\n",
    "        #Save closest tiles per cluster to disk\n",
    "        print('Saving random tiles for Features of Image', img)\n",
    "        print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        np.save(random_tiles_to_write, features_random_tiles)\n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print('_________________________________________')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile Train/Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:28.824188",
     "start_time": "2017-06-05T14:43:28.805754"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function reads feature vectors and index arrays, assembles the appropriate feature vectors and returns the array.\n",
    "\n",
    "def build_feature_data(image_list, selection_type, pca):\n",
    "        \n",
    "#     print('Retrieve features from disk and create array')\n",
    "    features_list = []\n",
    "    for i in image_list:\n",
    "        img = 'img%s' % (i,)\n",
    "        features_to_read = images_root_dir + 'level%s/img%s_files/tile_features.npy' % (l, i)\n",
    "        V_k_to_read = images_root_dir + 'level%s/img%s_files/V_k.npy' % (l, i)\n",
    "        \n",
    "        if selection_type == 'representative':\n",
    "            tiles_to_read = images_root_dir + 'level%s/img%s_files/closest_tiles.npy' % (l, i)\n",
    "        else:\n",
    "            tiles_to_read = images_root_dir + 'level%s/img%s_files/random_tiles.npy' % (l, i)\n",
    "            \n",
    "        tiles = np.load(tiles_to_read)\n",
    "        features = np.load(features_to_read)\n",
    "        features = features[:,0,0,:]\n",
    "        \n",
    "        if pca == 'yes':\n",
    "            V_k = np.load(V_k_to_read)\n",
    "            features = features.dot(V_k)\n",
    "            print('features shape', features.shape)\n",
    "            \n",
    "        features = np.array([features[tile] for _,tile in enumerate(tiles.flatten())])\n",
    "        features_list.append(features)\n",
    "    feature_data = np.array(features_list)\n",
    "    \n",
    "    return(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:29.683072",
     "start_time": "2017-06-05T14:43:29.672945"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function determines creates labels, concatenates data and returns X, y\n",
    "\n",
    "def prepare_data(X_astro, X_oligo):\n",
    "\n",
    "    X_astro = np.vstack(X_astro)\n",
    "    X_oligo = np.vstack(X_oligo)\n",
    "    \n",
    "    y_astro = np.ones((X_astro.shape[0],), dtype=int)\n",
    "    y_oligo = np.zeros((X_oligo.shape[0],), dtype=int)\n",
    "    \n",
    "    X = np.concatenate((X_astro, X_oligo), axis=0)\n",
    "    print('Shape of X', X.shape)\n",
    "    y = np.concatenate((y_astro, y_oligo), axis=0)\n",
    "    print('Shape of y', y.shape)\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier (Tile level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:31.374556",
     "start_time": "2017-06-05T14:43:31.367104"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function runs a grid search\n",
    "def grid_cv(classifier, params, X_train, y_train):\n",
    "    # Grid search and Cross validation\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    grid = GridSearchCV(classifier, params, scoring='accuracy', n_jobs=-1, cv=5, verbose=10)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:32.206360",
     "start_time": "2017-06-05T14:43:32.197174"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function trains a model from grid search best estimator\n",
    "def train_model_grid(grid, X_train, y_train):\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Train tiles\n",
    "    model = grid.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('____________________________')\n",
    "    print('grid', model)\n",
    "    print('X_train', X_train.shape)\n",
    "    print('y_train', y_train.shape)\n",
    "    print('____________________________')\n",
    "\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print('_________________________________________')\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:33.025932",
     "start_time": "2017-06-05T14:43:33.016728"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function trains an SVM model, specifying parameters\n",
    "def train_model(X_train, y_train):\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "#Train tiles\n",
    "    model = svm.SVC(C=1000, gamma=0.001, kernel='poly', max_iter=-1, probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "#     print('____________________________')\n",
    "#     print('model', model)\n",
    "#     print('X_train', X_train.shape)\n",
    "#     print('y_train', y_train.shape)\n",
    "#     print('____________________________')\n",
    "\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     print('_________________________________________')\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:34.173239",
     "start_time": "2017-06-05T14:43:34.165198"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function makes predictions for tiles and determines accuracy independent of images involved\n",
    "def test_model(model, X_test, y_test):\n",
    "    #Print out tile predictions    \n",
    "    model_predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, model_predictions)\n",
    "#     print(\"Accuracy: %f\\n\" % accuracy_score(y_test, model_predictions))\n",
    "#     print('Classification Report:')\n",
    "#     print(classification_report(y_test, model_predictions))\n",
    "\n",
    "    model_predictions_cm = confusion_matrix(y_test, model_predictions)\n",
    "#     print(model_predictions_cm)\n",
    "#     print('RMSE:',np.sqrt(mean_squared_error(y_test, model_predictions)))\n",
    "#     print('R2 Score:',r2_score(y_test, model_predictions))\n",
    "\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-01T07:08:13.665725",
     "start_time": "2017-05-01T07:08:13.661674"
    }
   },
   "source": [
    "### Image Level Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:39.068054",
     "start_time": "2017-06-05T14:43:39.039733"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function makes predictions for tiles for each image in the hold_out set and determines accuracies\n",
    "def test_images(model, X_hold_out, hold_out_images, hold_out_astro):\n",
    "\n",
    "    tile_proportion_correcta_list = []\n",
    "    img_actuals = []\n",
    "    img_predictions = []\n",
    "    img_accuracies = []\n",
    "    img_predictions_dict = {}\n",
    "    img_accuracies_dict = {}\n",
    "    \n",
    "    for i,im in enumerate(hold_out_images):\n",
    "        img = 'img%s' % (im,)\n",
    "        tile_predictions = model.predict(X_hold_out[i])\n",
    "        tile_probabilities = model.predict_proba(X_hold_out[i])\n",
    "        tile_probabilities_sum_astro = np.sum(tile_probabilities[:,1])\n",
    "        tile_probabilities_sum_oligo = np.sum(tile_probabilities[:,0])\n",
    "        \n",
    "        astro_count = np.sum(tile_predictions == 1)\n",
    "        oligo_count = np.sum(tile_predictions == 0)\n",
    "        \n",
    "        img_actual = \"\".join(['Astro' if im in hold_out_astro else 'Oligo'])\n",
    "        img_prediction = \"\".join(['Astro' if astro_count > oligo_count else 'Oligo'])\n",
    "        img_accuracy = [astro_count/len(tile_predictions) if img_actual == 'Astro' else oligo_count/len(tile_predictions)]\n",
    "        \n",
    "        img_actuals.append(img_actual)\n",
    "        img_predictions.append(img_prediction)\n",
    "        img_accuracies.append(img_accuracy)\n",
    "        img_accuracies_dict[im] = img_accuracy\n",
    "        img_predictions_dict[im] = img_prediction\n",
    "\n",
    "#Return arrays\n",
    "    img_predictions = np.array(img_predictions)\n",
    "    img_actuals = np.array(img_actuals)\n",
    "    img_accuracies = np.array(img_accuracies)\n",
    "    \n",
    "    return(img_accuracies, img_predictions, img_actuals, img_accuracies_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T16:19:51.504678",
     "start_time": "2017-06-05T16:19:51.477334"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function saves results objects to disk\n",
    "def save_results(model, grid, fold_accuracies_runs, img_accuracies_table_runs, description):\n",
    "    \n",
    "    print('Saving results to disk for run')\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    print('Saving model')\n",
    "    fileObject = open(run_dir + 'model_back', \"wb\")\n",
    "    pickle.dump(model, fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    print('Saving grid')\n",
    "    fileObject = open(run_dir + 'grid_back', \"wb\")\n",
    "    pickle.dump(grid, fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    print('Saving fold_accuracies_runs')\n",
    "    fileObject = open(run_dir + 'fold_accuracies_runs_back', \"wb\")\n",
    "    pickle.dump(fold_accuracies_runs, fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    print('Saving img_accuracies_table_runs')\n",
    "    fileObject = open(run_dir + 'img_accuracies_table_runs_back', \"wb\")\n",
    "    pickle.dump(img_accuracies_table_runs, fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    print('Saving description')\n",
    "    fileObject = open(run_dir + 'description', \"wb\")\n",
    "    pickle.dump(description, fileObject)\n",
    "    fileObject.close()\n",
    "\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T16:19:53.934308",
     "start_time": "2017-06-05T16:19:53.919484"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function loads results objects from disk\n",
    "def load_results(run_dir):\n",
    "    \n",
    "    fileObject = open(run_dir + 'model_back', \"rb\")\n",
    "    model_back = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    fileObject = open(run_dir + 'grid_back', \"rb\")\n",
    "    grid_back = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    fileObject = open(run_dir + 'fold_accuracies_runs_back', \"rb\")\n",
    "    fold_accuracies_runs_back = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    fileObject = open(run_dir + 'img_accuracies_table_runs_back', \"rb\")\n",
    "    img_accuracies_table_runs_back = pickle.load(fileObject)\n",
    "    fileObject.close()\n",
    "\n",
    "    return(model_back, grid_back, fold_accuracies_runs_back, img_accuracies_table_runs_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Cross Validation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T14:43:41.833371",
     "start_time": "2017-06-05T14:43:41.800038"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier switch is: xgb\n",
      "Test tile selection switch is: representative\n",
      "Use grid determined paramters switch is: yes\n",
      "PCA switch is: no\n"
     ]
    }
   ],
   "source": [
    "# This cell allows setting of a number of switches including classifier, parameters for grid search, random tile\n",
    "# selection versus tile selection through clustering, use of PCA or not. These selections are used in if/else\n",
    "# statements in other cells\n",
    "\n",
    "#Switches----------------------------------------------------\n",
    "\n",
    "#1. Classifier\n",
    "# classifier_used = 'rf'\n",
    "# classifier_used = 'svm'\n",
    "classifier_used = 'xgb'\n",
    "\n",
    "if classifier_used == 'svm':\n",
    "    classifier = svm.SVC()\n",
    "    svm_params = [{'kernel': ['poly', 'rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                      'C': [1e-2, 1e-1 ,1, 100, 1000]},\n",
    "                 {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "    params = svm_params\n",
    "\n",
    "elif classifier_used == 'rf':\n",
    "    classifier = RandomForestClassifier()\n",
    "    rf_params = [{'n_estimators': [1000, 2000], 'max_depth': [None, 4],\n",
    "                 'min_samples_split': [1, 2]}]\n",
    "    params = rf_params\n",
    "    \n",
    "else:\n",
    "    classifier = XGBClassifier()\n",
    "    xgb_params = {\n",
    "    'learning_rate':[.1,.2],\n",
    "    'n_estimators':[200],\n",
    "    'max_depth':[7],\n",
    "    'gamma':[0,.01],\n",
    "    'reg_alpha':[.1,.3],\n",
    "    'reg_lambda':[.3,.5],\n",
    "    'objective':['binary:logistic']\n",
    "    }\n",
    "    \n",
    "    params = xgb_params\n",
    "    \n",
    "# grid = GridSearchCV(gbm, param_grid, scoring='accuracy', n_jobs=-1, verbose=10, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "    \n",
    "#2. Test tiles selection type\n",
    "selection_type = 'representative'\n",
    "# selection_type = 'random'\n",
    "\n",
    "#3. Run new grid search?\n",
    "# use_gridsearch_parms = 'no'\n",
    "use_gridsearch_parms = 'yes'\n",
    "\n",
    "#4. Use PCA? Only applicable is clustering performed with PCA-reduced features\n",
    "# pca = 'yes'\n",
    "pca = 'no'\n",
    "\n",
    "#Switches---------------------------------------------------\n",
    "\n",
    "print('Classifier switch is:', classifier_used)\n",
    "print('Test tile selection switch is:', selection_type)\n",
    "print('Use grid determined paramters switch is:', use_gridsearch_parms)\n",
    "print('PCA switch is:', pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set indexes for machine learning runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-04T20:15:20.123349",
     "start_time": "2017-06-04T20:15:20.105231"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of astro images 16\n",
      "Number of oligo images 16\n",
      "Total number of images 32\n"
     ]
    }
   ],
   "source": [
    "# This cell used for setting indices of images for testing different machine learning scenarios\n",
    "\n",
    "\n",
    "# Original CBTC image sets\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "astro = astro1\n",
    "oligo = oligo1\n",
    "images = astro1 + oligo1\n",
    "\n",
    "\n",
    "\n",
    "# TCGA image sets\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# astro = astro2a\n",
    "# oligo = oligo2a\n",
    "# images = astro2a + oligo2a\n",
    "\n",
    "\n",
    "\n",
    "# Explore removing poor images - CBTC\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# astro = [1,2,7,8,9,11,14,15,17,18,19,23,26,28,29,31]\n",
    "# oligo = [3,4,5,6,10,12,13,16,20,21,22,24,25,27,30,32]\n",
    "# images = [1,2,7,8,9,11,14,15,17,18,19,23,26,28,29,31,3,4,5,6,10,12,13,16,20,21,22,24,25,27,30,32]\n",
    "\n",
    "# astro = [1,2,7,9,11,14,15,17,18,19,23,26,28]\n",
    "# oligo = [3,4,5,6,10,13,16,24,25,27,30,32]\n",
    "# images = [1,2,7,9,11,14,15,17,19,23,26,28,3,4,5,6,10,13,16,24,25,27,30,32]\n",
    "\n",
    "# astro = [1,2,7,9,11,14,15,17,18,19,26,28]\n",
    "# oligo = [3,4,5,6,10,12,16,20,24,25,27,30,32]\n",
    "\n",
    "# astro = [8,23,29,31]\n",
    "# oligo = [13,21,22,30]\n",
    "# images = [8,23,29,31,13,21,22,30]\n",
    "\n",
    "\n",
    "\n",
    "# Explore removing poor images - TCGA\n",
    "# Use both Grade 2 and Grade 3 images\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# images = images1 + images2a\n",
    "# #Remove small images with insufficient tiles (<100 tiles)\n",
    "# images = [i for i in images if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "# astro = astro1 + astro2a\n",
    "# astro = [i for i in astro if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "# oligo = oligo1 + oligo2a\n",
    "# oligo = [i for i in oligo if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "# astro = [i for i in astro if i not in lt30]\n",
    "# oligo = [i for i in oligo2a if i not in lt30]\n",
    "\n",
    "\n",
    "\n",
    "# Use only Grade 2 images\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# images = images1 + images2a_g2\n",
    "# images = [i for i in images if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "# astro = astro1 + astro2a_g2\n",
    "# astro = [i for i in astro if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "# oligo = oligo1 + oligo2a_g2\n",
    "# oligo = [i for i in oligo if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "\n",
    "\n",
    "print('Number of astro images' ,len(astro))\n",
    "print('Number of oligo images' ,len(oligo))\n",
    "print('Total number of images' ,len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T15:04:52.343071",
     "start_time": "2017-06-05T14:44:35.939798"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running new grid search...\n",
      "Building feature data arrays...\n",
      "Adding labels and concatenating data...\n",
      "Shape of X (3200, 2048)\n",
      "Shape of y (3200,)\n",
      "Setting up train/test split...\n",
      "Running grid search...\n",
      "Start time:  2017-06-05 14:44:44\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.839844 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.859100 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.849609 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.841797 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.835938 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.849609 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.859649 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.853801 - 2.2min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.837891 - 2.0min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.837891 - 2.0min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.845703 - 2.0min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.851852 - 2.0min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.849609 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.853229 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.857143 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.857700 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.845703 - 1.7min\n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.843750 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.859649 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.851562 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.841797 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.835938 - 2.0min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.843750 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.855186 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.855186 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  7.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.846004 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.859375 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.853516 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.847953 - 1.6min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.851562 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.849609 - 1.6min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.859100 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.847656 - 1.6min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.855186 - 1.5min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.851562 - 1.6min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.853801 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.835938 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.845703 - 1.6min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.839844 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.861057 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.833984 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.859649 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.843750 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.849609 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.868885 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 11.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.845703 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.861598 - 2.2min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.843750 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.855469 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.851272 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.865497 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.833984 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.841797 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.843750 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.1, score=0.853229 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.863548 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 13.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.835938 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.849903 - 1.8min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.843750 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.847656 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.849609 - 2.1min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.839844 - 1.7min\n",
      "[CV] reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.1, score=0.851272 - 2.1min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.849609 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.859100 - 1.6min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.841797 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.837891 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.846004 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.849903 - 1.6min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.841797 - 1.6min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.847656 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.1, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.855186 - 1.7min\n",
      "[CV] reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2 \n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.847656 - 1.7min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.859375 - 1.7min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.3, max_depth=7, learning_rate=0.2, score=0.853229 - 1.7min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.839844 - 1.8min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.841797 - 1.7min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.837891 - 1.8min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.853801 - 1.8min\n",
      "[CV]  reg_alpha=0.3, n_estimators=200, gamma=0.01, objective=binary:logistic, reg_lambda=0.5, max_depth=7, learning_rate=0.2, score=0.863014 - 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.1, 'n_estimators': 200, 'gamma': 0, 'objective': 'binary:logistic', 'reg_lambda': 0.5, 'max_depth': 7, 'learning_rate': 0.2}\n",
      "End time:  2017-06-05 15:04:52\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Only run this cell once to run a new grid search (and set up train/test set if not done elsewhere). \n",
    "\n",
    "print('Running new grid search...')\n",
    "\n",
    "#Build train data arrays based on image lists\n",
    "print('Building feature data arrays...')\n",
    "X_astro = build_feature_data(astro, selection_type, pca)\n",
    "X_oligo = build_feature_data(oligo, selection_type, pca)\n",
    "\n",
    "#Add labels and concatenate data\n",
    "print('Adding labels and concatenating data...')\n",
    "X, y = prepare_data(X_astro, X_oligo)\n",
    "\n",
    "#Train/Test\n",
    "print('Setting up train/test split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "#Run grid search up front on all images\n",
    "print('Running grid search...')\n",
    "grid = grid_cv(classifier, params, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T15:17:26.048020",
     "start_time": "2017-06-05T15:16:11.710050"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining tile level accuracy...\n",
      "Start time:  2017-06-05 15:16:11\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (2560, 2048)\n",
      "y_train (2560,)\n",
      "____________________________\n",
      "End time:  2017-06-05 15:17:26\n",
      "_________________________________________\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "# Build the model to determine baseline model accuracy at a tile level\n",
    "print('Determining tile level accuracy...')\n",
    "model = train_model_grid(grid, X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "tile_accuracy = test_model(model, X_test, y_test)\n",
    "print(tile_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image level cross validation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T18:40:40.899694",
     "start_time": "2017-06-05T18:35:28.765384"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with representative tiles...\n",
      "RUN NUMBER... 1\n",
      "_________________________________________\n",
      " \n",
      "Fold... 1\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [14  4]\n",
      "Train images: [ 7  8  9 11 12 17  3  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:35:37\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:35:56\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.768181818182\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.94  0.67]\n",
      "Average Tile level Image accuracy: 0.805\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.018225\n",
      "_________________________________________\n",
      " \n",
      "Fold... 2\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [12  6]\n",
      "Train images: [ 7  8  9 11 14 17  3  4  5 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:35:57\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:36:16\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.75\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Astro']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.63  0.45]\n",
      "Average Tile level Image accuracy: 0.54\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.0081\n",
      "_________________________________________\n",
      " \n",
      "Fold... 3\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [9 5]\n",
      "Train images: [ 7  8 11 12 14 17  3  4  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:36:17\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:36:36\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.777272727273\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.81  0.86]\n",
      "Average Tile level Image accuracy: 0.835\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.000625\n",
      "_________________________________________\n",
      " \n",
      "Fold... 4\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [11  3]\n",
      "Train images: [ 7  8  9 12 14 17  4  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:36:37\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:36:56\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.740909090909\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.9   0.82]\n",
      "Average Tile level Image accuracy: 0.86\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.0016\n",
      "_________________________________________\n",
      "Image level test summary:\n",
      "\n",
      "Tile level accuracies for fold 1 : 0.805\n",
      "Image level accuracies for fold 1 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 2 : 0.54\n",
      "Image level accuracies for fold 2 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 3 : 0.835\n",
      "Image level accuracies for fold 3 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 4 : 0.86\n",
      "Image level accuracies for fold 4 : 1.0\n",
      "\n",
      "Average Tile Level Overall accuracy for Run: 0.76\n",
      "\n",
      "Average Image Level accuracy for Run: 0.875\n",
      "Overall variance for Run: 0.046875\n",
      "_________________________________________\n",
      "RUN NUMBER... 2\n",
      "_________________________________________\n",
      " \n",
      "Fold... 1\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [7 6]\n",
      "Train images: [ 8  9 11 12 14 17  3  4  5 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:36:57\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:37:15\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.813636363636\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Astro']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.7   0.46]\n",
      "Average Tile level Image accuracy: 0.58\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.0144\n",
      "_________________________________________\n",
      " \n",
      "Fold... 2\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [17 13]\n",
      "Train images: [ 7  8  9 11 12 14  3  4  5  6 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:37:16\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:37:34\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.845454545455\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.68  0.51]\n",
      "Average Tile level Image accuracy: 0.595\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.007225\n",
      "_________________________________________\n",
      " \n",
      "Fold... 3\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [9 3]\n",
      "Train images: [ 7  8 11 12 14 17  4  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:37:35\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:37:54\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.781818181818\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.79  0.8 ]\n",
      "Average Tile level Image accuracy: 0.795\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 2.5e-05\n",
      "_________________________________________\n",
      " \n",
      "Fold... 4\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [12  5]\n",
      "Train images: [ 7  8  9 11 14 17  3  4  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:37:54\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:38:13\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.759090909091\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.63  0.87]\n",
      "Average Tile level Image accuracy: 0.75\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.0144\n",
      "_________________________________________\n",
      "Image level test summary:\n",
      "\n",
      "Tile level accuracies for fold 1 : 0.58\n",
      "Image level accuracies for fold 1 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 2 : 0.595\n",
      "Image level accuracies for fold 2 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 3 : 0.795\n",
      "Image level accuracies for fold 3 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 4 : 0.75\n",
      "Image level accuracies for fold 4 : 1.0\n",
      "\n",
      "Average Tile Level Overall accuracy for Run: 0.68\n",
      "\n",
      "Average Image Level accuracy for Run: 0.875\n",
      "Overall variance for Run: 0.046875\n",
      "_________________________________________\n",
      "RUN NUMBER... 3\n",
      "_________________________________________\n",
      " \n",
      "Fold... 1\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [14  4]\n",
      "Train images: [ 7  8  9 11 12 17  3  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:38:13\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:38:32\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.768181818182\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.94  0.67]\n",
      "Average Tile level Image accuracy: 0.805\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.018225\n",
      "_________________________________________\n",
      " \n",
      "Fold... 2\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [11  6]\n",
      "Train images: [ 7  8  9 12 14 17  3  4  5 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:38:32\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:38:49\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.795454545455\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Astro']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.88  0.43]\n",
      "Average Tile level Image accuracy: 0.655\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.050625\n",
      "_________________________________________\n",
      " \n",
      "Fold... 3\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [17  5]\n",
      "Train images: [ 7  8  9 11 12 14  3  4  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:38:50\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:39:07\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.745454545455\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Oligo' 'Oligo']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.5   0.87]\n",
      "Average Tile level Image accuracy: 0.685\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.034225\n",
      "_________________________________________\n",
      " \n",
      "Fold... 4\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [8 3]\n",
      "Train images: [ 7  9 11 12 14 17  4  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:39:08\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:39:25\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.831818181818\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Oligo' 'Oligo']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.09  0.79]\n",
      "Average Tile level Image accuracy: 0.44\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.1225\n",
      "_________________________________________\n",
      "Image level test summary:\n",
      "\n",
      "Tile level accuracies for fold 1 : 0.805\n",
      "Image level accuracies for fold 1 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 2 : 0.655\n",
      "Image level accuracies for fold 2 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 3 : 0.685\n",
      "Image level accuracies for fold 3 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 4 : 0.44\n",
      "Image level accuracies for fold 4 : 0.5\n",
      "\n",
      "Average Tile Level Overall accuracy for Run: 0.64625\n",
      "\n",
      "Average Image Level accuracy for Run: 0.625\n",
      "Overall variance for Run: 0.046875\n",
      "_________________________________________\n",
      "RUN NUMBER... 4\n",
      "_________________________________________\n",
      " \n",
      "Fold... 1\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [9 5]\n",
      "Train images: [ 7  8 11 12 14 17  3  4  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:39:25\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:39:44\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.777272727273\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Oligo']\n",
      "Correct image predictions 2\n",
      "\n",
      "Tile level accuracies per image: [ 0.81  0.86]\n",
      "Average Tile level Image accuracy: 0.835\n",
      "\n",
      "Image level accuracy for fold: 1.0\n",
      "Image level variance for fold: 0.000625\n",
      "_________________________________________\n",
      " \n",
      "Fold... 2\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [11 30]\n",
      "Train images: [ 7  8  9 12 14 17  3  4  5  6 13]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:39:44\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:40:01\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.795454545455\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Astro' 'Astro']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.88  0.38]\n",
      "Average Tile level Image accuracy: 0.63\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.0625\n",
      "_________________________________________\n",
      " \n",
      "Fold... 3\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [17  4]\n",
      "Train images: [ 7  8  9 11 12 14  3  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:40:02\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:40:21\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.781818181818\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Oligo' 'Oligo']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.46  0.72]\n",
      "Average Tile level Image accuracy: 0.59\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.0169\n",
      "_________________________________________\n",
      " \n",
      "Fold... 4\n",
      "Train/Test Split: 11 / 2\n",
      " \n",
      "Hold out images: [8 3]\n",
      "Train images: [ 7  9 11 12 14 17  4  5  6 13 30]\n",
      "Shape of X (1100, 2048)\n",
      "Shape of y (1100,)\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-06-05 18:40:21\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.5,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (880, 2048)\n",
      "y_train (880,)\n",
      "____________________________\n",
      "End time:  2017-06-05 18:40:40\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.831818181818\n",
      "\n",
      "Labels for images: ['Astro' 'Oligo']\n",
      "Predictions for images: ['Oligo' 'Oligo']\n",
      "Correct image predictions 1\n",
      "\n",
      "Tile level accuracies per image: [ 0.09  0.79]\n",
      "Average Tile level Image accuracy: 0.44\n",
      "\n",
      "Image level accuracy for fold: 0.5\n",
      "Image level variance for fold: 0.1225\n",
      "_________________________________________\n",
      "Image level test summary:\n",
      "\n",
      "Tile level accuracies for fold 1 : 0.835\n",
      "Image level accuracies for fold 1 : 1.0\n",
      "\n",
      "Tile level accuracies for fold 2 : 0.63\n",
      "Image level accuracies for fold 2 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 3 : 0.59\n",
      "Image level accuracies for fold 3 : 0.5\n",
      "\n",
      "Tile level accuracies for fold 4 : 0.44\n",
      "Image level accuracies for fold 4 : 0.5\n",
      "\n",
      "Average Tile Level Overall accuracy for Run: 0.62375\n",
      "\n",
      "Average Image Level accuracy for Run: 0.625\n",
      "Overall variance for Run: 0.046875\n",
      "_________________________________________\n",
      "Average tile level accuracy for Run 1 : 0.76\n",
      "Average Image Level accuracy for Run 1 : 0.875\n",
      "\n",
      "Average tile level accuracy for Run 2 : 0.68\n",
      "Average Image Level accuracy for Run 2 : 0.875\n",
      "\n",
      "Average tile level accuracy for Run 3 : 0.64625\n",
      "Average Image Level accuracy for Run 3 : 0.625\n",
      "\n",
      "Average tile level accuracy for Run 4 : 0.62375\n",
      "Average Image Level accuracy for Run 4 : 0.625\n",
      "\n",
      "\n",
      "Cross run Tile Level training accuracy for Run 4 : 0.785227272727\n",
      "Cross run Tile Level test accuracy: 0.6775\n",
      "\n",
      "_____________________________________________________________\n",
      "Cross run Image Level accuracy: 0.75\n",
      "Cross run Image Level variance: 0.015625\n",
      "_____________________________________________________________\n",
      "\n",
      "Cross run average accuracy per image:\n",
      "3     0.800000\n",
      "4     0.686667\n",
      "5     0.865000\n",
      "6     0.446667\n",
      "7     0.700000\n",
      "8     0.090000\n",
      "9     0.803333\n",
      "11    0.886667\n",
      "12    0.630000\n",
      "13    0.510000\n",
      "14    0.940000\n",
      "17    0.546667\n",
      "30    0.380000\n",
      "dtype: float64\n",
      "\n",
      "Cross run average accuracy per astro image:\n",
      "7     0.700000\n",
      "8     0.090000\n",
      "9     0.803333\n",
      "11    0.886667\n",
      "12    0.630000\n",
      "14    0.940000\n",
      "17    0.546667\n",
      "dtype: float64\n",
      "\n",
      "Cross run astro accuracy: 0.6566666666666666\n",
      "Cross run astro variance: 0.08174814814814814\n",
      "\n",
      "Cross run average accuracy per oligo image:\n",
      "3     0.800000\n",
      "4     0.686667\n",
      "5     0.865000\n",
      "6     0.446667\n",
      "13    0.510000\n",
      "30    0.380000\n",
      "dtype: float64\n",
      "\n",
      "Cross run oligo accuracy: 0.6147222222222223\n",
      "Cross run oligo variance: 0.03928935185185185\n",
      "Saving results in /Volumes/2T_HD/Masters_Project/results/181/\n",
      "Saving results to disk for run\n",
      "Start time:  2017-06-05 18:40:40\n",
      "Saving model\n",
      "Saving grid\n",
      "Saving fold_accuracies_runs\n",
      "Saving img_accuracies_table_runs\n",
      "Saving description\n",
      "End time:  2017-06-05 18:40:40\n"
     ]
    }
   ],
   "source": [
    "# Interactive K-fold Image cross validation\n",
    "# Number f folds and runs is set. The hold out set is selected randomly and remaining images placed into train set. \n",
    "# Loops through all images in hold out set.\n",
    "# Accuracies kept per image, per fold, per run\n",
    "\n",
    "description = 'CBTC images, 4 folds, 4 runs, clustering, relabeled by removing 50/50 bets -- second set of astro'\n",
    "run_dir = results_dir + '181/'\n",
    "\n",
    "#Runs\n",
    "runs = 4\n",
    "\n",
    "# Select number of folds: 2, 4, 8, 16\n",
    "folds = 4\n",
    "\n",
    "print('Running with', selection_type, 'tiles...')\n",
    "\n",
    "fold_accuracies_runs = []\n",
    "fold_training_accuracies_runs = []\n",
    "tile_fold_accuracies_runs = []\n",
    "img_accuracies_table_runs = pd.DataFrame([])\n",
    "\n",
    "for r in range(runs):\n",
    "    \n",
    "    fold_training_accuracies = []\n",
    "    fold_accuracies = []\n",
    "    tile_fold_accuracies = []\n",
    "    img_accuracies_table = pd.DataFrame([])\n",
    "    fold = 0\n",
    "    print('RUN NUMBER...', r+1)\n",
    "    \n",
    "    # Train model for each set of images left after hold out images removed. \n",
    "    # Randomly select images to hold out.\n",
    "    # Ensure an even number of astro and oligo images are chosen\n",
    "    for i,j in zip(np.random.choice(astro, (folds, int(len(astro)/folds)), replace=False), np.random.choice(oligo, (folds, int(len(oligo)/folds)), replace=False)):\n",
    "        \n",
    "        hold_out_astro = i\n",
    "        hold_out_oligo = j\n",
    "        hold_out_images = np.hstack((hold_out_astro, hold_out_oligo))\n",
    "        fold += 1\n",
    "        \n",
    "        # Determine Training images by removing hold_out images numbers from astro and oligo\n",
    "        train_astro = [x for _,x in enumerate(astro) if x not in hold_out_astro]\n",
    "        train_oligo = [x for _,x in enumerate(oligo) if x not in hold_out_oligo]\n",
    "        train_images = np.hstack((train_astro, train_oligo))\n",
    "\n",
    "        print('_________________________________________')\n",
    "        print(' ')\n",
    "        print('Fold...', fold)\n",
    "        print('Train/Test Split:', (len(astro)-int(len(astro)/folds)+len(oligo)-int(len(oligo)/folds)), '/', (int(len(astro)/folds)+int(len(astro)/folds)))\n",
    "\n",
    "        print(' ')\n",
    "        print('Hold out images:', hold_out_images)\n",
    "        print('Train images:', train_images)\n",
    "\n",
    "        #Build train data arrays based on image lists\n",
    "    #     print('Building feature data arrays...')\n",
    "        X_astro = build_feature_data(train_astro, selection_type, pca)\n",
    "        X_oligo = build_feature_data(train_oligo, selection_type, pca)\n",
    "\n",
    "        #Add labels and concatenate data\n",
    "    #     print('Adding labels and concatenating data...')\n",
    "        X, y = prepare_data(X_astro, X_oligo)\n",
    "\n",
    "        #Train/Test\n",
    "    #     print('Setting up train/test split...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "        #Train model for this fold over training images\n",
    "        print('')\n",
    "        if use_gridsearch_parms == 'yes':\n",
    "            print('Training tiles with grid search determined parameters with classifier',classifier_used,'...')\n",
    "            model = train_model_grid(grid, X_train, y_train)\n",
    "        else:\n",
    "            print('Training tiles with statically defined parameters and classifier',classifier_used,'...')\n",
    "            model = train_model(X_train, y_train)\n",
    "            \n",
    "        training_tile_accuracy = test_model(model, X_test, y_test)\n",
    "        print('Tile level accuracy (training images):', training_tile_accuracy)\n",
    "    #     print('_________________________________________')\n",
    "\n",
    "        #Build test images\n",
    "        X_hold_out = build_feature_data(hold_out_images, selection_type, pca)\n",
    "\n",
    "        #Image level test\n",
    "        img_accuracies, img_predictions, img_actuals, img_accuracies_dict = test_images(model, X_hold_out, hold_out_images, hold_out_astro)\n",
    "\n",
    "        #Determine and print accuracy\n",
    "        fold_accuracy = len(np.where(img_predictions == img_actuals)[0])/len(hold_out_images)\n",
    "        fold_training_accuracies.append(training_tile_accuracy)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "        tile_fold_accuracy = img_accuracies.mean()\n",
    "        tile_fold_accuracies.append(tile_fold_accuracy)\n",
    "        \n",
    "        img_accuracies_col = pd.DataFrame.from_dict(img_accuracies_dict, orient='index')\n",
    "        img_accuracies_col.columns = [r+1]\n",
    "        img_accuracies_table = pd.concat([img_accuracies_table, img_accuracies_col]).sort_index()\n",
    "\n",
    "    #     print('_________________________________________')\n",
    "        print('')\n",
    "        print('Labels for images:', img_actuals)\n",
    "        print('Predictions for images:', img_predictions)\n",
    "        print('Correct image predictions', len(np.where(img_predictions == img_actuals)[0]))\n",
    "        print('')\n",
    "        print('Tile level accuracies per image:', img_accuracies[:,0])\n",
    "        print('Average Tile level Image accuracy:', tile_fold_accuracy)\n",
    "        print('')\n",
    "        print('Image level accuracy for fold:', fold_accuracy)\n",
    "        print('Image level variance for fold:', img_accuracies.var())\n",
    "\n",
    "    #Overall average accuracy and variance\n",
    "    fold_accuracies = np.array(fold_accuracies)\n",
    "    fold_training_accuracies = np.array(fold_training_accuracies)\n",
    "    tile_fold_accuracies = np.array(tile_fold_accuracies)\n",
    "    average_tile_fold_accuracies = tile_fold_accuracies.mean()\n",
    "    average_fold_accuracies = fold_accuracies.mean()\n",
    "    average_fold_training_accuracies = fold_training_accuracies.mean()\n",
    "    tile_fold_accuracies_runs.append(average_tile_fold_accuracies)\n",
    "    fold_accuracies_runs.append(average_fold_accuracies)\n",
    "    fold_training_accuracies_runs.append(average_fold_training_accuracies)\n",
    "\n",
    "    img_accuracies_table_runs = pd.concat([img_accuracies_table_runs, img_accuracies_table], axis=1).sort_index()\n",
    "\n",
    "    print('_________________________________________')\n",
    "    print('Image level test summary:')\n",
    "    print('')\n",
    "    for f in range(folds):\n",
    "        print('Tile level accuracies for fold', f+1, ':',tile_fold_accuracies[f])\n",
    "        print('Image level accuracies for fold', f+1, ':',fold_accuracies[f])\n",
    "        print('')\n",
    "        \n",
    "    print('Average Tile Level Overall accuracy for Run:', tile_fold_accuracies.mean())\n",
    "    print('')\n",
    "    print('Average Image Level accuracy for Run:', fold_accuracies.mean())\n",
    "    print('Overall variance for Run:', fold_accuracies.var())\n",
    "    print('_________________________________________')\n",
    "\n",
    "tile_fold_accuracies_runs = np.array(tile_fold_accuracies_runs)\n",
    "fold_accuracies_runs = np.array(fold_accuracies_runs)\n",
    "fold_training_accuracies_runs = np.array(fold_training_accuracies_runs)\n",
    "\n",
    "for r in range(runs):\n",
    "    print('Average tile level accuracy for Run', r+1, ':',tile_fold_accuracies_runs[r])\n",
    "    print('Average Image Level accuracy for Run', r+1, ':',fold_accuracies_runs[r])\n",
    "    print('')\n",
    "print('')\n",
    "print('Cross run Tile Level training accuracy for Run', r+1, ':',fold_training_accuracies_runs.mean())\n",
    "print('Cross run Tile Level test accuracy:', tile_fold_accuracies_runs.mean())\n",
    "print('')\n",
    "print('_____________________________________________________________')\n",
    "print('Cross run Image Level accuracy:', fold_accuracies_runs.mean())\n",
    "print('Cross run Image Level variance:', fold_accuracies_runs.var())\n",
    "print('_____________________________________________________________')\n",
    "print('')\n",
    "print('Cross run average accuracy per image:')\n",
    "print(img_accuracies_table_runs.mean(axis=1))\n",
    "print('')\n",
    "print('Cross run average accuracy per astro image:')\n",
    "print(img_accuracies_table_runs.loc[astro,:].mean(axis=1))\n",
    "print('')\n",
    "print('Cross run astro accuracy:', img_accuracies_table_runs.loc[astro,:].mean(axis=1).mean(axis=0))\n",
    "print('Cross run astro variance:', img_accuracies_table_runs.loc[astro,:].mean(axis=1).var(axis=0))\n",
    "print('')\n",
    "print('Cross run average accuracy per oligo image:')\n",
    "print(img_accuracies_table_runs.loc[oligo,:].mean(axis=1))\n",
    "print('')\n",
    "print('Cross run oligo accuracy:', img_accuracies_table_runs.loc[oligo,:].mean(axis=1).mean(axis=0))\n",
    "print('Cross run oligo variance:', img_accuracies_table_runs.loc[oligo,:].mean(axis=1).var(axis=0))\n",
    "\n",
    "\n",
    "#Save results\n",
    "\n",
    "print('Saving results in', run_dir)\n",
    "call(['mkdir', run_dir])\n",
    "save_results(model, grid, fold_accuracies_runs, img_accuracies_table_runs, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-22T12:49:43.967491",
     "start_time": "2017-05-22T12:49:43.955558"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(53, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lt30 = img_accuracies_table_runs.loc[img_accuracies_table_runs.mean(axis=1) <= .3]\n",
    "display(lt30.shape)\n",
    "display(img_accuracies_table_runs.loc[img_accuracies_table_runs.mean(axis=1).between(.3, .7, inclusive=True)].shape)\n",
    "display(img_accuracies_table_runs.loc[img_accuracies_table_runs.mean(axis=1) >= .7].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5: Inter-Imageset Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Indexes for Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-04T17:06:59.708276",
     "start_time": "2017-06-04T17:06:59.567587"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 7, 9, 11, 14, 15, 17, 18, 19, 26, 28]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 10, 12, 16, 20, 24, 25, 27, 30, 32]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[8, 23, 29, 31]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[13, 21, 22]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['4938',\n",
       " '4941',\n",
       " '4942',\n",
       " '4943',\n",
       " '4944',\n",
       " '6188',\n",
       " '6290',\n",
       " '6666',\n",
       " '6691',\n",
       " '6667',\n",
       " '5854',\n",
       " '7013',\n",
       " '8158',\n",
       " 'A5TP',\n",
       " 'A5TU',\n",
       " 'A5TY',\n",
       " '5963',\n",
       " '6688',\n",
       " '6689',\n",
       " 'A87N',\n",
       " '7477',\n",
       " '7478',\n",
       " '7479',\n",
       " '7485',\n",
       " '7601',\n",
       " '7680',\n",
       " '7686',\n",
       " '7691',\n",
       " '7854',\n",
       " '7855',\n",
       " '7857',\n",
       " '7858',\n",
       " '7860',\n",
       " '8011',\n",
       " '8015',\n",
       " '8104',\n",
       " '8106',\n",
       " '8110']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['5396',\n",
       " '6668',\n",
       " '5849',\n",
       " '5874',\n",
       " '6397',\n",
       " '6399',\n",
       " '6404',\n",
       " '6410',\n",
       " '7008',\n",
       " '7015',\n",
       " '7018',\n",
       " '7294',\n",
       " '7301',\n",
       " '7302',\n",
       " '7309',\n",
       " '8164',\n",
       " '8165',\n",
       " '8168',\n",
       " 'A5TS',\n",
       " 'A6S8',\n",
       " '6690',\n",
       " '6692',\n",
       " 'A6IZ',\n",
       " 'A6J1',\n",
       " '7469',\n",
       " '7471',\n",
       " '7472',\n",
       " '7480',\n",
       " '7616',\n",
       " '7677',\n",
       " '6400',\n",
       " 'A5TT']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['4938',\n",
       " '4941',\n",
       " '4942',\n",
       " '4943',\n",
       " '4944',\n",
       " '6188',\n",
       " '6290',\n",
       " '6666',\n",
       " '6667',\n",
       " '5854',\n",
       " '6402',\n",
       " '6405',\n",
       " '7010',\n",
       " '7013',\n",
       " '7298',\n",
       " '7299',\n",
       " '8158',\n",
       " 'A5TP',\n",
       " 'A5TU',\n",
       " 'A5TW',\n",
       " 'A5TY',\n",
       " 'A6S7',\n",
       " '5963',\n",
       " '6688',\n",
       " '6689',\n",
       " '6691',\n",
       " 'A87N',\n",
       " '7476',\n",
       " '7477',\n",
       " '7478',\n",
       " '7479',\n",
       " '7485',\n",
       " '7601',\n",
       " '7606',\n",
       " '7607',\n",
       " '7680',\n",
       " '7686',\n",
       " '7691',\n",
       " '7854',\n",
       " '7855',\n",
       " '7857',\n",
       " '7858',\n",
       " '7860',\n",
       " '7884',\n",
       " '8011',\n",
       " '8015',\n",
       " '8104',\n",
       " '8106',\n",
       " '8110']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['5396',\n",
       " '6668',\n",
       " '6669',\n",
       " '5849',\n",
       " '5874',\n",
       " '6397',\n",
       " '6399',\n",
       " '6400',\n",
       " '6401',\n",
       " '6404',\n",
       " '6408',\n",
       " '6410',\n",
       " '7008',\n",
       " '7014',\n",
       " '7015',\n",
       " '7018',\n",
       " '7294',\n",
       " '7301',\n",
       " '7302',\n",
       " '7309',\n",
       " '8164',\n",
       " '8165',\n",
       " '8168',\n",
       " 'A5TS',\n",
       " 'A5TT',\n",
       " 'A6S2',\n",
       " 'A6S3',\n",
       " 'A6S8',\n",
       " '5964',\n",
       " '6690',\n",
       " '6692',\n",
       " '7634',\n",
       " '7641',\n",
       " '8189',\n",
       " 'A4MT',\n",
       " 'A6IZ',\n",
       " 'A6J1',\n",
       " '7467',\n",
       " '7469',\n",
       " '7470',\n",
       " '7471',\n",
       " '7472',\n",
       " '7480',\n",
       " '7481',\n",
       " '7602',\n",
       " '7605',\n",
       " '7616',\n",
       " '7620',\n",
       " '7677']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subsets labelled for ease of testing\n",
    "\n",
    "subset1_A = [1,2,7,9,11,14,15,17,18,19,26,28]\n",
    "subset2_O = [3,4,5,6,10,12,16,20,24,25,27,30,32]\n",
    "subset3_A = [8,23,29,31]\n",
    "subset4_O = [13,21,22]\n",
    "\n",
    "subset1_ATCGA = ['4938','4941','4942','4943','4944','6188','6290',\\\n",
    "         '6666','6691','6667','5854','7013','8158','A5TP','A5TU','A5TY','5963','6688','6689','A87N','7477','7478',\\\n",
    "         '7479','7485','7601','7680','7686','7691','7854','7855','7857','7858','7860','8011','8015','8104','8106',\\\n",
    "                 '8110']\n",
    "               \n",
    "subset2_OTCGA = ['5396','6668','5849','5874','6397',\\\n",
    "         '6399','6404','6410','7008','7015','7018','7294','7301','7302','7309','8164','8165','8168','A5TS','A6S8',\\\n",
    "         '6690','6692','A6IZ','A6J1','7469','7471','7472','7480','7616','7677','6400','A5TT']\n",
    "\n",
    "subset3_ATCGA = [i for i in astro2a if i not in subset1_A]\n",
    "subset4_OTCGA = [i for i in oligo2a if i not in subset2_O]\n",
    "\n",
    "display(subset1_A)\n",
    "display(subset2_O)\n",
    "display(subset3_A)\n",
    "display(subset4_O)\n",
    "display(subset1_ATCGA)\n",
    "display(subset2_OTCGA)\n",
    "display(subset3_ATCGA)\n",
    "display(subset4_OTCGA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T09:30:02.047656",
     "start_time": "2017-05-31T09:29:16.826195"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________\n",
      "Test images: ['6186', '5851', '5852', '5853', '5855', '5871', '5872', '6395', '6542', '7019', '7304', '7306', '8162', '8163', '8166', '8167', 'A5TR', 'A6S6', '5965', '7637', '7643', '8186', 'A4MU', 'A60K', 'A713', '7473', '7474', '7475', '7482', '7608', '7609', '7610', '7611', '7681', '7684', '7690', '7692', '7873', '7879', '7880', '7902', '8013', '8018']\n",
      "Train images: [ 1  2  7  9 11 14 15 17 18 19 26 28 13 21 22]\n",
      " \n",
      "_________________________________________\n",
      "Shape of X (1500, 2048)\n",
      "Shape of y (1500,)\n",
      "Setting up train/test split for training images...\n",
      "\n",
      "Training tiles with grid search determined parameters with classifier xgb ...\n",
      "Start time:  2017-05-31 09:29:22\n",
      "____________________________\n",
      "grid XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.3,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "X_train (1200, 2048)\n",
      "y_train (1200,)\n",
      "____________________________\n",
      "End time:  2017-05-31 09:29:57\n",
      "_________________________________________\n",
      "Tile level accuracy (training images): 0.823333333333\n",
      "_________________________________________\n",
      "Image Test Results...\n",
      "x test (43, 100, 2048)\n",
      "For image: img6186\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 94.3543\n",
      "Probabilities of oligo: 5.64571\n",
      "\n",
      "For image: img5851\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 84.9164\n",
      "Probabilities of oligo: 15.0836\n",
      "\n",
      "For image: img5852\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 74.1018\n",
      "Probabilities of oligo: 25.8982\n",
      "\n",
      "For image: img5853\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 75.3746\n",
      "Probabilities of oligo: 24.6254\n",
      "\n",
      "For image: img5855\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 96.317\n",
      "Probabilities of oligo: 3.68304\n",
      "\n",
      "For image: img5871\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 70.6655\n",
      "Probabilities of oligo: 29.3345\n",
      "\n",
      "For image: img5872\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 71.0623\n",
      "Probabilities of oligo: 28.9377\n",
      "\n",
      "For image: img6395\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 78.4115\n",
      "Probabilities of oligo: 21.5885\n",
      "\n",
      "For image: img6542\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.9674\n",
      "Probabilities of oligo: 6.03255\n",
      "\n",
      "For image: img7019\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.4858\n",
      "Probabilities of oligo: 6.51416\n",
      "\n",
      "For image: img7304\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 90.856\n",
      "Probabilities of oligo: 9.14401\n",
      "\n",
      "For image: img7306\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 86.7279\n",
      "Probabilities of oligo: 13.2721\n",
      "\n",
      "For image: img8162\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 62.0673\n",
      "Probabilities of oligo: 37.9327\n",
      "\n",
      "For image: img8163\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 90.8431\n",
      "Probabilities of oligo: 9.15692\n",
      "\n",
      "For image: img8166\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 82.8833\n",
      "Probabilities of oligo: 17.1167\n",
      "\n",
      "For image: img8167\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 90.2192\n",
      "Probabilities of oligo: 9.78079\n",
      "\n",
      "For image: imgA5TR\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 95.6085\n",
      "Probabilities of oligo: 4.39151\n",
      "\n",
      "For image: imgA6S6\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 96.6064\n",
      "Probabilities of oligo: 3.39359\n",
      "\n",
      "For image: img5965\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 94.6626\n",
      "Probabilities of oligo: 5.33742\n",
      "\n",
      "For image: img7637\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 96.1873\n",
      "Probabilities of oligo: 3.81268\n",
      "\n",
      "For image: img7643\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 56.3702\n",
      "Probabilities of oligo: 43.6298\n",
      "\n",
      "For image: img8186\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 96.1526\n",
      "Probabilities of oligo: 3.84744\n",
      "\n",
      "For image: imgA4MU\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.8559\n",
      "Probabilities of oligo: 6.14405\n",
      "\n",
      "For image: imgA60K\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 95.5519\n",
      "Probabilities of oligo: 4.44808\n",
      "\n",
      "For image: imgA713\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 97.0687\n",
      "Probabilities of oligo: 2.93134\n",
      "\n",
      "For image: img7473\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 92.9631\n",
      "Probabilities of oligo: 7.03689\n",
      "\n",
      "For image: img7474\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 98.4509\n",
      "Probabilities of oligo: 1.54911\n",
      "\n",
      "For image: img7475\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 97.843\n",
      "Probabilities of oligo: 2.15695\n",
      "\n",
      "For image: img7482\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.1181\n",
      "Probabilities of oligo: 6.8819\n",
      "\n",
      "For image: img7608\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 95.8931\n",
      "Probabilities of oligo: 4.10689\n",
      "\n",
      "For image: img7609\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 82.6392\n",
      "Probabilities of oligo: 17.3608\n",
      "\n",
      "For image: img7610\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 92.5553\n",
      "Probabilities of oligo: 7.44466\n",
      "\n",
      "For image: img7611\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 90.8709\n",
      "Probabilities of oligo: 9.1291\n",
      "\n",
      "For image: img7681\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 95.3144\n",
      "Probabilities of oligo: 4.68565\n",
      "\n",
      "For image: img7684\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.8074\n",
      "Probabilities of oligo: 6.19263\n",
      "\n",
      "For image: img7690\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 93.9981\n",
      "Probabilities of oligo: 6.00189\n",
      "\n",
      "For image: img7692\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 91.6171\n",
      "Probabilities of oligo: 8.38288\n",
      "\n",
      "For image: img7873\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 92.6514\n",
      "Probabilities of oligo: 7.34861\n",
      "\n",
      "For image: img7879\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 71.1275\n",
      "Probabilities of oligo: 28.8725\n",
      "\n",
      "For image: img7880\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 91.9224\n",
      "Probabilities of oligo: 8.07765\n",
      "\n",
      "For image: img7902\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 84.3652\n",
      "Probabilities of oligo: 15.6348\n",
      "\n",
      "For image: img8013\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 92.1786\n",
      "Probabilities of oligo: 7.82137\n",
      "\n",
      "For image: img8018\n",
      "The label is: Oligoastro\n",
      "The prediction is: Astro\n",
      "Probabilities of astro: 94.3688\n",
      "Probabilities of oligo: 5.63118\n",
      "\n",
      "_________________________________________\n",
      "Astro predictions: 43\n",
      "Astro predictions correct: 0\n",
      "Oligo predictions: 0\n",
      "Oligo predictions correct: 0\n",
      "astro_probabilities [94.354286, 84.916374, 74.101791, 75.374603, 96.316963, 70.665474, 71.062325, 78.411499, 93.967445, 93.485832, 90.855988, 86.727936, 62.067348, 90.843079, 82.883278, 90.219215, 95.60849, 96.6064, 94.662575, 96.187332, 56.370239, 96.152565, 93.855949, 95.551918, 97.068657, 92.963097, 98.45089, 97.843048, 93.11808, 95.893105, 82.639206, 92.555336, 90.870895, 95.314362, 93.807358, 93.998116, 91.617119, 92.65139, 71.127472, 91.922363, 84.365166, 92.178627, 94.36882]\n",
      "oligo_probabilities [5.6457067, 15.083626, 25.898205, 24.625402, 3.6830413, 29.334536, 28.937672, 21.588509, 6.032548, 6.5141597, 9.1440096, 13.272056, 37.932652, 9.1569242, 17.116728, 9.7807865, 4.3915119, 3.393594, 5.3374224, 3.8126752, 43.629761, 3.8474376, 6.1440501, 4.4480829, 2.9313381, 7.0368905, 1.5491109, 2.1569505, 6.8819017, 4.1068912, 17.360798, 7.444665, 9.1290989, 4.6856518, 6.1926303, 6.0018854, 8.3828812, 7.3486075, 28.87253, 8.0776453, 15.634838, 7.821373, 5.6311798]\n"
     ]
    }
   ],
   "source": [
    "# Interactive Image test\n",
    "# Allows training of TCGA set and testing against the CBTC set.\n",
    "# Prints out predictions and accuracies for each image and overall for run\n",
    "\n",
    "#Actuals\n",
    "astro = astro1\n",
    "oligo = oligo1\n",
    "mixed = mixed2a\n",
    "\n",
    "#Test\n",
    "testing_images = images2a\n",
    "\n",
    "#Train\n",
    "train_astro = astro1\n",
    "train_oligo = oligo1\n",
    "train_images = np.hstack((train_astro, train_oligo))\n",
    "\n",
    "#Run Directory to save cnn model\n",
    "run_dir = results_dir + '200/'\n",
    "print('Saving results in', run_dir)\n",
    "call(['mkdir', run_dir])\n",
    "\n",
    "print('_________________________________________')\n",
    "print('Test images:', testing_images)\n",
    "print('Train images:', train_images)\n",
    "print(' ')\n",
    "print('_________________________________________')\n",
    "\n",
    "\n",
    "#Build train data arrays based on image lists\n",
    "#     print('Building feature data arrays...')\n",
    "X_astro = build_feature_data(train_astro, selection_type, pca)\n",
    "X_oligo = build_feature_data(train_oligo, selection_type, pca)\n",
    "\n",
    "#Add labels and concatenate data\n",
    "#     print('Adding labels and concatenating data...')\n",
    "X, y = prepare_data(X_astro, X_oligo)\n",
    "\n",
    "#Train/Test for training images\n",
    "print('Setting up train/test split for training images...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "#Train model for this fold over training images\n",
    "print('')\n",
    "\n",
    "print('Training tiles with grid search determined parameters with classifier',classifier_used,'...')\n",
    "model = train_model_grid(grid, X_train, y_train)\n",
    "\n",
    "training_tile_accuracy = test_model(model, X_test, y_test)\n",
    "print('Tile level accuracy (training images):', training_tile_accuracy)\n",
    "print('_________________________________________')\n",
    "print('Image Test Results...')\n",
    "\n",
    "#Build test images\n",
    "X_test = build_feature_data(testing_images, selection_type, pca)\n",
    "print('x test', X_test.shape)\n",
    "\n",
    "img_predictions = []\n",
    "img_probabilities_astro = []\n",
    "img_probabilities_oligo = []\n",
    "astro_pred_count = 0\n",
    "oligo_pred_count = 0 \n",
    "astro_correct = 0\n",
    "oligo_correct = 0 \n",
    "astro_actual_count = 0 \n",
    "oligo_actual_count = 0 \n",
    "mixed_actual_count = 0 \n",
    "unknown_actual_count = 0 \n",
    "for i,im in enumerate(testing_images):\n",
    "    img = 'img%s' % (im,)\n",
    "    tile_predictions = model.predict(X_test[i])\n",
    "    tile_probabilities = model.predict_proba(X_test[i])\n",
    "    tile_probabilities_sum_astro = np.sum(tile_probabilities[:,1])\n",
    "    tile_probabilities_sum_oligo = np.sum(tile_probabilities[:,0])\n",
    "\n",
    "    astro_count = np.sum(tile_predictions == 1)\n",
    "    oligo_count = np.sum(tile_predictions == 0)\n",
    "\n",
    "    img_prediction = \"\".join(['Astro' if astro_count > oligo_count else 'Oligo'])\n",
    "    \n",
    "    if im in astro:\n",
    "        img_actual = 'Astro'\n",
    "        astro_actual_count += 1\n",
    "    elif im in oligo:\n",
    "        img_actual = 'Oligo'\n",
    "        oligo_actual_count += 1\n",
    "    elif im in mixed:\n",
    "        img_actual = 'Oligoastro'\n",
    "        mixed_actual_count += 1\n",
    "    else:\n",
    "        img_actual = 'Unknown'\n",
    "        unknown_actual_count += 1\n",
    "\n",
    "    print('For image:', img)\n",
    "    print('The label is:', img_actual)\n",
    "    print('The prediction is:', img_prediction)\n",
    "    print('Probabilities of astro:', tile_probabilities_sum_astro)\n",
    "    print('Probabilities of oligo:', tile_probabilities_sum_oligo)\n",
    "    print('')\n",
    "\n",
    "    if img_prediction == 'Astro':\n",
    "        astro_pred_count += 1\n",
    "        if img_prediction == img_actual:\n",
    "            astro_correct += 1\n",
    "    else:\n",
    "        oligo_pred_count += 1\n",
    "        if img_prediction == img_actual:\n",
    "            oligo_correct += 1\n",
    "\n",
    "    img_probabilities_astro.append(tile_probabilities_sum_astro)\n",
    "    img_probabilities_oligo.append(tile_probabilities_sum_oligo)\n",
    "\n",
    "print('_________________________________________')\n",
    "# print('Accuracy:', (astro_correct + oligo_correct)*100/(astro_actual_count+oligo_actual_count))\n",
    "\n",
    "print('Astro predictions:', astro_pred_count)\n",
    "\n",
    "if test_images != mixed:\n",
    "    print('Astro predictions correct:', astro_correct)\n",
    "    print('Astro precision:', astro_correct/astro_pred_count)\n",
    "    print('Astro recall:', astro_correct/astro_actual_count)\n",
    "    print('Astro F1 Measure:', 2 * (astro_correct/astro_actual_count) * (astro_correct/astro_pred_count)\\\n",
    "          / ((astro_correct/astro_actual_count) + (astro_correct/astro_pred_count)))\n",
    "print('')\n",
    "print('Oligo predictions:', oligo_pred_count)\n",
    "\n",
    "if test_images != mixed:\n",
    "    print('Oligo predictions correct:', oligo_correct)\n",
    "    print('Oligo precision:', oligo_correct/oligo_pred_count)\n",
    "    print('Oligo recall:', oligo_correct/oligo_actual_count)\n",
    "    print('Oligo F1 Measure:', 2 * (oligo_correct/oligo_actual_count) * (oligo_correct/oligo_pred_count)\\\n",
    "          / ((oligo_correct/oligo_actual_count) + (oligo_correct/oligo_pred_count)))\n",
    "print('')\n",
    "print('_________________________________________')\n",
    "print('astro_probabilities', img_probabilities_astro)\n",
    "print('oligo_probabilities', img_probabilities_oligo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T00:04:15.959935",
     "start_time": "2017-06-21T00:04:15.955139"
    }
   },
   "source": [
    "### Load Objects from Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-27T13:53:52.751436",
     "start_time": "2017-05-27T13:53:52.405518"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_dir = results_dir + '102/'\n",
    "_, _, fold_accuracies_runs_back102, img_accuracies_table_runs_back102 = load_results(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 6: CNN Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on CNN Fine Tuning versus Transfer Learning\n",
    "CNN Fine tuning requires a different approach to the structure of previous testing.\n",
    "Mainly because you must take care of data leakage at the training stage.\n",
    "With transfer learning it is possible to extract features from all tiles and keep them on disk.\n",
    "With fine tuning, you must only train the network with images that will not be used to validate or test.\n",
    "Therefore, CNN Fine Tuning is separated out from the rest of the code to simplify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:15.153983",
     "start_time": "2017-06-06T13:14:15.145050"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_cnn_model(run_dir, model_name):\n",
    "    run_dir = results_dir + '300/'\n",
    "    print('Saving results in', run_dir)\n",
    "    call(['mkdir', run_dir])\n",
    "    print('Saving model')\n",
    "    from keras.models import load_model\n",
    "\n",
    "    model.save(model_name + '.h5') \n",
    "    \n",
    "    return\n",
    "    \n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:16.027175",
     "start_time": "2017-06-06T13:14:15.984200"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function selects previously derived closest tiles based on clustered feature vectors from the non-fine tuned \n",
    "# second top layer of the ResNet50 model.\n",
    "# It then builds the dataset for train/test\n",
    "\n",
    "def build_data_for_cnn2(train_astro, train_oligo):\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    #Assemble clustered tiles for each image\n",
    "    X_astro = []\n",
    "    for i in train_astro:\n",
    "        img = 'img%s' % (i,)\n",
    "        tiles_to_read = images_root_dir + 'level%s/img%s_files/tile_array.npy' % (l, i)\n",
    "        closest_tiles_to_read = images_root_dir + 'level%s/img%s_files/closest_tiles.npy' % (l, i)\n",
    "        \n",
    "        tiles = np.load(tiles_to_read)\n",
    "        closest = np.load(closest_tiles_to_read)\n",
    "        \n",
    "        tiles = np.array([tiles[closest] for _,closest in enumerate(closest.flatten())])\n",
    "        X_astro.append(tiles)\n",
    "    X_astro = np.array(X_astro)\n",
    "    X_astro = X_astro.reshape(-1,224,224,3)\n",
    "    y_astro = np.ones((X_astro.shape[0],), dtype=int)\n",
    "    \n",
    "    X_oligo = []\n",
    "    for i in train_oligo:\n",
    "        img = 'img%s' % (i,)\n",
    "        tiles_to_read = images_root_dir + 'level%s/img%s_files/tile_array.npy' % (l, i)\n",
    "        closest_tiles_to_read = images_root_dir + 'level%s/img%s_files/closest_tiles.npy' % (l, i)\n",
    "        \n",
    "        tiles = np.load(tiles_to_read)\n",
    "        closest = np.load(closest_tiles_to_read)\n",
    "        \n",
    "        tiles = np.array([tiles[closest] for _,closest in enumerate(closest.flatten())])\n",
    "        X_oligo.append(tiles)\n",
    "    X_oligo = np.array(X_oligo)\n",
    "    X_oligo = X_oligo.reshape(-1,224,224,3)\n",
    "    y_oligo = np.zeros((X_oligo.shape[0],), dtype=int)\n",
    "    \n",
    "    X = np.concatenate((X_astro, X_oligo), axis=0)\n",
    "    print('Shape of X', X.shape)\n",
    "    y = np.concatenate((y_astro, y_oligo), axis=0)\n",
    "    print('Shape of y', y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    return(X_train, X_test, y_train, y_test, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:16.883618",
     "start_time": "2017-06-06T13:14:16.857232"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function selects tiles randomly \n",
    "# It then builds the dataset for train/test\n",
    "\n",
    "def build_data_for_cnn(train_astro, train_oligo):\n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    #Assemble random tiles for each image\n",
    "    X_astro = []\n",
    "    for i in train_astro:\n",
    "        img = 'img%s' % (i,)\n",
    "        cnn_tiles_to_read = images_root_dir + 'level%s/img%s_files/cnn_random_tiles.npy' % (l, i)\n",
    "        tiles = np.load(cnn_tiles_to_read)\n",
    "        X_astro.append(tiles)\n",
    "    X_astro = np.array(X_astro)\n",
    "    X_astro = X_astro.reshape(-1,224,224,3)\n",
    "    y_astro = np.ones((X_astro.shape[0],), dtype=int)\n",
    "\n",
    "    X_oligo = []\n",
    "    for i in train_oligo:\n",
    "        img = 'img%s' % (i,)\n",
    "        cnn_tiles_to_read = images_root_dir + 'level%s/img%s_files/cnn_random_tiles.npy' % (l, i)\n",
    "        tiles = np.load(cnn_tiles_to_read)\n",
    "        X_oligo.append(tiles)\n",
    "    X_oligo = np.array(X_oligo)\n",
    "    X_oligo = X_oligo.reshape(-1,224,224,3)\n",
    "    y_oligo = np.zeros((X_oligo.shape[0],), dtype=int)\n",
    "\n",
    "    X = np.concatenate((X_astro, X_oligo), axis=0)\n",
    "    print('Shape of X', X.shape)\n",
    "    y = np.concatenate((y_astro, y_oligo), axis=0)\n",
    "    print('Shape of y', y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "    print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    return(X_train, X_test, y_train, y_test, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-06T13:14:18.128424",
     "start_time": "2017-06-06T13:14:18.079743"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function tests hold out images against CNN trained model\n",
    "# Prints out accuracies of images individually and overall as well as validated test score from CNN training\n",
    "\n",
    "def test_cnn(hold_out_images, hold_out_astro, hold_out_oligo):\n",
    "    print('Building test image batches...')\n",
    "    X_test = []\n",
    "    img_predictions = []\n",
    "    img_actuals = []\n",
    "    for i in hold_out_images:\n",
    "\n",
    "        img = 'img%s' % (i,)\n",
    "        cnn_tiles_to_read = images_root_dir + 'level%s/img%s_files/cnn_random_tiles.npy' % (l, i)\n",
    "        X_test = np.load(cnn_tiles_to_read)\n",
    "        X_test = X_test.reshape(-1,224,224,3)\n",
    "\n",
    "        print('Predicting image:', img, '...')\n",
    "        tile_predictions = model.predict(X_test)\n",
    "\n",
    "        astro_count = np.sum(tile_predictions[:,1] >= .5)\n",
    "        oligo_count = np.sum(tile_predictions[:,0] > .5)\n",
    "\n",
    "        img_actual = \"\".join(['Astro' if i in hold_out_astro else 'Oligo'])\n",
    "        img_prediction = \"\".join(['Astro' if astro_count > oligo_count else 'Oligo'])\n",
    "        img_accuracy = [astro_count/X_test.shape[0] if img_actual == 'Astro' else oligo_count/X_test.shape[0]]\n",
    "        print('Prediction:', img_prediction)\n",
    "        print('Accuracy:', img_accuracy)\n",
    "\n",
    "        img_accuracies.append(img_accuracy)\n",
    "        img_predictions.append(img_prediction)\n",
    "        img_actuals.append(img_actual)\n",
    "        img_accuracies_dict[i] = img_accuracy\n",
    "\n",
    "    #Determine and print accuracy\n",
    "    fold_accuracy = np.sum(np.array(img_accuracies))/len(img_accuracies)\n",
    "\n",
    "    print('_________________________________________')\n",
    "    print('')\n",
    "    print('Labels for images:', img_actuals)\n",
    "    print('Predictions for images:', img_predictions)\n",
    "    print('Correct image predictions', len(np.where(np.array(img_predictions) == np.array(img_actuals))[0]))\n",
    "    print('')\n",
    "    print('Image level accuracy for fold: %.2f%%' % (fold_accuracy*100,))\n",
    "\n",
    "    print('Validation accuracy: %.2f%%' % (scores[1]*100),)\n",
    "\n",
    "\n",
    "    #Save results\n",
    "    print('Saving fold_accuracies_runs')\n",
    "    call(['mkdir', run_dir])\n",
    "    fileObject = open(run_dir + 'img_accuracies_dict%s' % (fold,), \"wb\")\n",
    "    pickle.dump(img_accuracies_dict, fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tile Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-04T16:23:36.448410",
     "start_time": "2017-06-04T16:23:07.456360"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on level: 1\n",
      "Start time:  2017-06-04 16:23:07\n",
      "Saving random tiles for Features of Image img4938b\n",
      "Saving random tiles for Features of Image img4941b\n",
      "Saving random tiles for Features of Image img4942b\n",
      "Saving random tiles for Features of Image img4943b\n",
      "Saving random tiles for Features of Image img4944b\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-9e62a679b379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtiles_to_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_root_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'level%s/img%s_files/tile_array.npy'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles_to_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_random_tiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:18113)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# This cell selects tiles randomly from each image and saves the to disk for using in CNN training and test.\n",
    "# Preselecting tiles in this way saves some time but does not prevent CNN training runs being long running.\n",
    "\n",
    "# These images have too few tiles so omit them (balance between astro and oligo)\n",
    "images = [i for i in images2a if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "for l in levels:\n",
    "    print('Working on level:', l)\n",
    "    \n",
    "    #Set number of tiles\n",
    "    n_random_tiles = 100\n",
    "    \n",
    "    print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    for i in images:\n",
    "        #Set names\n",
    "        img = 'img%s' % (i,)\n",
    "        random_tiles_to_write = images_root_dir + 'level%s/img%s_files/cnn_random_tiles' % (l, i)\n",
    "        tiles_to_read = images_root_dir + 'level%s/img%s_files/tile_array.npy' % (l, i)\n",
    "        tiles = np.load(tiles_to_read)\n",
    "        idx = np.random.choice(tiles.shape[0], n_random_tiles, replace=False)\n",
    "        tiles = tiles[idx]\n",
    "\n",
    "        #Save closest tiles per cluster to disk\n",
    "        print('Saving random tiles for Features of Image', img)\n",
    "        np.save(random_tiles_to_write, tiles)\n",
    "        \n",
    "print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This step is very long running (2+ hours).\n",
    "\n",
    "# Cross validation for tuned CNN\n",
    "# Requires CNN to be trained against the training set with test images held out.\n",
    "# Since CNN training is long running, testing with only 2 folds.\n",
    "\n",
    "astro = astro1\n",
    "oligo = oligo1\n",
    "images = astro + oligo\n",
    "\n",
    "#Interactive Image validation run\n",
    "\n",
    "description = 'Train CNN cross validation on images1 using feature clustering from original feature vectors'\n",
    "run_dir = results_dir + '700/'\n",
    "\n",
    "#Runs\n",
    "runs = 1\n",
    "\n",
    "\n",
    "# Select number of folds: 2, 4, 8, 16\n",
    "folds = 2\n",
    "\n",
    "print('Running with CNN testing')\n",
    "\n",
    "fold_accuracies_runs = []\n",
    "fold_training_accuracies_runs = []\n",
    "tile_fold_accuracies_runs = []\n",
    "img_accuracies_table_runs = pd.DataFrame([])\n",
    "\n",
    "for r in range(runs):\n",
    "    img_actuals = []\n",
    "    img_predictions = []\n",
    "    img_accuracies = []\n",
    "    img_predictions_dict = {}\n",
    "    img_accuracies_dict = {}\n",
    "        \n",
    "    fold_training_accuracies = []\n",
    "    fold_accuracies = []\n",
    "    tile_fold_accuracies = []\n",
    "    img_accuracies_table = pd.DataFrame([])\n",
    "    fold = 0\n",
    "    print('RUN NUMBER...', r+1)\n",
    "    \n",
    "    # Train model for each set of images left after hold out images removed. \n",
    "    # Randomly select images to hold out.\n",
    "    # Ensure an even number of astro and oligo images are chosen\n",
    "    for i,j in zip(np.random.choice(astro, (folds, int(len(astro)/folds)), replace=False), np.random.choice(oligo, (folds, int(len(oligo)/folds)), replace=False)):\n",
    "        \n",
    "        hold_out_astro = i\n",
    "        hold_out_oligo = j\n",
    "        hold_out_images = np.hstack((hold_out_astro, hold_out_oligo))\n",
    "        fold += 1\n",
    "        #Train image numbers: Mask hold_out image numbers from astro and oligo\n",
    "        train_astro = [x for _,x in enumerate(astro) if x not in hold_out_astro]\n",
    "        train_oligo = [x for _,x in enumerate(oligo) if x not in hold_out_oligo]\n",
    "        train_images = np.hstack((train_astro, train_oligo))\n",
    "\n",
    "        print('_________________________________________')\n",
    "        print(' ')\n",
    "        print('Fold...', fold)\n",
    "        print('Train/Test Split:', (len(astro)-int(len(astro)/folds)+len(oligo)-int(len(oligo)/folds)), '/', (int(len(astro)/folds)+int(len(astro)/folds)))\n",
    "\n",
    "        print(' ')\n",
    "        print('Hold out images:', hold_out_images)\n",
    "        print('Train images:', train_images)\n",
    "\n",
    "        print('Building train data arrays...')\n",
    "        X_train, X_test, y_train, y_test, _, _ = build_data_for_cnn2(train_astro, train_oligo)\n",
    "        #Train cnn for this fold over training images\n",
    "       \n",
    "        \n",
    "        print('_________________________________________')\n",
    "        print(' ')\n",
    "        \n",
    "        print('Training ResNet50 top layer...')\n",
    "        print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        #Add averaging and dense layer, plus a logistic prediction layer to the base ResNet50 \n",
    "        x = ResNet50_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs=ResNet50_model.input, outputs=predictions)\n",
    "        \n",
    "#         x = ResNet50_model.output\n",
    "#         x.add(GlobalAveragePooling2D())\n",
    "#         x.add(Dropout(0.5))\n",
    "#         x.add(Dense(1024, activation='relu'))\n",
    "#         predictions = Dense(2, activation='softmax')(x)\n",
    "#         model = Model(inputs=ResNet50_model.input, outputs=predictions)\n",
    "\n",
    "# Gather tuned features\n",
    "# cnn_model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "# tuned_features = cnn_model.predict(X_astro)\n",
    "\n",
    "        for layer in ResNet50_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        #Scale and parameters\n",
    "        y_train = np_utils.to_categorical(y_train, 2)\n",
    "        y_test = np_utils.to_categorical(y_test, 2)\n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "        epochs = 1\n",
    "        batch_size = 32\n",
    "\n",
    "        #Train top layer\n",
    "        top_layer_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\\\n",
    "                         verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "        print('Saving results in', run_dir)\n",
    "        call(['mkdir', run_dir])\n",
    "        print('Saving model')\n",
    "        model.save(run_dir + 'top_layer_model%s.h5' % (fold,)) \n",
    "    \n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print('_________________________________________')\n",
    "        print(' ')\n",
    "        \n",
    "        print('Fine tuning ResNet50 with layers 49-50 ...')\n",
    "        print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        epochs = 2\n",
    "        \n",
    "        for layer in model.layers[:173]:\n",
    "           layer.trainable = False\n",
    "        for layer in model.layers[173:]:\n",
    "           layer.trainable = True\n",
    "\n",
    "        model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        #Fine tune top 1 layer\n",
    "        tuned_model_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\\\n",
    "                     verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        print('Saving results in', run_dir)\n",
    "        call(['mkdir', run_dir])\n",
    "        print('Saving model')\n",
    "        model.save(run_dir + 'tuned_model%s.h5' % (fold,))\n",
    "        \n",
    "        print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print('_________________________________________')\n",
    "        print(' ')\n",
    "        \n",
    "        scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "        print('_________________________________________')\n",
    "\n",
    "        print('Building test image batches...')\n",
    "        X_test = []\n",
    "        img_predictions = []\n",
    "        img_actuals = []\n",
    "        tile_predictions_list = []\n",
    "        for i in hold_out_images:\n",
    "\n",
    "            img = 'img%s' % (i,)\n",
    "            cnn_tiles_to_read = images_root_dir + 'level%s/img%s_files/cnn_random_tiles.npy' % (l, i)\n",
    "            X_test = np.load(cnn_tiles_to_read)\n",
    "            X_test = X_test.reshape(-1,224,224,3)\n",
    "\n",
    "            print('Predicting image:', img)\n",
    "            tile_predictions = model.predict(X_test)\n",
    "\n",
    "            astro_count = np.sum(tile_predictions[:,1] >= .5)\n",
    "            oligo_count = np.sum(tile_predictions[:,0] > .5)\n",
    "\n",
    "            img_actual = \"\".join(['Astro' if i in hold_out_astro else 'Oligo'])\n",
    "            img_prediction = \"\".join(['Astro' if astro_count > oligo_count else 'Oligo'])\n",
    "            img_accuracy = [astro_count/X_test.shape[0] if img_actual == 'Astro' else oligo_count/X_test.shape[0]]\n",
    "            print('Prediction:', img_prediction)\n",
    "            print('Accuracy:', img_accuracy)\n",
    "            \n",
    "            tile_predictions_list.append(tile_predictions)\n",
    "            img_accuracies.append(img_accuracy)\n",
    "            img_predictions.append(img_prediction)\n",
    "            img_actuals.append(img_actual)\n",
    "            img_accuracies_dict[i] = img_accuracy\n",
    "\n",
    "        #Determine and print accuracy\n",
    "        fold_accuracy = np.sum(np.array(img_accuracies))/len(img_accuracies)\n",
    "\n",
    "        print('_________________________________________')\n",
    "        print('')\n",
    "        print('Labels for images:', img_actuals)\n",
    "        print('Predictions for images:', img_predictions)\n",
    "        print('Correct image predictions', len(np.where(np.array(img_predictions) == np.array(img_actuals))[0]))\n",
    "        print('')\n",
    "        print('Image level accuracy for fold:', fold_accuracy)\n",
    "        print('Validation accuracy: %.2f%%' % (scores[1]*100,))\n",
    "\n",
    "        #Save results\n",
    "        print('Saving img_accuracies_dict')\n",
    "        call(['mkdir', run_dir])\n",
    "        fileObject = open(run_dir + 'img_accuracies_dict%s' % (fold,), \"wb\")\n",
    "        pickle.dump(img_accuracies_dict, fileObject)\n",
    "        fileObject.close()\n",
    "        \n",
    "        print('Saving tile_predictions_list')\n",
    "        call(['mkdir', run_dir])\n",
    "        fileObject = open(run_dir + 'tile_predictions_list%s' % (fold,), \"wb\")\n",
    "        pickle.dump(tile_predictions_list, fileObject)\n",
    "        fileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Test Inter-Image sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T03:33:39.865374",
     "start_time": "2017-06-04T23:42:00.587380"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning with following images as input\n",
      "['4938', '4941', '4942', '4943', '4944', '6188', '6290', '6666', '6667', '5854', '6402', '6405', '7010', '7013', '7298', '7299', '8158', 'A5TP', 'A5TU', 'A5TW', 'A5TY', 'A6S7', '5963', '6688', '6689', '6691', 'A87N', '7476', '7477', '7478', '7479', '7485', '7601', '7606', '7607', '7680', '7686', '7691', '7854', '7855', '7857', '7858', '7860', '7884', '8011', '8015', '8104', '8106', '8110']\n",
      "['5396', '6668', '6669', '5849', '5874', '6397', '6399', '6400', '6401', '6404', '6408', '6410', '7008', '7014', '7015', '7018', '7294', '7301', '7302', '7309', '8164', '8165', '8168', 'A5TS', 'A5TT', 'A6S2', 'A6S3', 'A6S8', '5964', '6690', '6692', '7634', '7641', '8189', 'A4MT', 'A6IZ', 'A6J1', '7467', '7469', '7470', '7471', '7472', '7480', '7481', '7602', '7605', '7616', '7620', '7677']\n",
      "Start time:  2017-06-04 23:42:00\n",
      "Shape of X (9800, 224, 224, 3)\n",
      "Shape of y (9800,)\n",
      "End time:  2017-06-04 23:53:20\n",
      "Start time:  2017-06-04 23:53:24\n",
      "Train on 7840 samples, validate on 1960 samples\n",
      "Epoch 1/2\n",
      "7840/7840 [==============================] - 3494s - loss: 0.9327 - acc: 0.6511 - val_loss: 1.4340 - val_acc: 0.5117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/2\n",
      "7840/7840 [==============================] - 3174s - loss: 0.4874 - acc: 0.7542 - val_loss: 1.2905 - val_acc: 0.4888\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Saving results in /Volumes/2T_HD/Masters_Project/results/800/\n",
      "Saving model\n",
      "End time:  2017-06-05 01:45:02\n",
      "Start time:  2017-06-05 01:45:02\n",
      "Train on 7840 samples, validate on 1960 samples\n",
      "Epoch 1/2\n",
      "7840/7840 [==============================] - 2762s - loss: 0.3559 - acc: 0.8304 - val_loss: 1.3711 - val_acc: 0.5464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/2\n",
      "7840/7840 [==============================] - 2774s - loss: 0.3250 - acc: 0.8542 - val_loss: 1.1006 - val_acc: 0.6051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Saving results in /Volumes/2T_HD/Masters_Project/results/800/\n",
      "Saving model\n",
      "End time:  2017-06-05 03:17:24\n",
      "Start time:  2017-06-05 03:17:24\n",
      "Building test image batches...\n",
      "Predicting image: img1 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img2 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img7 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img8 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img9 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img11 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img14 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img15 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img17 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img18 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img19 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img23 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img26 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img28 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img29 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img31 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [0.0]\n",
      "Predicting image: img3 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img4 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img5 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img6 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img10 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img12 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img13 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img16 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img20 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img21 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img22 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img24 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img25 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img27 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img30 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "Predicting image: img32 ...\n",
      "Prediction: Oligo\n",
      "Accuracy: [1.0]\n",
      "_________________________________________\n",
      "\n",
      "Labels for images: ['Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Astro', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo']\n",
      "Predictions for images: ['Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo', 'Oligo']\n",
      "Correct image predictions 16\n",
      "\n",
      "Image level accuracy for fold: 50.55%\n",
      "Validation accuracy: 50.94%\n",
      "Saving fold_accuracies_runs\n",
      "End time:  2017-06-05 03:33:39\n"
     ]
    }
   ],
   "source": [
    "# This step is very long running (3+ hours).\n",
    "\n",
    "# Interactive Image test for CNN testing\n",
    "# Allows training of TCGA set and testing against the CBTC set.\n",
    "# Prints out predictions and accuracies for each image and overall for run\n",
    "\n",
    "astro = [i for i in astro2a if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "oligo = [i for i in oligo2a if i not in ['5393', '5394', '5397', '5390', '5395', '7676']]\n",
    "\n",
    "\n",
    "print('Fine tuning with following images as input')\n",
    "print(astro)\n",
    "print(oligo)\n",
    "\n",
    "description = 'Train CNN on TCGA images2a using feature clustering from original feature vectors'\n",
    "run_dir = results_dir + '800/'\n",
    "\n",
    "\n",
    "#Load data\n",
    "\n",
    "X_train, X_test, y_train, y_test, X, y = build_data_for_cnn2(astro, oligo)\n",
    "\n",
    "print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#Add averaging and dense layer, plus a logistic prediction layer to the base ResNet50 \n",
    "x = ResNet50_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=ResNet50_model.input, outputs=predictions)\n",
    "\n",
    "for layer in ResNet50_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Scale and parameters\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "\n",
    "#Train top layer\n",
    "top_layer_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\\\n",
    "                 verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "print('Saving results in', run_dir)\n",
    "call(['mkdir', run_dir])\n",
    "print('Saving model')\n",
    "model.save(run_dir + 'top_layer_model.h5')\n",
    "\n",
    "print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Fine tune top few layers\n",
    "\n",
    "print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "epochs = 2\n",
    "\n",
    "for layer in model.layers[:169]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[169:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tuned_model_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\\\n",
    "                 verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "print('Saving results in', run_dir)\n",
    "call(['mkdir', run_dir])\n",
    "print('Saving model')\n",
    "model.save(run_dir + 'tuned_model.h5')\n",
    "print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "print(\"Start time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "test_cnn(images1, astro1, oligo1)\n",
    "print(\"End time: \",strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
